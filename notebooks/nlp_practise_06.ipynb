{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM6g47UGWbSjRCO0K/yBCJO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prp20/tensorflow_learning/blob/main/notebooks/nlp_practise_06.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "iUAWR-2enEQd",
        "outputId": "f603bc51-99fb-4d98-ae2b-374bb0e5147c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.9.2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "tf.__version__"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi -L"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ksQ-JU_3nNw5",
        "outputId": "39d01054-e789-4ce2-cc54-e54ba4aef32d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-5bfb5ce1-5e45-26c7-2f4a-0dd5d6f603d6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install kaggle"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_dlUFCnnQL3",
        "outputId": "333c706f-ce93-49e4-a8b4-0e9ce2e69917"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.8/dist-packages (1.5.12)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.8/dist-packages (from kaggle) (2022.12.7)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.8/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.8/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from kaggle) (2.25.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.8/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from kaggle) (4.64.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.8/dist-packages (from kaggle) (7.0.0)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.8/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->kaggle) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->kaggle) (4.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-j6D-thnSCP",
        "outputId": "2930d275-ee2f-4140-aa3f-0bd5649ad572"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir ~/.kaggle\n",
        "! cp /content/drive/MyDrive/kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "rj928M9HnUpM"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! kaggle datasets download -d chaitanyakck/medical-text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PjTscpyRnZWC",
        "outputId": "757497e9-5183-47ac-9715-a7a04ec64008"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading medical-text.zip to /content\n",
            "\r  0% 0.00/11.6M [00:00<?, ?B/s]\n",
            "\r100% 11.6M/11.6M [00:00<00:00, 129MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! unzip medical-text.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1jwB7uuSndG3",
        "outputId": "20eeb744-a00c-4359-b626-eb077c325bab"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  medical-text.zip\n",
            "  inflating: test.dat                \n",
            "  inflating: train.dat               \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_text_labels(fname):\n",
        "  labels = []\n",
        "  texts = []\n",
        "  with open(fname, \"r\") as fh:\n",
        "    train_lines = fh.readlines() \n",
        "  for line in train_lines:\n",
        "    splitline = line.split('\\t')\n",
        "    labels.append(int(splitline[0]))\n",
        "    texts.append(splitline[1])\n",
        "  return texts, labels"
      ],
      "metadata": {
        "id": "Y9jYlJhpnn8S"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data, labels = create_text_labels(\"train.dat\")"
      ],
      "metadata": {
        "id": "HVnSNuBdoIv8"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for val in range(10):\n",
        "  print(data[val]+ \"\\t\" + str(labels[val]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ELCi6GaCqVMb",
        "outputId": "65542ae4-07cc-4cf0-d864-d93e05e35f19"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Catheterization laboratory events and hospital outcome with direct angioplasty for acute myocardial infarction To assess the safety of direct infarct angioplasty without antecedent thrombolytic therapy, catheterization laboratory and hospital events were assessed in consecutively treated patients with infarctions involving the left anterior descending (n = 100 patients), right (n = 100), and circumflex (n = 50) coronary arteries. The groups of patients were similar for age (left anterior descending coronary artery, 59 years; right coronary artery, 58 years; circumflex coronary artery, 62 years), patients with multivessel disease (left anterior descending coronary artery, 55%; right coronary artery, 55%; circumflex coronary artery, 64%), and patients with initial grade 0/1 antegrade flow (left anterior descending coronary artery, 79%; right coronary artery, 84%; circumflex coronary artery, 90%). Cardiogenic shock was present in eight patients with infarction of the left anterior descending coronary artery, four with infarction of the right coronary artery, and four with infarction of the circumflex coronary artery. Major catheterization laboratory events (cardioversion, cardiopulmonary resuscitation, dopamine or intra-aortic balloon pump support for hypotension, and urgent surgery) occurred in 10 patients with infarction of the left anterior descending coronary artery, eight with infarction of the right coronary artery, and four with infarction of the circumflex coronary artery (16 of 16 shock and six of 234 nonshock patients, p less than 0.001). There was one in-laboratory death (shock patient with infarction of the left anterior descending coronary artery). \n",
            "\t4\n",
            "Renal abscess in children. Three cases of renal abscesses in children are described to illustrate the variable presenting features. An additional 23 pediatric cases, reported over the past ten years, were reviewed for clinical features and therapy. Fever, loin pain, and leukocytosis were common presenting features, but less than half of all abscesses were associated with either an abnormal urinalysis or a positive urine culture. The presenting features were sometimes confused with appendicitis, peritonitis, or a Wilms tumor. An organism was identified in 17 cases--Escherichia coli in 9 children and Staphylococcus aureus in 8 children. The majority of E. coli infections occurred in girls and the majority of S. aureus infections occurred in boys. Reflux was documented in 5 patients, and 2 children had a possible extrarenal source of infection. Antibiotics alone produced a cure in 10 children (38%), but 16 children (62%) required a surgical procedure. \n",
            "\t5\n",
            "Hyperplastic polyps seen at sigmoidoscopy are markers for additional adenomas seen at colonoscopy. Asymptomatic individuals undergoing screening flexible sigmoidoscopy were prospectively studied. Polyps were found in 185 subjects. The endoscopist recorded an opinion on the polyps' histology based on endoscopic appearance. No polyps were removed at sigmoidoscopy. All subjects with rectosigmoid polyps then underwent colonoscopy and polypectomy. Of them, 99 subjects (54%) had at least one rectosigmoid adenoma, 69 (37%) had only hyperplastic polyps, and 17 (9%) had other findings. The endoscopists' opinion of the histopathology of polyps at sigmoidoscopy was correct for 61% of the lesions. Of subjects with adenomatous rectosigmoid polyps, 29% had additional adenomas at more proximal sites. Proximal adenomas were found in 28% of patients with hyperplastic rectosigmoid polyps. Patients with rectosigmoid hyperplastic polyps had the same risk for additional proximal adenomas as patients with rectosigmoid adenomatous polyps. \n",
            "\t2\n",
            "Subclavian artery to innominate vein fistula after insertion of a hemodialysis catheter. Insertion of hemodialysis catheters for temporary use is now preferentially performed by percutaneous infraclavicular subclavian vein catheterization. This method involves passage of a stiff dilator and a peel-away sheath over a guide wire, and is usually carried out without fluoroscopy. For the most part this has proved to be a valuable and safe approach. However, a small incidence of major complications occurs, which needs to be emphasized. Sixteen cases of arteriovenous fistulas between the subclavian artery or its branches and the subclavian vein have been reported so far in the literature. To date only one case of subclavian artery to innominate vein fistula has been reported. We report the second case with this complication and suggest possible preventive measures. \n",
            "\t5\n",
            "Effect of local inhibition of gamma-aminobutyric acid uptake in the dorsomedial hypothalamus on extracellular levels of gamma-aminobutyric acid and on stress-induced tachycardia: a study using microdialysis. Previous studies involving local microinjection of drugs that interfere with gamma-aminobutyric acid (GABA)A receptor-mediated synaptic inhibition have led to the suggestion that endogenous GABA suppresses the activity of a sympatho-excitatory mechanism in the dorsomedial hypothalamus in rats. In this study, microdialysis was used to assess and to alter pharmacologically extracellular-levels of GABA within this region while simultaneously monitoring heart rate and blood pressure. In anesthetized rats, local microdialysis for 15 min with 2.5, 10 and 40 mM nipecotic acid, an inhibitor of GABA uptake, caused concentration-related increases in GABA and taurine in the extracellular space, but no significant change in heart rate or arterial pressure. Similar perfusion with 37.5, 75 and 150 mM KCl caused concentration-related increases in GABA as well as aspartate, glutamate, taurine, glycine and alanine. Only modest, variable increases in heart rate and no effect on arterial pressure were observed during the perfusions with high potassium. In conscious rats, unilateral microdialysis of the dorsomedial hypothalamus with 0.5 mM nipecotic acid for 2 to 2.5 hr before stress coupled with contralateral microinjection of muscimol (88 pmol/250 nl) 5 min before stress significantly reduced air stress-induced tachycardia; this reduction in tachycardia was associated with markedly elevated levels of GABA in dialysates collected from the dorsomedial hypothalamus. Neither treatment alone significantly influenced stress-induced increases in heart rate, although perfusion with nipecotic acid alone evoked similar elevations in extracellular GABA. These results suggest that extracellular levels of endogenous GABA in the dorsomedial hypothalamus may regulate the cardiovascular response to stress. \n",
            "\t4\n",
            "Infection during chronic epidural catheterization: diagnosis and treatment. A potentially serious complication of long-term epidural catheterization in cancer patients is infection. The early signs of infection were studied in 350 patients in whom long-term epidural catheters were inserted. Three areas of the catheter track were found to be involved; exit site and superficial catheter track infection, and epidural space infection. The authors identified the early signs of infection in each area and the progress of the infection from the deep track to include the epidural space in four of these patients. All 19 patients who developed deep track or epidural infections were successfully treated with antibiotics and catheter removal. None of the patients required surgery for spinal cord decompression. Catheters were replaced in 15 of the 19 treated patients who requested them after treatment with no recurrent infections. It was concluded that use of long-term epidural catheterization is associated with a definable epidural infection rate. The use of epidural opioid analgesia is an effective and safe means of obtaining pain relief for terminally ill patients when patients are monitored for possible infection and receive prompt treatment when the diagnosis is established. \n",
            "\t1\n",
            "Mediastinal tracheostomy using a pectoralis major myocutaneous flap after resection of carcinoma of the esophagus involving the proximal part of the trachea. An operative procedure of mediastinal tracheostomy using a pectoralis major myocutaneous flap is presented. In this procedure, the terminal portion of the trachea penetrates through the center of a pectoralis major myocutaneous flap and the tracheal wall is completely wrapped with the muscular portion of the flap. Between 1981 and 1988, eight patients with carcinoma in the cervicothoracic segment of the esophagus underwent mediastinal tracheostomy after laryngoesophagectomy and extended resection of the proximal part of the trachea through sternal manubrectomy, because of invasion into the trachea. In five of eight patients, a pectoralis major myocutaneous flap was used to construct a tracheal stoma. A skin flap only, or both a skin flap and a muscle flap, was used in the other three. In four of eight patients, tracheal necrosis occurred, and rupture of the brachiocephalic artery occurred in one patient when the tracheal stoma had been constructed using both a skin flap and a muscle flap. However, neither skin breakdown nor bleeding from the major vessels occurred when using the myocutaneous flap. Therefore, it is concluded that the construction of the tracheal stoma using a pectoralis major myocutaneous flap is recommended for mediastinal tracheostomy after laryngoesophagectomy with extended resection of the proximal part of the trachea. \n",
            "\t5\n",
            "Tumefactive fibroinflammatory lesion of the extremity. Report of a case and review of the literature. Tumefactive fibroinflammatory lesion is an idiopathic fibroinflammatory process of the head and neck region. Although benign histopathologically, it is invasive, destructive, and locally recurrent, leading to uncertainty regarding its proper management; as the disease is rare, determining optimal treatment is difficult, given the anecdotal nature of reports. We report the first case of a tumefactive fibroinflammatory lesion occurring outside the head and neck region. Our patient was treated with corticosteroids and had a favorable response, supporting this approach as initial treatment. Immunohistochemical studies performed on a pretreatment specimen were consistent with a secondary inflammatory component because no monoclonal nor aberrant phenotypes were detected. The tumefactive fibroinflammatory lesion appears to be indistinguishable from the other known idiopathic fibroinflammatory processes; patients presenting with any one of these should be evaluated for the others. \n",
            "\t5\n",
            "Multiple representations contribute to body knowledge processing. Evidence from a case of autotopagnosia. Body schema disturbances were studied in a 62-yr-old woman with Alzheimer's disease. She was severely impaired in verbal and nonverbal tasks requiring her to localize body parts (on her own body, the examiner's body or a doll's body) even though she correctly named the same parts when pointed at by the examiner. Pointing responses were misdirected mainly to parts contiguous with the target area and, to a lesser extent, to functionally equivalent body parts. We also found that the patient was able to define body part names functionally but not spatially. In another series of tasks, and in contrast to the above results, performances were normal when small objects, attached to the patient's body, served as pointing targets. Furthermore, on subsequent testing she pointed correctly at the remembered position of these objects. The fact that the same point in 'body space' is localized correctly when it corresponds to an external object and erroneously when it corresponds to a body part contradicts the idea of the body schema as a unitary function. Learning the position of objects on the body surface requires access to some form of body-reference system on which this information can be mapped. We argue that such a system can be available in autotopagnosia and is independent from the visuospatial representations of the body structure that are postulated to be damaged or inaccessible in this syndrome. An integrated account of the present results and of those reported by other authors suggests that multiple levels of representation (e.g., sensorimotor, visuospatial, semantic) are involved in the organization of body knowledge. \n",
            "\t3\n",
            "Increasing asthma prevalence in a rural New Zealand adolescent population: 1975-89. A survey of asthma symptoms and spirometry in 435 adolescent schoolchildren was undertaken in 1989 in a rural, largely Maori population. The survey questionnaires were identical to those used in a 1975 survey at the same school. The prevalence of reported asthma or wheeze significantly increased from 26.2% to 34.0%. This increase occurred in groups reporting asthma, and also those reporting wheeze unassociated with colds, but without a previous diagnosis of asthma. There was a tendency for a rise in reported wheeze in Europeans (24.3% to 27.4%) and a significant rise in Maoris (27.1% to 36.2%). The reclassification of other respiratory problems did not account for the increase. Data from this study provides evidence that there has been a rise in the prevalence of asthma in this New Zealand population over a time period of 14 years. \n",
            "\t5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(data), len(labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YIZsaHnPoOFM",
        "outputId": "9f363bb7-decd-4354-ea5d-7b2f9f04f7b0"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14438, 14438)"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels = np.asarray(labels).reshape(-1, 1)"
      ],
      "metadata": {
        "id": "4znUljrXoWRy"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E7MUdAq-om2l",
        "outputId": "06a04570-5af3-4367-d30b-3028d90c6632"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[4],\n",
              "       [5],\n",
              "       [2],\n",
              "       ...,\n",
              "       [1],\n",
              "       [2],\n",
              "       [3]])"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "ZNCi-X6Aonj_"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, test_data, train_labels, test_labels = train_test_split(data, labels, test_size=0.2, shuffle=True, random_state=42)\n",
        "len(train_data), len(test_data), len(train_labels), len(test_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J4pYF__go9N7",
        "outputId": "a5d52a46-0ab1-48d9-c31c-fe7f1a76a0da"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11550, 2888, 11550, 2888)"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "one_hot_encoder = OneHotEncoder(sparse=False)"
      ],
      "metadata": {
        "id": "oaxanpZ6pBKN"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels_one_hot = one_hot_encoder.fit_transform(train_labels)\n",
        "test_labels_one_hot = one_hot_encoder.transform(test_labels)"
      ],
      "metadata": {
        "id": "i0gfROrQpDa7"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels_one_hot"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oRwK0wlBpFEk",
        "outputId": "41006366-7ea4-48e0-f65d-53c206c4db2d"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1.],\n",
              "       [0., 0., 0., 0., 1.],\n",
              "       ...,\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0.],\n",
              "       [0., 1., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_CLASSES=5"
      ],
      "metadata": {
        "id": "jAMkRqSKpG4w"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "model_0 = Pipeline([\n",
        "    (\"tfidf\", TfidfVectorizer()),\n",
        "    (\"clf\", MultinomialNB())\n",
        "])\n",
        "model_0.fit(train_data, train_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C5QgNFnapXcf",
        "outputId": "bb86ea29-4ffb-4dfd-f5a2-90a89fb0bd74"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('tfidf', TfidfVectorizer()), ('clf', MultinomialNB())])"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_0_score = model_0.score(test_data, test_labels)"
      ],
      "metadata": {
        "id": "FEPxApP3pa5n"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "def calculate_results(y_true, y_pred):\n",
        "  model_accuracy = accuracy_score(y_true, y_pred) * 100\n",
        "  model_precision, model_recall, model_f1_score, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
        "  model_results = {\n",
        "      \"accuracy\": model_accuracy,\n",
        "      \"precision\":model_precision,\n",
        "      \"recall\": model_recall,\n",
        "      \"f1_score\": model_f1_score\n",
        "  }\n",
        "  return model_results\n",
        "\n",
        "def return_callbacks(model_name):\n",
        "  callbacks_list = []\n",
        "  callbacks_list.append(tf.keras.callbacks.ModelCheckpoint(\"saved_models/\"+model_name, monitor='val_loss', save_best_only='True', verbose=1))\n",
        "  callbacks_list.append(tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1, restore_best_weights='True'))\n",
        "  return callbacks_list"
      ],
      "metadata": {
        "id": "sSIk6Lc4pdSK"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_0_preds = model_0.predict(test_data)\n",
        "model_0_results = calculate_results(test_labels, model_0_preds)\n",
        "model_results_dataset = {}\n",
        "model_results_dataset['model_0'] = model_0_results\n",
        "model_0_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hzhMtYA2pgFP",
        "outputId": "0d7f71b7-4389-4450-b200-89cd8fca1a9a"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 49.411357340720215,\n",
              " 'precision': 0.5369400656025278,\n",
              " 'recall': 0.4941135734072022,\n",
              " 'f1_score': 0.436777962137569}"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_data, train_labels_one_hot))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_data, test_labels_one_hot))\n",
        "\n",
        "# Take the TensorSliceDataset's and turn them into prefetched batches\n",
        "train_dataset = train_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "test_dataset = test_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "train_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Znbe1rXzpho_",
        "outputId": "25863e84-777f-43ba-f647-19bcc76c5889"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PrefetchDataset element_spec=(TensorSpec(shape=(None,), dtype=tf.string, name=None), TensorSpec(shape=(None, 5), dtype=tf.float64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import TextVectorization\n",
        "output_seq_length = round(sum([len(i.split()) for i in train_data])/len(train_data))\n",
        "tv_layer = TextVectorization(max_tokens=10000, standardize=\"lower_and_strip_punctuation\", split=\"whitespace\", output_mode=\"int\", output_sequence_length=output_seq_length, pad_to_max_tokens=True)\n",
        "tv_layer.adapt(train_data)"
      ],
      "metadata": {
        "id": "SPsO-K1gpkKC"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "embedding_layer = layers.Embedding(input_dim=10000, output_dim=128, input_length=output_seq_length)"
      ],
      "metadata": {
        "id": "y0zDcdMGpnGl"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
        "x = tv_layer(inputs)\n",
        "x = embedding_layer(x)\n",
        "x = layers.GlobalAveragePooling1D()(x)\n",
        "output = layers.Dense(NUM_CLASSES, activation='softmax')(x)\n",
        "\n",
        "model_1 = tf.keras.Model(inputs, output, name=\"nlp_model_1\")\n",
        "model_1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9-EZl5vhpo67",
        "outputId": "1a7cc54e-2e10-4a99-c9a0-1fd24d565043"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"nlp_model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization (TextVec  (None, 180)              0         \n",
            " torization)                                                     \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 180, 128)          1280000   \n",
            "                                                                 \n",
            " global_average_pooling1d (G  (None, 128)              0         \n",
            " lobalAveragePooling1D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,280,645\n",
            "Trainable params: 1,280,645\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.compile(loss=\"categorical_crossentropy\", optimizer=tf.keras.optimizers.Adam(), metrics=[\"accuracy\"])\n",
        "history_1 = model_1.fit(train_dataset, epochs=50, validation_data=test_dataset, callbacks=return_callbacks(model_1.name))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nOu72wc5pqzo",
        "outputId": "6985048a-8ed1-43ef-ded1-6821f9ea8c28"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "352/361 [============================>.] - ETA: 0s - loss: 0.7768 - accuracy: 0.6866\n",
            "Epoch 1: val_loss improved from inf to 1.00897, saving model to saved_models/nlp_model_1\n",
            "361/361 [==============================] - 4s 8ms/step - loss: 0.7769 - accuracy: 0.6858 - val_loss: 1.0090 - val_accuracy: 0.5720\n",
            "Epoch 2/50\n",
            "361/361 [==============================] - ETA: 0s - loss: 0.7209 - accuracy: 0.7023\n",
            "Epoch 2: val_loss did not improve from 1.00897\n",
            "361/361 [==============================] - 2s 6ms/step - loss: 0.7209 - accuracy: 0.7023 - val_loss: 1.0256 - val_accuracy: 0.5689\n",
            "Epoch 3/50\n",
            "361/361 [==============================] - ETA: 0s - loss: 0.6731 - accuracy: 0.7158\n",
            "Epoch 3: val_loss did not improve from 1.00897\n",
            "361/361 [==============================] - 3s 8ms/step - loss: 0.6731 - accuracy: 0.7158 - val_loss: 1.0512 - val_accuracy: 0.5609\n",
            "Epoch 4/50\n",
            "357/361 [============================>.] - ETA: 0s - loss: 0.6304 - accuracy: 0.7293\n",
            "Epoch 4: val_loss did not improve from 1.00897\n",
            "361/361 [==============================] - 2s 7ms/step - loss: 0.6316 - accuracy: 0.7287 - val_loss: 1.0834 - val_accuracy: 0.5512\n",
            "Epoch 5/50\n",
            "353/361 [============================>.] - ETA: 0s - loss: 0.5944 - accuracy: 0.7375\n",
            "Epoch 5: val_loss did not improve from 1.00897\n",
            "361/361 [==============================] - 2s 6ms/step - loss: 0.5955 - accuracy: 0.7371 - val_loss: 1.1206 - val_accuracy: 0.5367\n",
            "Epoch 6/50\n",
            "352/361 [============================>.] - ETA: 0s - loss: 0.5631 - accuracy: 0.7463\n",
            "Epoch 6: val_loss did not improve from 1.00897\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "361/361 [==============================] - 2s 6ms/step - loss: 0.5641 - accuracy: 0.7461 - val_loss: 1.1614 - val_accuracy: 0.5312\n",
            "Epoch 6: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.evaluate(test_dataset)\n",
        "model_1_loaded = tf.keras.models.load_model(\"saved_models/nlp_model_1\")\n",
        "model_1_preds = model_1_loaded.predict(test_dataset)\n",
        "model_1_results = calculate_results(test_labels, tf.argmax(model_1_preds, axis=1))\n",
        "model_results_dataset['model_1'] = model_1_results\n",
        "model_1_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QzlHEbNnps_1",
        "outputId": "1dd33707-38a9-41f4-a9b8-d486dc3709dd"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "91/91 [==============================] - 0s 4ms/step - loss: 1.0090 - accuracy: 0.5720\n",
            "91/91 [==============================] - 0s 3ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 8.829639889196676,\n",
              " 'precision': 0.06526131289348824,\n",
              " 'recall': 0.08829639889196676,\n",
              " 'f1_score': 0.06713543423412932}"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()"
      ],
      "metadata": {
        "id": "u12akoThpvp_"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "model_2_embedding = layers.Embedding(input_dim=10000, output_dim=128, embeddings_initializer=\"uniform\", input_length=output_seq_length, name=\"embedding_2\")\n",
        "\n",
        "inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
        "x = tv_layer(inputs)\n",
        "x = model_2_embedding(x)\n",
        "x = layers.GlobalAveragePooling1D()(x)\n",
        "x = layers.Dense(64, activation='relu')(x)\n",
        "output = layers.Dense(NUM_CLASSES, activation='softmax')(x)\n",
        "\n",
        "model_2 = tf.keras.Model(inputs, output, name=\"nlp_model_2\")\n",
        "model_2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0RW0GgxPpxu0",
        "outputId": "5abc77e0-b047-4e77-fe90-b34df316a285"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"nlp_model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization (TextVec  (None, 180)              0         \n",
            " torization)                                                     \n",
            "                                                                 \n",
            " embedding_2 (Embedding)     (None, 180, 128)          1280000   \n",
            "                                                                 \n",
            " global_average_pooling1d (G  (None, 128)              0         \n",
            " lobalAveragePooling1D)                                          \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 5)                 325       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,288,581\n",
            "Trainable params: 1,288,581\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_2.compile(loss=\"categorical_crossentropy\", optimizer=tf.keras.optimizers.Adam(), metrics=[\"accuracy\"])\n",
        "history_2 = model_2.fit(train_dataset, epochs=20, validation_data=test_dataset,callbacks=return_callbacks(model_2.name))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qH0hZb4Spz-u",
        "outputId": "57547d23-7198-4b57-a2e4-eabf55dcc054"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "360/361 [============================>.] - ETA: 0s - loss: 1.3282 - accuracy: 0.4444\n",
            "Epoch 1: val_loss improved from inf to 1.11776, saving model to saved_models/nlp_model_2\n",
            "361/361 [==============================] - 4s 9ms/step - loss: 1.3276 - accuracy: 0.4448 - val_loss: 1.1178 - val_accuracy: 0.5409\n",
            "Epoch 2/20\n",
            "352/361 [============================>.] - ETA: 0s - loss: 0.9488 - accuracy: 0.5978\n",
            "Epoch 2: val_loss improved from 1.11776 to 0.99340, saving model to saved_models/nlp_model_2\n",
            "361/361 [==============================] - 4s 10ms/step - loss: 0.9465 - accuracy: 0.5984 - val_loss: 0.9934 - val_accuracy: 0.5651\n",
            "Epoch 3/20\n",
            "361/361 [==============================] - ETA: 0s - loss: 0.7666 - accuracy: 0.6766\n",
            "Epoch 3: val_loss did not improve from 0.99340\n",
            "361/361 [==============================] - 2s 6ms/step - loss: 0.7666 - accuracy: 0.6766 - val_loss: 1.0119 - val_accuracy: 0.5686\n",
            "Epoch 4/20\n",
            "359/361 [============================>.] - ETA: 0s - loss: 0.6613 - accuracy: 0.7089\n",
            "Epoch 4: val_loss did not improve from 0.99340\n",
            "361/361 [==============================] - 2s 6ms/step - loss: 0.6614 - accuracy: 0.7092 - val_loss: 1.0808 - val_accuracy: 0.5578\n",
            "Epoch 5/20\n",
            "360/361 [============================>.] - ETA: 0s - loss: 0.5885 - accuracy: 0.7274\n",
            "Epoch 5: val_loss did not improve from 0.99340\n",
            "361/361 [==============================] - 2s 6ms/step - loss: 0.5886 - accuracy: 0.7274 - val_loss: 1.1760 - val_accuracy: 0.5409\n",
            "Epoch 6/20\n",
            "352/361 [============================>.] - ETA: 0s - loss: 0.5358 - accuracy: 0.7388\n",
            "Epoch 6: val_loss did not improve from 0.99340\n",
            "361/361 [==============================] - 2s 6ms/step - loss: 0.5366 - accuracy: 0.7378 - val_loss: 1.2760 - val_accuracy: 0.5242\n",
            "Epoch 7/20\n",
            "355/361 [============================>.] - ETA: 0s - loss: 0.4974 - accuracy: 0.7429\n",
            "Epoch 7: val_loss did not improve from 0.99340\n",
            "Restoring model weights from the end of the best epoch: 2.\n",
            "361/361 [==============================] - 2s 6ms/step - loss: 0.4983 - accuracy: 0.7424 - val_loss: 1.3766 - val_accuracy: 0.5093\n",
            "Epoch 7: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_2.evaluate(test_dataset)\n",
        "model_2_loaded = tf.keras.models.load_model(\"saved_models/nlp_model_2\")\n",
        "model_2_preds = model_2_loaded.predict(test_dataset)\n",
        "model_2_results = calculate_results(test_labels, tf.argmax(model_2_preds, axis=1))\n",
        "model_results_dataset['model_2'] = model_2_results\n",
        "model_2_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2dv3DFe-p2ms",
        "outputId": "31a4bae1-0172-4ae2-fb83-477256bf9934"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "91/91 [==============================] - 0s 4ms/step - loss: 0.9934 - accuracy: 0.5651\n",
            "91/91 [==============================] - 0s 3ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 8.379501385041552,\n",
              " 'precision': 0.05900035221026017,\n",
              " 'recall': 0.08379501385041552,\n",
              " 'f1_score': 0.06259384370506027}"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()"
      ],
      "metadata": {
        "id": "lpcqHDHvp5Qo"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "model_3_embedding = layers.Embedding(input_dim=10000, output_dim=128, embeddings_initializer=\"uniform\", input_length=output_seq_length, name=\"embedding_2\")\n",
        "\n",
        "inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
        "x = tv_layer(inputs)\n",
        "x = model_3_embedding(x)\n",
        "x = layers.LSTM(64)(x)\n",
        "x = layers.Dense(64, activation='relu')(x)\n",
        "output = layers.Dense(NUM_CLASSES, activation='softmax')(x)\n",
        "\n",
        "model_3 = tf.keras.Model(inputs, output, name=\"nlp_model_3\")\n",
        "model_3.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r2SJqJcmp7DB",
        "outputId": "dcf0d709-b790-42cb-d3f0-56122ed5552e"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"nlp_model_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization (TextVec  (None, 180)              0         \n",
            " torization)                                                     \n",
            "                                                                 \n",
            " embedding_2 (Embedding)     (None, 180, 128)          1280000   \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 64)                49408     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 5)                 325       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,333,893\n",
            "Trainable params: 1,333,893\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_3.compile(loss=\"categorical_crossentropy\", optimizer=tf.keras.optimizers.Adam(), metrics=[\"accuracy\"])\n",
        "history_3 = model_3.fit(train_dataset, epochs=20, validation_data=test_dataset,callbacks=return_callbacks(model_3.name))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ELXub3zap8c5",
        "outputId": "318135e7-d20e-41d4-90bb-3ba947decb2b"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "359/361 [============================>.] - ETA: 0s - loss: 1.4732 - accuracy: 0.3619\n",
            "Epoch 1: val_loss improved from inf to 1.53226, saving model to saved_models/nlp_model_3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r361/361 [==============================] - 10s 25ms/step - loss: 1.4736 - accuracy: 0.3617 - val_loss: 1.5323 - val_accuracy: 0.3466\n",
            "Epoch 2/20\n",
            "358/361 [============================>.] - ETA: 0s - loss: 1.3904 - accuracy: 0.3891\n",
            "Epoch 2: val_loss improved from 1.53226 to 1.37303, saving model to saved_models/nlp_model_3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r361/361 [==============================] - 11s 30ms/step - loss: 1.3904 - accuracy: 0.3900 - val_loss: 1.3730 - val_accuracy: 0.3885\n",
            "Epoch 3/20\n",
            "361/361 [==============================] - ETA: 0s - loss: 1.3081 - accuracy: 0.4341\n",
            "Epoch 3: val_loss did not improve from 1.37303\n",
            "361/361 [==============================] - 5s 13ms/step - loss: 1.3081 - accuracy: 0.4341 - val_loss: 1.4560 - val_accuracy: 0.3816\n",
            "Epoch 4/20\n",
            "359/361 [============================>.] - ETA: 0s - loss: 1.3021 - accuracy: 0.4569\n",
            "Epoch 4: val_loss did not improve from 1.37303\n",
            "361/361 [==============================] - 5s 13ms/step - loss: 1.3027 - accuracy: 0.4569 - val_loss: 1.4145 - val_accuracy: 0.4055\n",
            "Epoch 5/20\n",
            "358/361 [============================>.] - ETA: 0s - loss: 1.2686 - accuracy: 0.4768\n",
            "Epoch 5: val_loss improved from 1.37303 to 1.36542, saving model to saved_models/nlp_model_3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r361/361 [==============================] - 8s 23ms/step - loss: 1.2693 - accuracy: 0.4767 - val_loss: 1.3654 - val_accuracy: 0.4304\n",
            "Epoch 6/20\n",
            "359/361 [============================>.] - ETA: 0s - loss: 1.2227 - accuracy: 0.5008\n",
            "Epoch 6: val_loss did not improve from 1.36542\n",
            "361/361 [==============================] - 5s 13ms/step - loss: 1.2233 - accuracy: 0.5008 - val_loss: 1.3789 - val_accuracy: 0.4041\n",
            "Epoch 7/20\n",
            "357/361 [============================>.] - ETA: 0s - loss: 1.2160 - accuracy: 0.5009\n",
            "Epoch 7: val_loss improved from 1.36542 to 1.32115, saving model to saved_models/nlp_model_3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r361/361 [==============================] - 9s 24ms/step - loss: 1.2141 - accuracy: 0.5021 - val_loss: 1.3212 - val_accuracy: 0.4726\n",
            "Epoch 8/20\n",
            "357/361 [============================>.] - ETA: 0s - loss: 0.9886 - accuracy: 0.6015\n",
            "Epoch 8: val_loss improved from 1.32115 to 1.23272, saving model to saved_models/nlp_model_3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r361/361 [==============================] - 8s 23ms/step - loss: 0.9884 - accuracy: 0.6017 - val_loss: 1.2327 - val_accuracy: 0.5177\n",
            "Epoch 9/20\n",
            "359/361 [============================>.] - ETA: 0s - loss: 0.8468 - accuracy: 0.6453\n",
            "Epoch 9: val_loss improved from 1.23272 to 1.19379, saving model to saved_models/nlp_model_3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r361/361 [==============================] - 9s 25ms/step - loss: 0.8474 - accuracy: 0.6452 - val_loss: 1.1938 - val_accuracy: 0.5267\n",
            "Epoch 10/20\n",
            "360/361 [============================>.] - ETA: 0s - loss: 0.7608 - accuracy: 0.6790\n",
            "Epoch 10: val_loss did not improve from 1.19379\n",
            "361/361 [==============================] - 5s 13ms/step - loss: 0.7613 - accuracy: 0.6790 - val_loss: 1.2187 - val_accuracy: 0.5184\n",
            "Epoch 11/20\n",
            "357/361 [============================>.] - ETA: 0s - loss: 0.6960 - accuracy: 0.7032\n",
            "Epoch 11: val_loss did not improve from 1.19379\n",
            "361/361 [==============================] - 5s 12ms/step - loss: 0.6978 - accuracy: 0.7029 - val_loss: 1.2636 - val_accuracy: 0.5166\n",
            "Epoch 12/20\n",
            "361/361 [==============================] - ETA: 0s - loss: 0.6490 - accuracy: 0.7229\n",
            "Epoch 12: val_loss did not improve from 1.19379\n",
            "361/361 [==============================] - 5s 13ms/step - loss: 0.6490 - accuracy: 0.7229 - val_loss: 1.3613 - val_accuracy: 0.5100\n",
            "Epoch 13/20\n",
            "357/361 [============================>.] - ETA: 0s - loss: 0.6105 - accuracy: 0.7386\n",
            "Epoch 13: val_loss did not improve from 1.19379\n",
            "361/361 [==============================] - 6s 16ms/step - loss: 0.6124 - accuracy: 0.7378 - val_loss: 1.5184 - val_accuracy: 0.4913\n",
            "Epoch 14/20\n",
            "357/361 [============================>.] - ETA: 0s - loss: 0.5758 - accuracy: 0.7502\n",
            "Epoch 14: val_loss did not improve from 1.19379\n",
            "Restoring model weights from the end of the best epoch: 9.\n",
            "361/361 [==============================] - 5s 13ms/step - loss: 0.5768 - accuracy: 0.7500 - val_loss: 1.5939 - val_accuracy: 0.4972\n",
            "Epoch 14: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_3.evaluate(test_dataset)\n",
        "model_3_loaded = tf.keras.models.load_model(\"saved_models/nlp_model_3\")\n",
        "model_3_preds = model_3_loaded.predict(test_dataset)\n",
        "model_3_results = calculate_results(test_labels, tf.argmax(model_3_preds, axis=1))\n",
        "model_results_dataset['model_3'] = model_3_results\n",
        "model_3_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kUhXhWCJp-xn",
        "outputId": "ee9c8c32-1954-494e-a707-2bc23ebd08eb"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "91/91 [==============================] - 1s 7ms/step - loss: 1.1938 - accuracy: 0.5267\n",
            "91/91 [==============================] - 1s 7ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 7.375346260387812,\n",
              " 'precision': 0.05157344286420999,\n",
              " 'recall': 0.07375346260387812,\n",
              " 'f1_score': 0.0548008170186416}"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()"
      ],
      "metadata": {
        "id": "sh_1R-aJrTVG"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "model_4_embedding = layers.Embedding(input_dim=10000, output_dim=128, embeddings_initializer=\"uniform\", input_length=output_seq_length, name=\"embedding_4\")\n",
        "\n",
        "inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
        "x = tv_layer(inputs)\n",
        "x = model_4_embedding(x)\n",
        "x = layers.LSTM(64, return_sequences=True)(x)\n",
        "x = layers.GRU(64)(x)\n",
        "x = layers.Dense(64, activation='relu')(x)\n",
        "output = layers.Dense(NUM_CLASSES, activation='softmax')(x)\n",
        "\n",
        "model_4 = tf.keras.Model(inputs, output, name=\"nlp_model_4\")\n",
        "model_4.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "maHEOkKSrrzw",
        "outputId": "d24088c5-e6b1-40c6-a917-ef2f36833c05"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"nlp_model_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization (TextVec  (None, 180)              0         \n",
            " torization)                                                     \n",
            "                                                                 \n",
            " embedding_4 (Embedding)     (None, 180, 128)          1280000   \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 180, 64)           49408     \n",
            "                                                                 \n",
            " gru (GRU)                   (None, 64)                24960     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 5)                 325       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,358,853\n",
            "Trainable params: 1,358,853\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_4.compile(loss=\"categorical_crossentropy\", optimizer=tf.keras.optimizers.Adam(), metrics=[\"accuracy\"])\n",
        "history_4 = model_4.fit(train_dataset, epochs=20, validation_data=test_dataset,callbacks=return_callbacks(model_4.name))\n",
        "     "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MH_rRngSrtj4",
        "outputId": "c7193183-7661-4736-953c-f0e4471934f0"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "359/361 [============================>.] - ETA: 0s - loss: 1.4709 - accuracy: 0.3696\n",
            "Epoch 1: val_loss improved from inf to 1.42708, saving model to saved_models/nlp_model_4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, gru_cell_layer_call_fn, gru_cell_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r361/361 [==============================] - 22s 54ms/step - loss: 1.4711 - accuracy: 0.3694 - val_loss: 1.4271 - val_accuracy: 0.4404\n",
            "Epoch 2/20\n",
            "361/361 [==============================] - ETA: 0s - loss: 1.3288 - accuracy: 0.4562\n",
            "Epoch 2: val_loss improved from 1.42708 to 1.21964, saving model to saved_models/nlp_model_4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, gru_cell_layer_call_fn, gru_cell_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r361/361 [==============================] - 14s 40ms/step - loss: 1.3288 - accuracy: 0.4562 - val_loss: 1.2196 - val_accuracy: 0.5312\n",
            "Epoch 3/20\n",
            "359/361 [============================>.] - ETA: 0s - loss: 1.1058 - accuracy: 0.5575\n",
            "Epoch 3: val_loss improved from 1.21964 to 1.18270, saving model to saved_models/nlp_model_4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, gru_cell_layer_call_fn, gru_cell_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r361/361 [==============================] - 14s 38ms/step - loss: 1.1059 - accuracy: 0.5577 - val_loss: 1.1827 - val_accuracy: 0.5540\n",
            "Epoch 4/20\n",
            "358/361 [============================>.] - ETA: 0s - loss: 0.9876 - accuracy: 0.5987\n",
            "Epoch 4: val_loss did not improve from 1.18270\n",
            "361/361 [==============================] - 8s 21ms/step - loss: 0.9882 - accuracy: 0.5987 - val_loss: 1.2018 - val_accuracy: 0.5492\n",
            "Epoch 5/20\n",
            "359/361 [============================>.] - ETA: 0s - loss: 0.8707 - accuracy: 0.6395\n",
            "Epoch 5: val_loss improved from 1.18270 to 1.16768, saving model to saved_models/nlp_model_4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, gru_cell_layer_call_fn, gru_cell_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r361/361 [==============================] - 16s 45ms/step - loss: 0.8715 - accuracy: 0.6395 - val_loss: 1.1677 - val_accuracy: 0.5509\n",
            "Epoch 6/20\n",
            "359/361 [============================>.] - ETA: 0s - loss: 0.7811 - accuracy: 0.6737\n",
            "Epoch 6: val_loss did not improve from 1.16768\n",
            "361/361 [==============================] - 7s 19ms/step - loss: 0.7819 - accuracy: 0.6736 - val_loss: 1.1867 - val_accuracy: 0.5429\n",
            "Epoch 7/20\n",
            "361/361 [==============================] - ETA: 0s - loss: 0.7216 - accuracy: 0.7007\n",
            "Epoch 7: val_loss did not improve from 1.16768\n",
            "361/361 [==============================] - 8s 21ms/step - loss: 0.7216 - accuracy: 0.7007 - val_loss: 1.1989 - val_accuracy: 0.5343\n",
            "Epoch 8/20\n",
            "359/361 [============================>.] - ETA: 0s - loss: 0.6617 - accuracy: 0.7305\n",
            "Epoch 8: val_loss did not improve from 1.16768\n",
            "361/361 [==============================] - 7s 21ms/step - loss: 0.6626 - accuracy: 0.7306 - val_loss: 1.2751 - val_accuracy: 0.5256\n",
            "Epoch 9/20\n",
            "360/361 [============================>.] - ETA: 0s - loss: 0.6206 - accuracy: 0.7497\n",
            "Epoch 9: val_loss did not improve from 1.16768\n",
            "361/361 [==============================] - 7s 20ms/step - loss: 0.6210 - accuracy: 0.7497 - val_loss: 1.4350 - val_accuracy: 0.5187\n",
            "Epoch 10/20\n",
            "361/361 [==============================] - ETA: 0s - loss: 0.5847 - accuracy: 0.7615\n",
            "Epoch 10: val_loss did not improve from 1.16768\n",
            "Restoring model weights from the end of the best epoch: 5.\n",
            "361/361 [==============================] - 9s 25ms/step - loss: 0.5847 - accuracy: 0.7615 - val_loss: 1.5538 - val_accuracy: 0.5152\n",
            "Epoch 10: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_4.evaluate(test_dataset)\n",
        "model_4_loaded = tf.keras.models.load_model(\"saved_models/nlp_model_4\")\n",
        "model_4_preds = model_4_loaded.predict(test_dataset)\n",
        "model_4_results = calculate_results(test_labels, tf.argmax(model_4_preds, axis=1))\n",
        "model_results_dataset['model_4'] = model_4_results\n",
        "model_4_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MR2dl6RqrwMf",
        "outputId": "85aadf9d-33de-4b74-d665-eed559aec2b4"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "91/91 [==============================] - 1s 11ms/step - loss: 1.1677 - accuracy: 0.5509\n",
            "91/91 [==============================] - 2s 9ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 8.067867036011082,\n",
              " 'precision': 0.04965719983612757,\n",
              " 'recall': 0.08067867036011081,\n",
              " 'f1_score': 0.05773820398490547}"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()"
      ],
      "metadata": {
        "id": "9K4IN2Dlr1Xy"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "model_5_embedding = layers.Embedding(input_dim=10000, output_dim=128, embeddings_initializer=\"uniform\", input_length=output_seq_length, name=\"embedding_5\")\n",
        "\n",
        "inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
        "x = tv_layer(inputs)\n",
        "x = model_5_embedding(x)\n",
        "x = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(x)\n",
        "x = layers.Bidirectional(layers.GRU(64))(x)\n",
        "x = layers.Dense(64, activation='relu')(x)\n",
        "output = layers.Dense(NUM_CLASSES, activation='softmax')(x)\n",
        "\n",
        "model_5 = tf.keras.Model(inputs, output, name=\"nlp_model_5\")\n",
        "model_5.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qxr_K-pyr3Yc",
        "outputId": "2181aea3-bf40-47e4-c659-450c2997f1c8"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"nlp_model_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization (TextVec  (None, 180)              0         \n",
            " torization)                                                     \n",
            "                                                                 \n",
            " embedding_5 (Embedding)     (None, 180, 128)          1280000   \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 180, 128)         98816     \n",
            " l)                                                              \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirectio  (None, 128)              74496     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 5)                 325       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,461,893\n",
            "Trainable params: 1,461,893\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_5.compile(loss=\"categorical_crossentropy\", optimizer=tf.keras.optimizers.Adam(), metrics=[\"accuracy\"])\n",
        "history_5 = model_5.fit(train_dataset, epochs=20, validation_data=test_dataset,callbacks=return_callbacks(model_5.name))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ac_WdhfSr5HK",
        "outputId": "ce400496-134c-4e92-a052-4a08a33f7170"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "360/361 [============================>.] - ETA: 0s - loss: 1.2209 - accuracy: 0.4895\n",
            "Epoch 1: val_loss improved from inf to 1.05502, saving model to saved_models/nlp_model_5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, gru_cell_1_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r361/361 [==============================] - 39s 94ms/step - loss: 1.2207 - accuracy: 0.4899 - val_loss: 1.0550 - val_accuracy: 0.5738\n",
            "Epoch 2/20\n",
            "361/361 [==============================] - ETA: 0s - loss: 0.9162 - accuracy: 0.6276\n",
            "Epoch 2: val_loss did not improve from 1.05502\n",
            "361/361 [==============================] - 13s 35ms/step - loss: 0.9162 - accuracy: 0.6276 - val_loss: 1.0666 - val_accuracy: 0.5699\n",
            "Epoch 3/20\n",
            "361/361 [==============================] - ETA: 0s - loss: 0.7665 - accuracy: 0.6944\n",
            "Epoch 3: val_loss did not improve from 1.05502\n",
            "361/361 [==============================] - 12s 34ms/step - loss: 0.7665 - accuracy: 0.6944 - val_loss: 1.1442 - val_accuracy: 0.5606\n",
            "Epoch 4/20\n",
            "361/361 [==============================] - ETA: 0s - loss: 0.6779 - accuracy: 0.7268\n",
            "Epoch 4: val_loss did not improve from 1.05502\n",
            "361/361 [==============================] - 12s 33ms/step - loss: 0.6779 - accuracy: 0.7268 - val_loss: 1.2066 - val_accuracy: 0.5488\n",
            "Epoch 5/20\n",
            "361/361 [==============================] - ETA: 0s - loss: 0.6058 - accuracy: 0.7531\n",
            "Epoch 5: val_loss did not improve from 1.05502\n",
            "361/361 [==============================] - 12s 34ms/step - loss: 0.6058 - accuracy: 0.7531 - val_loss: 1.3933 - val_accuracy: 0.5291\n",
            "Epoch 6/20\n",
            "360/361 [============================>.] - ETA: 0s - loss: 0.5633 - accuracy: 0.7640\n",
            "Epoch 6: val_loss did not improve from 1.05502\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "361/361 [==============================] - 12s 34ms/step - loss: 0.5639 - accuracy: 0.7636 - val_loss: 1.6387 - val_accuracy: 0.5069\n",
            "Epoch 6: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_5.evaluate(test_dataset)\n",
        "model_5_loaded = tf.keras.models.load_model(\"saved_models/nlp_model_5\")\n",
        "model_5_preds = model_5_loaded.predict(test_dataset)\n",
        "model_5_results = calculate_results(test_labels, tf.argmax(model_5_preds, axis=1))\n",
        "model_results_dataset['model_5'] = model_5_results\n",
        "model_5_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0KI2wkGvr9Kc",
        "outputId": "119789a6-578b-413e-be45-4a7516a2d051"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "91/91 [==============================] - 1s 15ms/step - loss: 1.0550 - accuracy: 0.5738\n",
            "91/91 [==============================] - 2s 15ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 6.752077562326869,\n",
              " 'precision': 0.05384783151965126,\n",
              " 'recall': 0.06752077562326869,\n",
              " 'f1_score': 0.049941019941433795}"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "model_6_embedding = layers.Embedding(input_dim=10000, output_dim=128, embeddings_initializer=\"uniform\", input_length=output_seq_length, name=\"embedding_6\")\n",
        "\n",
        "# Create 1D convolutional model to process sequences\n",
        "inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
        "text_vectors = tv_layer(inputs) # vectorize text inputs\n",
        "token_embeddings = model_6_embedding(text_vectors) # create embedding\n",
        "x = layers.Conv1D(64, kernel_size=5, padding=\"same\", activation=\"relu\")(token_embeddings)\n",
        "x = layers.GlobalAveragePooling1D()(x) # condense the output of our feature vector\n",
        "outputs = layers.Dense(NUM_CLASSES, activation=\"softmax\")(x)\n",
        "model_6 = tf.keras.Model(inputs, outputs, name=\"nlp_model_6\")\n",
        "\n",
        "# Compile\n",
        "model_6.compile(loss=\"categorical_crossentropy\", # if your labels are integer form (not one hot) use sparse_categorical_crossentropy\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "history_6 = model_6.fit(train_dataset, epochs=20, validation_data=test_dataset,callbacks=return_callbacks(model_6.name))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lAvztDt0sBSf",
        "outputId": "74638a04-ddc3-4c73-8930-a8b83be85e89"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "358/361 [============================>.] - ETA: 0s - loss: 1.2530 - accuracy: 0.4787\n",
            "Epoch 1: val_loss improved from inf to 1.06569, saving model to saved_models/nlp_model_6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r361/361 [==============================] - 8s 10ms/step - loss: 1.2517 - accuracy: 0.4790 - val_loss: 1.0657 - val_accuracy: 0.5308\n",
            "Epoch 2/20\n",
            "360/361 [============================>.] - ETA: 0s - loss: 0.8829 - accuracy: 0.6273\n",
            "Epoch 2: val_loss improved from 1.06569 to 1.04618, saving model to saved_models/nlp_model_6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r361/361 [==============================] - 3s 9ms/step - loss: 0.8829 - accuracy: 0.6272 - val_loss: 1.0462 - val_accuracy: 0.5530\n",
            "Epoch 3/20\n",
            "355/361 [============================>.] - ETA: 0s - loss: 0.7228 - accuracy: 0.6863\n",
            "Epoch 3: val_loss did not improve from 1.04618\n",
            "361/361 [==============================] - 3s 7ms/step - loss: 0.7235 - accuracy: 0.6855 - val_loss: 1.1438 - val_accuracy: 0.5287\n",
            "Epoch 4/20\n",
            "355/361 [============================>.] - ETA: 0s - loss: 0.6315 - accuracy: 0.7064\n",
            "Epoch 4: val_loss did not improve from 1.04618\n",
            "361/361 [==============================] - 2s 7ms/step - loss: 0.6327 - accuracy: 0.7057 - val_loss: 1.2646 - val_accuracy: 0.5066\n",
            "Epoch 5/20\n",
            "352/361 [============================>.] - ETA: 0s - loss: 0.5752 - accuracy: 0.7139\n",
            "Epoch 5: val_loss did not improve from 1.04618\n",
            "361/361 [==============================] - 2s 7ms/step - loss: 0.5768 - accuracy: 0.7126 - val_loss: 1.3758 - val_accuracy: 0.4927\n",
            "Epoch 6/20\n",
            "361/361 [==============================] - ETA: 0s - loss: 0.5396 - accuracy: 0.7142\n",
            "Epoch 6: val_loss did not improve from 1.04618\n",
            "361/361 [==============================] - 4s 10ms/step - loss: 0.5396 - accuracy: 0.7142 - val_loss: 1.4684 - val_accuracy: 0.4823\n",
            "Epoch 7/20\n",
            "357/361 [============================>.] - ETA: 0s - loss: 0.5117 - accuracy: 0.7182\n",
            "Epoch 7: val_loss did not improve from 1.04618\n",
            "Restoring model weights from the end of the best epoch: 2.\n",
            "361/361 [==============================] - 3s 7ms/step - loss: 0.5131 - accuracy: 0.7172 - val_loss: 1.5403 - val_accuracy: 0.4740\n",
            "Epoch 7: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_6.evaluate(test_dataset)\n",
        "model_6_loaded = tf.keras.models.load_model(\"saved_models/nlp_model_6\")\n",
        "model_6_preds = model_6_loaded.predict(test_dataset)\n",
        "model_6_results = calculate_results(test_labels, tf.argmax(model_6_preds, axis=1))\n",
        "model_results_dataset['model_6'] = model_6_results\n",
        "model_6_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JYMA-sJksG3J",
        "outputId": "81fd8a86-6de5-4797-ae29-4e341e4604c8"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "91/91 [==============================] - 0s 4ms/step - loss: 1.0462 - accuracy: 0.5530\n",
            "91/91 [==============================] - 0s 3ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 9.764542936288088,\n",
              " 'precision': 0.06707984082798316,\n",
              " 'recall': 0.09764542936288088,\n",
              " 'f1_score': 0.07142276020748689}"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "import tensorflow_hub as hub\n",
        "tf_hub_embedding_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
        "                                        trainable=False,\n",
        "                                        name=\"universal_sentence_encoder\")\n",
        "\n",
        "model_7 = tf.keras.Sequential([\n",
        "  layers.Input(shape=[], dtype=tf.string),\n",
        "  tf_hub_embedding_layer, # take in sentences and then encode them into an embedding\n",
        "  layers.Dense(128, activation=\"relu\"),\n",
        "  layers.Dense(NUM_CLASSES, activation=\"softmax\")\n",
        "], name=\"nlp_model_7\")\n",
        "\n",
        "model_7.summary()\n",
        "\n",
        "model_7.compile(loss=\"categorical_crossentropy\", # if your labels are integer form (not one hot) use sparse_categorical_crossentropy\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "history_7 = model_7.fit(train_dataset, epochs=20, validation_data=test_dataset,callbacks=return_callbacks(model_7.name))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nTFCAZVUsKMg",
        "outputId": "e8e4c81f-9e6a-4e4e-a53b-13a1baaa4da9"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"nlp_model_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " universal_sentence_encoder   (None, 512)              256797824 \n",
            " (KerasLayer)                                                    \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               65664     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 256,864,133\n",
            "Trainable params: 66,309\n",
            "Non-trainable params: 256,797,824\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "361/361 [==============================] - ETA: 0s - loss: 1.1180 - accuracy: 0.5399\n",
            "Epoch 1: val_loss improved from inf to 1.01256, saving model to saved_models/nlp_model_7\n",
            "361/361 [==============================] - 24s 56ms/step - loss: 1.1180 - accuracy: 0.5399 - val_loss: 1.0126 - val_accuracy: 0.5751\n",
            "Epoch 2/20\n",
            "359/361 [============================>.] - ETA: 0s - loss: 0.9763 - accuracy: 0.5917\n",
            "Epoch 2: val_loss improved from 1.01256 to 0.99435, saving model to saved_models/nlp_model_7\n",
            "361/361 [==============================] - 19s 52ms/step - loss: 0.9772 - accuracy: 0.5917 - val_loss: 0.9944 - val_accuracy: 0.5873\n",
            "Epoch 3/20\n",
            "361/361 [==============================] - ETA: 0s - loss: 0.9496 - accuracy: 0.6023\n",
            "Epoch 3: val_loss improved from 0.99435 to 0.98825, saving model to saved_models/nlp_model_7\n",
            "361/361 [==============================] - 18s 51ms/step - loss: 0.9496 - accuracy: 0.6023 - val_loss: 0.9883 - val_accuracy: 0.5886\n",
            "Epoch 4/20\n",
            "361/361 [==============================] - ETA: 0s - loss: 0.9306 - accuracy: 0.6117\n",
            "Epoch 4: val_loss improved from 0.98825 to 0.98647, saving model to saved_models/nlp_model_7\n",
            "361/361 [==============================] - 20s 54ms/step - loss: 0.9306 - accuracy: 0.6117 - val_loss: 0.9865 - val_accuracy: 0.5931\n",
            "Epoch 5/20\n",
            "360/361 [============================>.] - ETA: 0s - loss: 0.9149 - accuracy: 0.6173\n",
            "Epoch 5: val_loss did not improve from 0.98647\n",
            "361/361 [==============================] - 10s 29ms/step - loss: 0.9153 - accuracy: 0.6175 - val_loss: 0.9865 - val_accuracy: 0.5945\n",
            "Epoch 6/20\n",
            "359/361 [============================>.] - ETA: 0s - loss: 0.9013 - accuracy: 0.6235\n",
            "Epoch 6: val_loss did not improve from 0.98647\n",
            "361/361 [==============================] - 10s 28ms/step - loss: 0.9020 - accuracy: 0.6236 - val_loss: 0.9881 - val_accuracy: 0.5925\n",
            "Epoch 7/20\n",
            "359/361 [============================>.] - ETA: 0s - loss: 0.8889 - accuracy: 0.6289\n",
            "Epoch 7: val_loss did not improve from 0.98647\n",
            "361/361 [==============================] - 10s 29ms/step - loss: 0.8895 - accuracy: 0.6289 - val_loss: 0.9899 - val_accuracy: 0.5904\n",
            "Epoch 8/20\n",
            "361/361 [==============================] - ETA: 0s - loss: 0.8779 - accuracy: 0.6324\n",
            "Epoch 8: val_loss did not improve from 0.98647\n",
            "361/361 [==============================] - 10s 28ms/step - loss: 0.8779 - accuracy: 0.6324 - val_loss: 0.9928 - val_accuracy: 0.5890\n",
            "Epoch 9/20\n",
            "360/361 [============================>.] - ETA: 0s - loss: 0.8662 - accuracy: 0.6377\n",
            "Epoch 9: val_loss did not improve from 0.98647\n",
            "Restoring model weights from the end of the best epoch: 4.\n",
            "361/361 [==============================] - 10s 28ms/step - loss: 0.8666 - accuracy: 0.6378 - val_loss: 0.9959 - val_accuracy: 0.5886\n",
            "Epoch 9: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_7.evaluate(test_dataset)\n",
        "model_7_loaded = tf.keras.models.load_model(\"saved_models/nlp_model_7\")\n",
        "model_7_preds = model_7_loaded.predict(test_dataset)\n",
        "model_7_results = calculate_results(test_labels, tf.argmax(model_7_preds, axis=1))\n",
        "model_results_dataset['model_7'] = model_7_results\n",
        "model_7_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zBwsiSrjsMjE",
        "outputId": "f85b45f7-0572-4c4b-c02e-c63fdb2a749f"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "91/91 [==============================] - 3s 30ms/step - loss: 0.9865 - accuracy: 0.5931\n",
            "91/91 [==============================] - 2s 21ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 7.756232686980609,\n",
              " 'precision': 0.05633940023524356,\n",
              " 'recall': 0.07756232686980609,\n",
              " 'f1_score': 0.06001645960179962}"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()"
      ],
      "metadata": {
        "id": "LG6Wvdf2sQCU"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make function to split sentences into characters\n",
        "def split_chars(text):\n",
        "  return \" \".join(list(text))\n",
        "\n",
        "# Split sequence-level data splits into character-level data splits\n",
        "train_chars = [split_chars(sentence) for sentence in train_data]\n",
        "test_chars = [split_chars(sentence) for sentence in test_data]\n",
        "print(train_chars[0])\n",
        "char_lens = [len(sentence) for sentence in train_data]\n",
        "mean_char_len = np.mean(char_lens)\n",
        "mean_char_len\n",
        "output_seq_char_len = int(np.percentile(char_lens, 95))\n",
        "output_seq_char_len"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U4tgC6O1tqSa",
        "outputId": "5160562c-20dd-468f-ea84-ed59965a087b"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "T h e   u n i q u e   a s p e c t s   o f   a c u t e   p r o m y e l o c y t i c   l e u k e m i a .   A c u t e   p r o m y e l o c y t i c   l e u k e m i a   ( A P L )   a c c o u n t s   f o r   a p p r o x i m a t e l y   1 0 %   o f   c a s e s   o f   a c u t e   m y e l o i d   l e u k e m i a   ( A M L ) .   D i s t i n c t i v e   f e a t u r e s   o f   t h i s   d i s o r d e r   a t   t h e   t i m e   o f   d i a g n o s i s   i n c l u d e   l e u k o p e n i a   c o e x i s t i n g   w i t h   a   m a r r o w   r e p l a c e d   w i t h   g r a n u l a t e d   d y s p l a s t i c   p r o m y e l o c y t e s ,   d i s s e m i n a t e d   i n t r a v a s c u l a r   c o a g u l o p a t h y ,   l a c k   o f   I a   ( H L A - D R )   a n t i g e n   e x p r e s s i o n ,   a n d   t r a n s l o c a t i o n   b e t w e e n   t h e   l o n g   a r m s   o f   c h r o m o s o m e s   1 5   a n d   1 7   ( t [ 1 5 ; 1 7 ] ) .   H e p a r i n   i s   w i d e l y   b u t   n o t   u n i v e r s a l l y   u s e d   t o   i n t e r f e r e   w i t h   t h e   c o a g u l o p a t h y   d u r i n g   t h e   i n i t i a l   p h a s e s   o f   t r e a t m e n t .   S e r i a l   b o n e   m a r r o w   e x a m i n a t i o n s   d u r i n g   t h e   i n d u c t i o n   p e r i o d   d e m o n s t r a t e   t h e   a c h i e v e m e n t   o f   r e m i s s i o n   d e s p i t e   t h e   p e r s i s t e n c e   o f   m a l i g n a n t - a p p e a r i n g   p r o m y e l o c y t e s .   P a t i e n t s   w i t h   A P L   a r e   g e n e r a l l y   y o u n g e r   t h a n   t h o s e   w i t h   o t h e r   s u b t y p e s   o f   A M L ,   h a v e   a   7 0 %   t o   8 0 %   l i k e l i h o o d   o f   e n t e r i n g   r e m i s s i o n ,   a n d   a r e   t h o u g h t   t o   h a v e   a   m o r e   f a v o r a b l e   p r o g n o s i s   t h a n   o t h e r   i n d i v i d u a l s   w i t h   A M L .   R e m i s s i o n   m a y   b e   a c h i e v e d   w i t h   a   c o n v e n t i o n a l   a n t h r a c y c l i n e - c y t a r a b i n e   c o m b i n a t i o n ,   a n t h r a c y c l i n e   a l o n e ,   o r ,   a p p a r e n t l y ,   a l l - t r a n s   r e t i n o i c   a c i d .   G e n e s   p o t e n t i a l l y   i m p o r t a n t   i n   m y e l o i d   d i f f e r e n t i a t i o n   s u c h   a s   g r a n u l o c y t e   c o l o n y - s t i m u l a t i n g   f a c t o r   ( G - C S F )   a n d   m y e l o p e r o x i d a s e   a r e   l o c a t e d   c l o s e   t o   t h e   b r e a k p o i n t   i n   t h e   t ( 1 5 ; 1 7 )   b u t   h a v e   n o t   b e e n   c o n c l u s i v e l y   s h o w n   t o   b e   r e a r r a n g e d   i n   t h e   t r a n s l o c a t i o n .   A   b e t t e r   u n d e r s t a n d i n g   o f   t h e   u n i q u e   a s p e c t s   o f   A P L   m a y   w e l l   s h e d   l i g h t   o n   t h e   p a t h o g e n e t i c   p r o c e s s e s   o f   A M L .   \n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2054"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "alphabet = string.ascii_lowercase + string.digits + string.punctuation\n",
        "alphabet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "47TkeLtLtr1s",
        "outputId": "4903eca0-dc45-40bc-ff41-eaa4655a7608"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'abcdefghijklmnopqrstuvwxyz0123456789!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create char-level token vectorizer instance\n",
        "NUM_CHAR_TOKENS = len(alphabet) + 2 # num characters in alphabet + space + OOV token\n",
        "char_vectorizer = TextVectorization(max_tokens=NUM_CHAR_TOKENS,  \n",
        "                                    output_sequence_length=output_seq_char_len,\n",
        "                                    standardize=\"lower_and_strip_punctuation\",\n",
        "                                    name=\"char_vectorizer\")\n",
        "\n",
        "# Adapt character vectorizer to training characters\n",
        "char_vectorizer.adapt(train_chars)"
      ],
      "metadata": {
        "id": "rKhrxHPHtu7A"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create char embedding layer\n",
        "char_embed = layers.Embedding(input_dim=NUM_CHAR_TOKENS, # number of different characters\n",
        "                              output_dim=25, # embedding dimension of each character (same as Figure 1 in https://arxiv.org/pdf/1612.05251.pdf)\n",
        "                              mask_zero=False, # don't use masks (this messes up model_5 if set to True)\n",
        "                              name=\"char_embed\")"
      ],
      "metadata": {
        "id": "FtCz5hMYtwjT"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make Conv1D on chars only\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
        "char_vectors = char_vectorizer(inputs)\n",
        "char_embeddings = char_embed(char_vectors)\n",
        "x = layers.Conv1D(64, kernel_size=5, padding=\"same\", activation=\"relu\")(char_embeddings)\n",
        "x = layers.GlobalMaxPool1D()(x)\n",
        "outputs = layers.Dense(NUM_CLASSES, activation=\"softmax\")(x)\n",
        "model_8 = tf.keras.Model(inputs=inputs,\n",
        "                         outputs=outputs,\n",
        "                         name=\"nlp_model_8\")\n",
        "\n",
        "# Compile model\n",
        "model_8.compile(loss=\"categorical_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "0BSrdfL9tyHf"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_char_dataset = tf.data.Dataset.from_tensor_slices((train_chars, train_labels_one_hot)).batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "val_char_dataset = tf.data.Dataset.from_tensor_slices((test_chars, test_labels_one_hot)).batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "train_char_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-sQz6k-tz4j",
        "outputId": "880ebdf9-6612-4704-bd79-72a92aeebbba"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PrefetchDataset element_spec=(TensorSpec(shape=(None,), dtype=tf.string, name=None), TensorSpec(shape=(None, 5), dtype=tf.float64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history_8 = model_8.fit(train_char_dataset, epochs=20, validation_data=val_char_dataset,callbacks=return_callbacks(model_8.name))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FgkF-Z23t1sz",
        "outputId": "328012bd-598c-4d42-ddb3-514f47e4a39b"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "359/361 [============================>.] - ETA: 0s - loss: 1.4702 - accuracy: 0.3716\n",
            "Epoch 1: val_loss improved from inf to 1.34008, saving model to saved_models/nlp_model_8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r361/361 [==============================] - 6s 15ms/step - loss: 1.4699 - accuracy: 0.3720 - val_loss: 1.3401 - val_accuracy: 0.4605\n",
            "Epoch 2/20\n",
            "360/361 [============================>.] - ETA: 0s - loss: 1.2294 - accuracy: 0.5047\n",
            "Epoch 2: val_loss improved from 1.34008 to 1.18783, saving model to saved_models/nlp_model_8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r361/361 [==============================] - 7s 18ms/step - loss: 1.2292 - accuracy: 0.5045 - val_loss: 1.1878 - val_accuracy: 0.5253\n",
            "Epoch 3/20\n",
            "357/361 [============================>.] - ETA: 0s - loss: 1.1435 - accuracy: 0.5299\n",
            "Epoch 3: val_loss improved from 1.18783 to 1.14462, saving model to saved_models/nlp_model_8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r361/361 [==============================] - 6s 16ms/step - loss: 1.1438 - accuracy: 0.5293 - val_loss: 1.1446 - val_accuracy: 0.5367\n",
            "Epoch 4/20\n",
            "357/361 [============================>.] - ETA: 0s - loss: 1.0992 - accuracy: 0.5461\n",
            "Epoch 4: val_loss improved from 1.14462 to 1.11851, saving model to saved_models/nlp_model_8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r361/361 [==============================] - 5s 14ms/step - loss: 1.0996 - accuracy: 0.5456 - val_loss: 1.1185 - val_accuracy: 0.5443\n",
            "Epoch 5/20\n",
            "361/361 [==============================] - ETA: 0s - loss: 1.0669 - accuracy: 0.5597\n",
            "Epoch 5: val_loss improved from 1.11851 to 1.09924, saving model to saved_models/nlp_model_8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r361/361 [==============================] - 5s 15ms/step - loss: 1.0669 - accuracy: 0.5597 - val_loss: 1.0992 - val_accuracy: 0.5523\n",
            "Epoch 6/20\n",
            "358/361 [============================>.] - ETA: 0s - loss: 1.0396 - accuracy: 0.5704\n",
            "Epoch 6: val_loss improved from 1.09924 to 1.08501, saving model to saved_models/nlp_model_8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r361/361 [==============================] - 6s 15ms/step - loss: 1.0400 - accuracy: 0.5706 - val_loss: 1.0850 - val_accuracy: 0.5575\n",
            "Epoch 7/20\n",
            "360/361 [============================>.] - ETA: 0s - loss: 1.0171 - accuracy: 0.5791\n",
            "Epoch 7: val_loss improved from 1.08501 to 1.07601, saving model to saved_models/nlp_model_8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r361/361 [==============================] - 5s 15ms/step - loss: 1.0172 - accuracy: 0.5793 - val_loss: 1.0760 - val_accuracy: 0.5575\n",
            "Epoch 8/20\n",
            "361/361 [==============================] - ETA: 0s - loss: 0.9991 - accuracy: 0.5880\n",
            "Epoch 8: val_loss improved from 1.07601 to 1.07053, saving model to saved_models/nlp_model_8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r361/361 [==============================] - 6s 15ms/step - loss: 0.9991 - accuracy: 0.5880 - val_loss: 1.0705 - val_accuracy: 0.5630\n",
            "Epoch 9/20\n",
            "356/361 [============================>.] - ETA: 0s - loss: 0.9838 - accuracy: 0.5954\n",
            "Epoch 9: val_loss improved from 1.07053 to 1.06644, saving model to saved_models/nlp_model_8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r361/361 [==============================] - 5s 14ms/step - loss: 0.9844 - accuracy: 0.5952 - val_loss: 1.0664 - val_accuracy: 0.5689\n",
            "Epoch 10/20\n",
            "359/361 [============================>.] - ETA: 0s - loss: 0.9720 - accuracy: 0.5994\n",
            "Epoch 10: val_loss improved from 1.06644 to 1.06516, saving model to saved_models/nlp_model_8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r361/361 [==============================] - 6s 16ms/step - loss: 0.9721 - accuracy: 0.5996 - val_loss: 1.0652 - val_accuracy: 0.5654\n",
            "Epoch 11/20\n",
            "356/361 [============================>.] - ETA: 0s - loss: 0.9604 - accuracy: 0.6058\n",
            "Epoch 11: val_loss improved from 1.06516 to 1.06448, saving model to saved_models/nlp_model_8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r361/361 [==============================] - 7s 19ms/step - loss: 0.9609 - accuracy: 0.6055 - val_loss: 1.0645 - val_accuracy: 0.5627\n",
            "Epoch 12/20\n",
            "358/361 [============================>.] - ETA: 0s - loss: 0.9508 - accuracy: 0.6114\n",
            "Epoch 12: val_loss improved from 1.06448 to 1.06390, saving model to saved_models/nlp_model_8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r361/361 [==============================] - 5s 14ms/step - loss: 0.9512 - accuracy: 0.6113 - val_loss: 1.0639 - val_accuracy: 0.5613\n",
            "Epoch 13/20\n",
            "359/361 [============================>.] - ETA: 0s - loss: 0.9422 - accuracy: 0.6147\n",
            "Epoch 13: val_loss did not improve from 1.06390\n",
            "361/361 [==============================] - 5s 14ms/step - loss: 0.9423 - accuracy: 0.6152 - val_loss: 1.0647 - val_accuracy: 0.5606\n",
            "Epoch 14/20\n",
            "357/361 [============================>.] - ETA: 0s - loss: 0.9339 - accuracy: 0.6168\n",
            "Epoch 14: val_loss did not improve from 1.06390\n",
            "361/361 [==============================] - 4s 12ms/step - loss: 0.9345 - accuracy: 0.6165 - val_loss: 1.0652 - val_accuracy: 0.5613\n",
            "Epoch 15/20\n",
            "359/361 [============================>.] - ETA: 0s - loss: 0.9273 - accuracy: 0.6185\n",
            "Epoch 15: val_loss did not improve from 1.06390\n",
            "361/361 [==============================] - 5s 14ms/step - loss: 0.9274 - accuracy: 0.6188 - val_loss: 1.0659 - val_accuracy: 0.5602\n",
            "Epoch 16/20\n",
            "361/361 [==============================] - ETA: 0s - loss: 0.9214 - accuracy: 0.6203\n",
            "Epoch 16: val_loss did not improve from 1.06390\n",
            "361/361 [==============================] - 5s 14ms/step - loss: 0.9214 - accuracy: 0.6203 - val_loss: 1.0660 - val_accuracy: 0.5599\n",
            "Epoch 17/20\n",
            "358/361 [============================>.] - ETA: 0s - loss: 0.9152 - accuracy: 0.6234\n",
            "Epoch 17: val_loss did not improve from 1.06390\n",
            "Restoring model weights from the end of the best epoch: 12.\n",
            "361/361 [==============================] - 5s 14ms/step - loss: 0.9155 - accuracy: 0.6233 - val_loss: 1.0669 - val_accuracy: 0.5644\n",
            "Epoch 17: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_8.evaluate(test_dataset)\n",
        "model_8_loaded = tf.keras.models.load_model(\"saved_models/nlp_model_8\")\n",
        "model_8_preds = model_8_loaded.predict(test_dataset)\n",
        "model_8_results = calculate_results(test_labels, tf.argmax(model_8_preds, axis=1))\n",
        "model_results_dataset['model_8'] = model_8_results\n",
        "model_8_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7GTYkDgft3cN",
        "outputId": "b9d260e9-9db5-4278-92e9-ef37df139c3f"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "91/91 [==============================] - 1s 6ms/step - loss: 1.6656 - accuracy: 0.2261\n",
            "91/91 [==============================] - 0s 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 4.639889196675901,\n",
              " 'precision': 0.12761786821178037,\n",
              " 'recall': 0.046398891966759004,\n",
              " 'f1_score': 0.0670086467498325}"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()"
      ],
      "metadata": {
        "id": "JKAvPJjot7PP"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Setup token inputs/model\n",
        "token_inputs = layers.Input(shape=[], dtype=tf.string, name=\"token_input\")\n",
        "token_embeddings = tf_hub_embedding_layer(token_inputs)\n",
        "token_output = layers.Dense(128, activation=\"relu\")(token_embeddings)\n",
        "token_model = tf.keras.Model(inputs=token_inputs,\n",
        "                             outputs=token_output)\n",
        "\n",
        "# 2. Setup char inputs/model\n",
        "char_inputs = layers.Input(shape=(1,), dtype=tf.string, name=\"char_input\")\n",
        "char_vectors = char_vectorizer(char_inputs)\n",
        "char_embeddings = char_embed(char_vectors)\n",
        "char_bi_lstm = layers.Bidirectional(layers.LSTM(25))(char_embeddings) # bi-LSTM shown in Figure 1 of https://arxiv.org/pdf/1612.05251.pdf\n",
        "char_model = tf.keras.Model(inputs=char_inputs,\n",
        "                            outputs=char_bi_lstm)\n",
        "\n",
        "# 3. Concatenate token and char inputs (create hybrid token embedding)\n",
        "token_char_concat = layers.Concatenate(name=\"token_char_hybrid\")([token_model.output, \n",
        "                                                                  char_model.output])\n",
        "\n",
        "# 4. Create output layers - addition of dropout discussed in 4.2 of https://arxiv.org/pdf/1612.05251.pdf\n",
        "combined_dropout = layers.Dropout(0.5)(token_char_concat)\n",
        "combined_dense = layers.Dense(200, activation=\"relu\")(combined_dropout) # slightly different to Figure 1 due to different shapes of token/char embedding layers\n",
        "final_dropout = layers.Dropout(0.5)(combined_dense)\n",
        "output_layer = layers.Dense(4, activation=\"softmax\")(final_dropout)\n",
        "\n",
        "# 5. Construct model with char and token inputs\n",
        "model_9 = tf.keras.Model(inputs=[token_model.input, char_model.input],\n",
        "                         outputs=output_layer,\n",
        "                         name=\"nlp_model_9\")"
      ],
      "metadata": {
        "id": "xUc9PcYEt9wz"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile token char model\n",
        "model_9.compile(loss=\"categorical_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(), # section 4.2 of https://arxiv.org/pdf/1612.05251.pdf mentions using SGD but we'll stick with Adam\n",
        "                metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "ArXeO6OluAej"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine chars and tokens into a dataset\n",
        "train_char_token_data = tf.data.Dataset.from_tensor_slices((train_data, train_chars)) # make data\n",
        "train_char_token_labels = tf.data.Dataset.from_tensor_slices(train_labels_one_hot) # make labels\n",
        "train_char_token_dataset = tf.data.Dataset.zip((train_char_token_data, train_char_token_labels)) # combine data and labels\n",
        "\n",
        "# Prefetch and batch train data\n",
        "train_char_token_dataset = train_char_token_dataset.batch(32).prefetch(tf.data.AUTOTUNE) \n",
        "\n",
        "# Repeat same steps validation data\n",
        "val_char_token_data = tf.data.Dataset.from_tensor_slices((test_data, test_chars))\n",
        "val_char_token_labels = tf.data.Dataset.from_tensor_slices(test_labels_one_hot)\n",
        "val_char_token_dataset = tf.data.Dataset.zip((val_char_token_data, val_char_token_labels))\n",
        "val_char_token_dataset = val_char_token_dataset.batch(32).prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "RIa97QfIuCGD"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_9 = model_9.fit(train_char_token_dataset, epochs=20, validation_data=val_char_token_dataset, callbacks=return_callbacks(model_9.name))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 744
        },
        "id": "09q7Ar4tuD2P",
        "outputId": "7a1a1fd4-0aab-4d7f-80b1-2d8a4bad8b0d"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-100-52aa9280dfc8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory_9\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_9\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_char_token_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_char_token_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_9\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 890, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 948, in compute_loss\n        return self.compiled_loss(\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/compile_utils.py\", line 201, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/losses.py\", line 139, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/losses.py\", line 243, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/losses.py\", line 1787, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"/usr/local/lib/python3.8/dist-packages/keras/backend.py\", line 5119, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 5) and (None, 4) are incompatible\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()"
      ],
      "metadata": {
        "id": "TqJkadJpuGGB"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_10_embedding = tf.keras.layers.Embedding(input_dim=10000, output_dim=128, embeddings_initializer=\"uniform\", input_length=output_seq_length, name=\"embedding_6\")\n",
        "\n",
        "inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
        "x = tv_layer(inputs)\n",
        "x = model_10_embedding(x)\n",
        "x = layers.Conv1D(128, 5, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling1D(5)(x)\n",
        "x = layers.Conv1D(128, 5, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling1D(5)(x)\n",
        "x = layers.Conv1D(128, 5, activation=\"relu\")(x)\n",
        "x = layers.GlobalMaxPooling1D()(x)\n",
        "x = layers.Dense(128, activation=\"relu\")(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "preds = layers.Dense(NUM_CLASSES, activation=\"softmax\")(x)\n",
        "model_10 = tf.keras.Model(inputs, preds, name=\"nlp_model_10\")\n",
        "model_10.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dl4M665suKLr",
        "outputId": "c0d687cc-0b8a-4d41-87f7-deb2a466517e"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"nlp_model_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization (TextVec  (None, 180)              0         \n",
            " torization)                                                     \n",
            "                                                                 \n",
            " embedding_6 (Embedding)     (None, 180, 128)          1280000   \n",
            "                                                                 \n",
            " conv1d (Conv1D)             (None, 176, 128)          82048     \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1D  (None, 35, 128)          0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 31, 128)           82048     \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPooling  (None, 6, 128)           0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " conv1d_2 (Conv1D)           (None, 2, 128)            82048     \n",
            "                                                                 \n",
            " global_max_pooling1d (Globa  (None, 128)              0         \n",
            " lMaxPooling1D)                                                  \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               16512     \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,543,301\n",
            "Trainable params: 1,543,301\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_10.compile(loss=\"categorical_crossentropy\", # if your labels are integer form (not one hot) use sparse_categorical_crossentropy\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "history_10 = model_10.fit(train_dataset, epochs=20, validation_data=test_dataset,callbacks=return_callbacks(model_10.name))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PyeG7z8SuL9t",
        "outputId": "0442d6a2-55f4-43fe-a6aa-9972c4178309"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "361/361 [==============================] - ETA: 0s - loss: 1.3993 - accuracy: 0.3961\n",
            "Epoch 1: val_loss improved from inf to 1.17510, saving model to saved_models/nlp_model_10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r361/361 [==============================] - 6s 13ms/step - loss: 1.3993 - accuracy: 0.3961 - val_loss: 1.1751 - val_accuracy: 0.5433\n",
            "Epoch 2/20\n",
            "355/361 [============================>.] - ETA: 0s - loss: 1.0914 - accuracy: 0.5596\n",
            "Epoch 2: val_loss improved from 1.17510 to 1.08626, saving model to saved_models/nlp_model_10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r361/361 [==============================] - 4s 12ms/step - loss: 1.0906 - accuracy: 0.5601 - val_loss: 1.0863 - val_accuracy: 0.5727\n",
            "Epoch 3/20\n",
            "359/361 [============================>.] - ETA: 0s - loss: 0.9135 - accuracy: 0.6254\n",
            "Epoch 3: val_loss did not improve from 1.08626\n",
            "361/361 [==============================] - 3s 8ms/step - loss: 0.9126 - accuracy: 0.6256 - val_loss: 1.0887 - val_accuracy: 0.5976\n",
            "Epoch 4/20\n",
            "355/361 [============================>.] - ETA: 0s - loss: 0.7637 - accuracy: 0.6859\n",
            "Epoch 4: val_loss did not improve from 1.08626\n",
            "361/361 [==============================] - 3s 8ms/step - loss: 0.7627 - accuracy: 0.6868 - val_loss: 1.3499 - val_accuracy: 0.5772\n",
            "Epoch 5/20\n",
            "361/361 [==============================] - ETA: 0s - loss: 0.6927 - accuracy: 0.7129\n",
            "Epoch 5: val_loss did not improve from 1.08626\n",
            "361/361 [==============================] - 3s 8ms/step - loss: 0.6927 - accuracy: 0.7129 - val_loss: 1.7989 - val_accuracy: 0.5557\n",
            "Epoch 6/20\n",
            "357/361 [============================>.] - ETA: 0s - loss: 0.6312 - accuracy: 0.7343\n",
            "Epoch 6: val_loss did not improve from 1.08626\n",
            "361/361 [==============================] - 3s 9ms/step - loss: 0.6308 - accuracy: 0.7347 - val_loss: 1.7815 - val_accuracy: 0.5582\n",
            "Epoch 7/20\n",
            "358/361 [============================>.] - ETA: 0s - loss: 0.6026 - accuracy: 0.7394\n",
            "Epoch 7: val_loss did not improve from 1.08626\n",
            "Restoring model weights from the end of the best epoch: 2.\n",
            "361/361 [==============================] - 3s 8ms/step - loss: 0.6026 - accuracy: 0.7394 - val_loss: 1.9181 - val_accuracy: 0.5461\n",
            "Epoch 7: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_10.evaluate(test_dataset)\n",
        "model_10_loaded = tf.keras.models.load_model(\"saved_models/nlp_model_10\")\n",
        "model_10_preds = model_10_loaded.predict(test_dataset)\n",
        "model_10_results = calculate_results(test_labels, tf.argmax(model_10_preds, axis=1))\n",
        "model_results_dataset['model_10'] = model_10_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J5sTFzU9uN7P",
        "outputId": "f3dc219a-db39-4962-dd26-2b8aef0717fa"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "91/91 [==============================] - 0s 4ms/step - loss: 1.0863 - accuracy: 0.5727\n",
            "91/91 [==============================] - 0s 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe = pd.DataFrame(model_results_dataset).T\n",
        "dataframe['accuracy'] = dataframe['accuracy'].div(100)\n",
        "dataframe"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "ipSCKEM4uQVD",
        "outputId": "61533db4-5130-4ed7-f44e-fe1039c1706e"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          accuracy  precision    recall  f1_score\n",
              "model_0   0.494114   0.536940  0.494114  0.436778\n",
              "model_1   0.088296   0.065261  0.088296  0.067135\n",
              "model_2   0.083795   0.059000  0.083795  0.062594\n",
              "model_3   0.073753   0.051573  0.073753  0.054801\n",
              "model_4   0.080679   0.049657  0.080679  0.057738\n",
              "model_5   0.067521   0.053848  0.067521  0.049941\n",
              "model_6   0.097645   0.067080  0.097645  0.071423\n",
              "model_7   0.077562   0.056339  0.077562  0.060016\n",
              "model_8   0.046399   0.127618  0.046399  0.067009\n",
              "model_10  0.052632   0.053047  0.052632  0.040200"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b46c1962-47ae-4887-87ae-79d67969bae0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accuracy</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>model_0</th>\n",
              "      <td>0.494114</td>\n",
              "      <td>0.536940</td>\n",
              "      <td>0.494114</td>\n",
              "      <td>0.436778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>model_1</th>\n",
              "      <td>0.088296</td>\n",
              "      <td>0.065261</td>\n",
              "      <td>0.088296</td>\n",
              "      <td>0.067135</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>model_2</th>\n",
              "      <td>0.083795</td>\n",
              "      <td>0.059000</td>\n",
              "      <td>0.083795</td>\n",
              "      <td>0.062594</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>model_3</th>\n",
              "      <td>0.073753</td>\n",
              "      <td>0.051573</td>\n",
              "      <td>0.073753</td>\n",
              "      <td>0.054801</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>model_4</th>\n",
              "      <td>0.080679</td>\n",
              "      <td>0.049657</td>\n",
              "      <td>0.080679</td>\n",
              "      <td>0.057738</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>model_5</th>\n",
              "      <td>0.067521</td>\n",
              "      <td>0.053848</td>\n",
              "      <td>0.067521</td>\n",
              "      <td>0.049941</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>model_6</th>\n",
              "      <td>0.097645</td>\n",
              "      <td>0.067080</td>\n",
              "      <td>0.097645</td>\n",
              "      <td>0.071423</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>model_7</th>\n",
              "      <td>0.077562</td>\n",
              "      <td>0.056339</td>\n",
              "      <td>0.077562</td>\n",
              "      <td>0.060016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>model_8</th>\n",
              "      <td>0.046399</td>\n",
              "      <td>0.127618</td>\n",
              "      <td>0.046399</td>\n",
              "      <td>0.067009</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>model_10</th>\n",
              "      <td>0.052632</td>\n",
              "      <td>0.053047</td>\n",
              "      <td>0.052632</td>\n",
              "      <td>0.040200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b46c1962-47ae-4887-87ae-79d67969bae0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b46c1962-47ae-4887-87ae-79d67969bae0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b46c1962-47ae-4887-87ae-79d67969bae0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe.plot.bar()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "uJ9AYbuDuRut",
        "outputId": "6dd5d64c-f5d4-4887-930b-d9effb526d23"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fec194f6610>"
            ]
          },
          "metadata": {},
          "execution_count": 106
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PxuQVIuluTR2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}