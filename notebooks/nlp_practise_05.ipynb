{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prp20/tensorflow_learning/blob/main/notebooks/nlp_practise_05.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "wvFrj6CRfxNg",
        "outputId": "ce947c91-14b6-4768-b2aa-18ae8cbc23f3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.9.2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "tf.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "zfNlCauvf2Nv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72fbcc44-9d71-46d1-b523-95029b089e8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-46b275ab-e0bd-dc54-d6a1-344236775951)\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi -L"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install kaggle"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_JMR_M3cgJ2X",
        "outputId": "457c8dd2-e09f-454b-c891-2d1698c64001"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.8/dist-packages (1.5.12)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.8/dist-packages (from kaggle) (2022.12.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from kaggle) (2.25.1)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.8/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from kaggle) (4.64.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.8/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.8/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.8/dist-packages (from kaggle) (7.0.0)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.8/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->kaggle) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->kaggle) (2.10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p85ZwW-VgOSb",
        "outputId": "de880c8e-0c55-4958-dad1-bb585214c216"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir ~/.kaggle\n",
        "! cp /content/drive/MyDrive/kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "QttSQgFFgQM8"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d kaushiksuresh147/the-social-dilemma-tweets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6boYhLY0gZ-J",
        "outputId": "f46a8da7-d571-44c7-f840-98ee6920fabb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading the-social-dilemma-tweets.zip to /content\n",
            "100% 2.56M/2.56M [00:00<00:00, 4.85MB/s]\n",
            "100% 2.56M/2.56M [00:00<00:00, 4.15MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! unzip /content/the-social-dilemma-tweets.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p4Iq1Ugrgdrh",
        "outputId": "08b9bb3a-b653-43b1-d04a-e22dc4dfe2eb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/the-social-dilemma-tweets.zip\n",
            "  inflating: TheSocialDilemma.csv    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_csv(\"/content/TheSocialDilemma.csv\")"
      ],
      "metadata": {
        "id": "KTmZOpaqgiRF"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 886
        },
        "id": "Qrv8Hyr6golZ",
        "outputId": "b5f95a98-2530-48e2-e78f-da1625fbae6f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                          user_name            user_location  \\\n",
              "0                        Mari Smith    San Diego, California   \n",
              "1                        Mari Smith    San Diego, California   \n",
              "2                       Varun Tyagi               Goa, India   \n",
              "3                      Casey Conway  Sydney, New South Wales   \n",
              "4                    Charlotte Paul               Darlington   \n",
              "...                             ...                      ...   \n",
              "20063                          scp.                      NaN   \n",
              "20064                      Dono6971            United States   \n",
              "20065                   Remi Shores                      NaN   \n",
              "20066  Scott the Great and Terrible                      NaN   \n",
              "20067             Get Outside Media            Telluride, CO   \n",
              "\n",
              "                                        user_description         user_created  \\\n",
              "0      Premier Facebook Marketing Expert | Social Med...  2007-09-11 22:22:51   \n",
              "1      Premier Facebook Marketing Expert | Social Med...  2007-09-11 22:22:51   \n",
              "2      Indian | Tech Solution Artist & Hospitality Ex...  2009-09-06 10:36:01   \n",
              "3      Head of Diversity & Inclusion @RugbyAU | It's ...  2012-12-28 21:45:06   \n",
              "4                              Instagram Charlottejyates  2012-05-28 20:43:08   \n",
              "...                                                  ...                  ...   \n",
              "20063  “Through love, all is possible.” - SJM - See m...  2013-02-19 00:55:12   \n",
              "20064  Father, Husband, and a Dude|| Love Notre Dame ...  2010-01-06 04:08:41   \n",
              "20065  Genderfluid / They/Them/Theirs / Queer Christi...  2012-05-16 23:49:13   \n",
              "20066  I can't recall the taste of food, nor the soun...  2020-03-16 18:20:31   \n",
              "20067  CREATIVE AGENCY | BRAND + CONTENT + DESIGN + P...  2018-07-14 04:44:23   \n",
              "\n",
              "       user_followers  user_friends  user_favourites  user_verified  \\\n",
              "0              579942        288625            11610          False   \n",
              "1              579942        288625            11610          False   \n",
              "2                 257           204              475          False   \n",
              "3               11782          1033            12219           True   \n",
              "4                 278           387             5850          False   \n",
              "...               ...           ...              ...            ...   \n",
              "20063             431           193            32958          False   \n",
              "20064             172            96            50159          False   \n",
              "20065             387           652             7885          False   \n",
              "20066             103            84             2976          False   \n",
              "20067             133           898             1131          False   \n",
              "\n",
              "                      date                                               text  \\\n",
              "0      2020-09-16 20:55:33  @musicmadmarc @SocialDilemma_ @netflix @Facebo...   \n",
              "1      2020-09-16 20:53:17  @musicmadmarc @SocialDilemma_ @netflix @Facebo...   \n",
              "2      2020-09-16 20:51:57  Go watch “The Social Dilemma” on Netflix!\\n\\nI...   \n",
              "3      2020-09-16 20:51:46  I watched #TheSocialDilemma last night. I’m sc...   \n",
              "4      2020-09-16 20:51:11  The problem of me being on my phone most the t...   \n",
              "...                    ...                                                ...   \n",
              "20063  2020-10-09 00:25:53  #TheSocialDilemma yalll.... this shit... we kn...   \n",
              "20064  2020-10-09 00:24:45  Peeps:\\n\\nFind 90 minutes this weekend and wat...   \n",
              "20065  2020-10-09 00:11:42  So you watched #thesocialdilemma, or have been...   \n",
              "20066  2020-10-09 00:10:16  Good social media advice:\\n\\nChoose the thing ...   \n",
              "20067  2020-10-09 00:00:31  Boulder director Jeff Orlowski hopes viewers o...   \n",
              "\n",
              "                   hashtags              source  is_retweet Sentiment  \n",
              "0                       NaN     Twitter Web App       False   Neutral  \n",
              "1                       NaN     Twitter Web App       False   Neutral  \n",
              "2                       NaN  Twitter for iPhone       False  Positive  \n",
              "3      ['TheSocialDilemma']  Twitter for iPhone       False  Negative  \n",
              "4      ['TheSocialDilemma']  Twitter for iPhone       False  Positive  \n",
              "...                     ...                 ...         ...       ...  \n",
              "20063  ['TheSocialDilemma']  Twitter for iPhone       False  Negative  \n",
              "20064                   NaN  Twitter for iPhone       False  Positive  \n",
              "20065  ['thesocialdilemma']     Twitter Web App       False  Negative  \n",
              "20066  ['TheSocialDilemma']     Twitter Web App       False  Positive  \n",
              "20067  ['TheSocialDilemma']      Hootsuite Inc.       False   Neutral  \n",
              "\n",
              "[20068 rows x 14 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-41c2b319-703e-4e94-9ac8-272974eda46c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_name</th>\n",
              "      <th>user_location</th>\n",
              "      <th>user_description</th>\n",
              "      <th>user_created</th>\n",
              "      <th>user_followers</th>\n",
              "      <th>user_friends</th>\n",
              "      <th>user_favourites</th>\n",
              "      <th>user_verified</th>\n",
              "      <th>date</th>\n",
              "      <th>text</th>\n",
              "      <th>hashtags</th>\n",
              "      <th>source</th>\n",
              "      <th>is_retweet</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Mari Smith</td>\n",
              "      <td>San Diego, California</td>\n",
              "      <td>Premier Facebook Marketing Expert | Social Med...</td>\n",
              "      <td>2007-09-11 22:22:51</td>\n",
              "      <td>579942</td>\n",
              "      <td>288625</td>\n",
              "      <td>11610</td>\n",
              "      <td>False</td>\n",
              "      <td>2020-09-16 20:55:33</td>\n",
              "      <td>@musicmadmarc @SocialDilemma_ @netflix @Facebo...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Twitter Web App</td>\n",
              "      <td>False</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Mari Smith</td>\n",
              "      <td>San Diego, California</td>\n",
              "      <td>Premier Facebook Marketing Expert | Social Med...</td>\n",
              "      <td>2007-09-11 22:22:51</td>\n",
              "      <td>579942</td>\n",
              "      <td>288625</td>\n",
              "      <td>11610</td>\n",
              "      <td>False</td>\n",
              "      <td>2020-09-16 20:53:17</td>\n",
              "      <td>@musicmadmarc @SocialDilemma_ @netflix @Facebo...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Twitter Web App</td>\n",
              "      <td>False</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Varun Tyagi</td>\n",
              "      <td>Goa, India</td>\n",
              "      <td>Indian | Tech Solution Artist &amp; Hospitality Ex...</td>\n",
              "      <td>2009-09-06 10:36:01</td>\n",
              "      <td>257</td>\n",
              "      <td>204</td>\n",
              "      <td>475</td>\n",
              "      <td>False</td>\n",
              "      <td>2020-09-16 20:51:57</td>\n",
              "      <td>Go watch “The Social Dilemma” on Netflix!\\n\\nI...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>False</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Casey Conway</td>\n",
              "      <td>Sydney, New South Wales</td>\n",
              "      <td>Head of Diversity &amp; Inclusion @RugbyAU | It's ...</td>\n",
              "      <td>2012-12-28 21:45:06</td>\n",
              "      <td>11782</td>\n",
              "      <td>1033</td>\n",
              "      <td>12219</td>\n",
              "      <td>True</td>\n",
              "      <td>2020-09-16 20:51:46</td>\n",
              "      <td>I watched #TheSocialDilemma last night. I’m sc...</td>\n",
              "      <td>['TheSocialDilemma']</td>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>False</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Charlotte Paul</td>\n",
              "      <td>Darlington</td>\n",
              "      <td>Instagram Charlottejyates</td>\n",
              "      <td>2012-05-28 20:43:08</td>\n",
              "      <td>278</td>\n",
              "      <td>387</td>\n",
              "      <td>5850</td>\n",
              "      <td>False</td>\n",
              "      <td>2020-09-16 20:51:11</td>\n",
              "      <td>The problem of me being on my phone most the t...</td>\n",
              "      <td>['TheSocialDilemma']</td>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>False</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20063</th>\n",
              "      <td>scp.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>“Through love, all is possible.” - SJM - See m...</td>\n",
              "      <td>2013-02-19 00:55:12</td>\n",
              "      <td>431</td>\n",
              "      <td>193</td>\n",
              "      <td>32958</td>\n",
              "      <td>False</td>\n",
              "      <td>2020-10-09 00:25:53</td>\n",
              "      <td>#TheSocialDilemma yalll.... this shit... we kn...</td>\n",
              "      <td>['TheSocialDilemma']</td>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>False</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20064</th>\n",
              "      <td>Dono6971</td>\n",
              "      <td>United States</td>\n",
              "      <td>Father, Husband, and a Dude|| Love Notre Dame ...</td>\n",
              "      <td>2010-01-06 04:08:41</td>\n",
              "      <td>172</td>\n",
              "      <td>96</td>\n",
              "      <td>50159</td>\n",
              "      <td>False</td>\n",
              "      <td>2020-10-09 00:24:45</td>\n",
              "      <td>Peeps:\\n\\nFind 90 minutes this weekend and wat...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>False</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20065</th>\n",
              "      <td>Remi Shores</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Genderfluid / They/Them/Theirs / Queer Christi...</td>\n",
              "      <td>2012-05-16 23:49:13</td>\n",
              "      <td>387</td>\n",
              "      <td>652</td>\n",
              "      <td>7885</td>\n",
              "      <td>False</td>\n",
              "      <td>2020-10-09 00:11:42</td>\n",
              "      <td>So you watched #thesocialdilemma, or have been...</td>\n",
              "      <td>['thesocialdilemma']</td>\n",
              "      <td>Twitter Web App</td>\n",
              "      <td>False</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20066</th>\n",
              "      <td>Scott the Great and Terrible</td>\n",
              "      <td>NaN</td>\n",
              "      <td>I can't recall the taste of food, nor the soun...</td>\n",
              "      <td>2020-03-16 18:20:31</td>\n",
              "      <td>103</td>\n",
              "      <td>84</td>\n",
              "      <td>2976</td>\n",
              "      <td>False</td>\n",
              "      <td>2020-10-09 00:10:16</td>\n",
              "      <td>Good social media advice:\\n\\nChoose the thing ...</td>\n",
              "      <td>['TheSocialDilemma']</td>\n",
              "      <td>Twitter Web App</td>\n",
              "      <td>False</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20067</th>\n",
              "      <td>Get Outside Media</td>\n",
              "      <td>Telluride, CO</td>\n",
              "      <td>CREATIVE AGENCY | BRAND + CONTENT + DESIGN + P...</td>\n",
              "      <td>2018-07-14 04:44:23</td>\n",
              "      <td>133</td>\n",
              "      <td>898</td>\n",
              "      <td>1131</td>\n",
              "      <td>False</td>\n",
              "      <td>2020-10-09 00:00:31</td>\n",
              "      <td>Boulder director Jeff Orlowski hopes viewers o...</td>\n",
              "      <td>['TheSocialDilemma']</td>\n",
              "      <td>Hootsuite Inc.</td>\n",
              "      <td>False</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20068 rows × 14 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-41c2b319-703e-4e94-9ac8-272974eda46c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-41c2b319-703e-4e94-9ac8-272974eda46c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-41c2b319-703e-4e94-9ac8-272974eda46c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_data = dataset['text'].to_list()\n",
        "labels = dataset['Sentiment'].to_numpy().reshape(-1, 1)"
      ],
      "metadata": {
        "id": "t6DfVLZ8gpk0"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_data, test_data, train_labels, test_labels = train_test_split(text_data, labels, test_size=0.2, shuffle=True, random_state=42)\n",
        "len(train_data), len(test_data), len(train_labels), len(test_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "awRCj_YbhDLt",
        "outputId": "3f120d46-4535-489c-b142-131d36ca9374"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(16054, 4014, 16054, 4014)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "one_hot_encoder = OneHotEncoder(sparse=False)\n",
        "label_encoder = LabelEncoder()"
      ],
      "metadata": {
        "id": "qQVVNX73hIqi"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels_one_hot = one_hot_encoder.fit_transform(train_labels)\n",
        "test_labels_one_hot = one_hot_encoder.transform(test_labels)\n",
        "\n",
        "train_labels = label_encoder.fit_transform(train_labels)\n",
        "test_labels = label_encoder.transform(test_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LM80FvN_hLe-",
        "outputId": "c16bc8a4-6b71-43a4-cebd-5c797f1bdb95"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/preprocessing/_label.py:115: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/preprocessing/_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_CLASSES = len(label_encoder.classes_)\n",
        "NUM_CLASSES"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gmIr_N3_hNjV",
        "outputId": "9d8d9750-8bcd-4506-8d93-02643629e615"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "model_0 = Pipeline([\n",
        "    (\"tfidf\", TfidfVectorizer()),\n",
        "    (\"clf\", MultinomialNB())\n",
        "])\n",
        "model_0.fit(train_data, train_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PM4CnwIOhPxm",
        "outputId": "f56f9833-82c9-484a-b13c-b21d353f0f5e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('tfidf', TfidfVectorizer()), ('clf', MultinomialNB())])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_0_score = model_0.score(test_data, test_labels)"
      ],
      "metadata": {
        "id": "4KyL8JVYhRnv"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "def calculate_results(y_true, y_pred):\n",
        "  model_accuracy = accuracy_score(y_true, y_pred) * 100\n",
        "  model_precision, model_recall, model_f1_score, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
        "  model_results = {\n",
        "      \"accuracy\": model_accuracy,\n",
        "      \"precision\":model_precision,\n",
        "      \"recall\": model_recall,\n",
        "      \"f1_score\": model_f1_score\n",
        "  }\n",
        "  return model_results\n",
        "\n",
        "def return_callbacks(model_name):\n",
        "  callbacks_list = []\n",
        "  callbacks_list.append(tf.keras.callbacks.ModelCheckpoint(\"saved_models/\"+model_name, monitor='val_loss', save_best_only='True', verbose=1))\n",
        "  callbacks_list.append(tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1, restore_best_weights='True'))\n",
        "  return callbacks_list"
      ],
      "metadata": {
        "id": "HlRMqWvThT7r"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_0_preds = model_0.predict(test_data)\n",
        "model_0_results = calculate_results(test_labels, model_0_preds)\n",
        "model_results_dataset = {}\n",
        "model_results_dataset['model_0'] = model_0_results\n",
        "model_0_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8dc4yNg9hVnN",
        "outputId": "1e8f6731-889e-4a52-ba44-7f3b7186e003"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 61.85849526656702,\n",
              " 'precision': 0.7451298809731886,\n",
              " 'recall': 0.6185849526656702,\n",
              " 'f1_score': 0.5600003587792417}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_data, train_labels_one_hot))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_data, test_labels_one_hot))\n",
        "\n",
        "# Take the TensorSliceDataset's and turn them into prefetched batches\n",
        "train_dataset = train_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "test_dataset = test_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "train_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1DJ32hJfhYLv",
        "outputId": "5c64edda-ea25-406a-d355-b727db89be72"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PrefetchDataset element_spec=(TensorSpec(shape=(None,), dtype=tf.string, name=None), TensorSpec(shape=(None, 3), dtype=tf.float64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import TextVectorization\n",
        "output_seq_length = round(sum([len(i.split()) for i in train_data])/len(train_data))\n",
        "tv_layer = TextVectorization(max_tokens=10000, standardize=\"lower_and_strip_punctuation\", split=\"whitespace\", output_mode=\"int\", output_sequence_length=output_seq_length, pad_to_max_tokens=True)\n",
        "tv_layer.adapt(train_data)"
      ],
      "metadata": {
        "id": "MIql9OF0haXu"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "embedding_layer = layers.Embedding(input_dim=10000, output_dim=128, input_length=output_seq_length)"
      ],
      "metadata": {
        "id": "VKWsV9bZhd77"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
        "x = tv_layer(inputs)\n",
        "x = embedding_layer(x)\n",
        "x = layers.GlobalAveragePooling1D()(x)\n",
        "output = layers.Dense(NUM_CLASSES, activation='softmax')(x)\n",
        "\n",
        "model_1 = tf.keras.Model(inputs, output, name=\"nlp_model_1\")\n",
        "model_1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E7llQeGshgAy",
        "outputId": "14056e92-0a9c-40f3-fa18-b35b14aba6c8"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"nlp_model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization (TextVec  (None, 16)               0         \n",
            " torization)                                                     \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 16, 128)           1280000   \n",
            "                                                                 \n",
            " global_average_pooling1d (G  (None, 128)              0         \n",
            " lobalAveragePooling1D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 3)                 387       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,280,387\n",
            "Trainable params: 1,280,387\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.compile(loss=\"categorical_crossentropy\", optimizer=tf.keras.optimizers.Adam(), metrics=[\"accuracy\"])\n",
        "history_1 = model_1.fit(train_dataset, epochs=20, validation_data=test_dataset, callbacks=return_callbacks(model_1.name))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IEv2FNhfhi19",
        "outputId": "3e4fce12-ed9b-47c5-f6fe-2b81a8cafdb1"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "501/502 [============================>.] - ETA: 0s - loss: 0.8072 - accuracy: 0.6551\n",
            "Epoch 1: val_loss improved from inf to 0.64943, saving model to saved_models/nlp_model_1\n",
            "502/502 [==============================] - 6s 7ms/step - loss: 0.8069 - accuracy: 0.6552 - val_loss: 0.6494 - val_accuracy: 0.7304\n",
            "Epoch 2/20\n",
            "499/502 [============================>.] - ETA: 0s - loss: 0.4971 - accuracy: 0.8224\n",
            "Epoch 2: val_loss improved from 0.64943 to 0.48374, saving model to saved_models/nlp_model_1\n",
            "502/502 [==============================] - 3s 7ms/step - loss: 0.4968 - accuracy: 0.8224 - val_loss: 0.4837 - val_accuracy: 0.8109\n",
            "Epoch 3/20\n",
            "500/502 [============================>.] - ETA: 0s - loss: 0.3305 - accuracy: 0.8948\n",
            "Epoch 3: val_loss improved from 0.48374 to 0.41159, saving model to saved_models/nlp_model_1\n",
            "502/502 [==============================] - 3s 6ms/step - loss: 0.3303 - accuracy: 0.8947 - val_loss: 0.4116 - val_accuracy: 0.8490\n",
            "Epoch 4/20\n",
            "501/502 [============================>.] - ETA: 0s - loss: 0.2417 - accuracy: 0.9268\n",
            "Epoch 4: val_loss improved from 0.41159 to 0.38295, saving model to saved_models/nlp_model_1\n",
            "502/502 [==============================] - 3s 6ms/step - loss: 0.2415 - accuracy: 0.9269 - val_loss: 0.3829 - val_accuracy: 0.8617\n",
            "Epoch 5/20\n",
            "495/502 [============================>.] - ETA: 0s - loss: 0.1884 - accuracy: 0.9450\n",
            "Epoch 5: val_loss improved from 0.38295 to 0.37558, saving model to saved_models/nlp_model_1\n",
            "502/502 [==============================] - 3s 6ms/step - loss: 0.1884 - accuracy: 0.9450 - val_loss: 0.3756 - val_accuracy: 0.8687\n",
            "Epoch 6/20\n",
            "502/502 [==============================] - ETA: 0s - loss: 0.1532 - accuracy: 0.9563\n",
            "Epoch 6: val_loss did not improve from 0.37558\n",
            "502/502 [==============================] - 2s 4ms/step - loss: 0.1532 - accuracy: 0.9563 - val_loss: 0.3801 - val_accuracy: 0.8714\n",
            "Epoch 7/20\n",
            "498/502 [============================>.] - ETA: 0s - loss: 0.1281 - accuracy: 0.9650\n",
            "Epoch 7: val_loss did not improve from 0.37558\n",
            "502/502 [==============================] - 2s 4ms/step - loss: 0.1280 - accuracy: 0.9649 - val_loss: 0.3920 - val_accuracy: 0.8702\n",
            "Epoch 8/20\n",
            "499/502 [============================>.] - ETA: 0s - loss: 0.1090 - accuracy: 0.9718\n",
            "Epoch 8: val_loss did not improve from 0.37558\n",
            "502/502 [==============================] - 4s 8ms/step - loss: 0.1091 - accuracy: 0.9716 - val_loss: 0.4087 - val_accuracy: 0.8710\n",
            "Epoch 9/20\n",
            "500/502 [============================>.] - ETA: 0s - loss: 0.0943 - accuracy: 0.9763\n",
            "Epoch 9: val_loss did not improve from 0.37558\n",
            "502/502 [==============================] - 4s 8ms/step - loss: 0.0944 - accuracy: 0.9763 - val_loss: 0.4290 - val_accuracy: 0.8700\n",
            "Epoch 10/20\n",
            "497/502 [============================>.] - ETA: 0s - loss: 0.0828 - accuracy: 0.9787\n",
            "Epoch 10: val_loss did not improve from 0.37558\n",
            "Restoring model weights from the end of the best epoch: 5.\n",
            "502/502 [==============================] - 4s 7ms/step - loss: 0.0826 - accuracy: 0.9788 - val_loss: 0.4518 - val_accuracy: 0.8665\n",
            "Epoch 10: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.evaluate(test_dataset)\n",
        "model_1_loaded = tf.keras.models.load_model(\"saved_models/nlp_model_1\")\n",
        "model_1_preds = model_1_loaded.predict(test_dataset)\n",
        "model_1_results = calculate_results(test_labels, tf.argmax(model_1_preds, axis=1))\n",
        "model_results_dataset['model_1'] = model_1_results\n",
        "model_1_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9UKkZZOhloA",
        "outputId": "3582966e-42f9-41a2-de1c-9f46c243045f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "126/126 [==============================] - 1s 5ms/step - loss: 0.3756 - accuracy: 0.8687\n",
            "126/126 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 86.87095166915795,\n",
              " 'precision': 0.8695089684609235,\n",
              " 'recall': 0.8687095166915795,\n",
              " 'f1_score': 0.8663084047885153}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()"
      ],
      "metadata": {
        "id": "9Q-ROFvThoPh"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "model_2_embedding = layers.Embedding(input_dim=10000, output_dim=128, embeddings_initializer=\"uniform\", input_length=output_seq_length, name=\"embedding_2\")\n",
        "\n",
        "inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
        "x = tv_layer(inputs)\n",
        "x = model_2_embedding(x)\n",
        "x = layers.GlobalAveragePooling1D()(x)\n",
        "x = layers.Dense(64, activation='relu')(x)\n",
        "output = layers.Dense(NUM_CLASSES, activation='softmax')(x)\n",
        "\n",
        "model_2 = tf.keras.Model(inputs, output, name=\"nlp_model_2\")\n",
        "model_2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4RTdWBHHhsDM",
        "outputId": "b1de7c9e-225d-4642-a476-11bc1cd355af"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"nlp_model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization (TextVec  (None, 16)               0         \n",
            " torization)                                                     \n",
            "                                                                 \n",
            " embedding_2 (Embedding)     (None, 16, 128)           1280000   \n",
            "                                                                 \n",
            " global_average_pooling1d (G  (None, 128)              0         \n",
            " lobalAveragePooling1D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 3)                 195       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,288,451\n",
            "Trainable params: 1,288,451\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_2.compile(loss=\"categorical_crossentropy\", optimizer=tf.keras.optimizers.Adam(), metrics=[\"accuracy\"])\n",
        "history_2 = model_2.fit(train_dataset, epochs=20, validation_data=test_dataset,callbacks=return_callbacks(model_2.name))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yeERvvynhuSX",
        "outputId": "dc1dae91-4d9d-4450-cdb7-fb8b83dd3b12"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "494/502 [============================>.] - ETA: 0s - loss: 0.6619 - accuracy: 0.7287\n",
            "Epoch 1: val_loss improved from inf to 0.43324, saving model to saved_models/nlp_model_2\n",
            "502/502 [==============================] - 4s 7ms/step - loss: 0.6585 - accuracy: 0.7303 - val_loss: 0.4332 - val_accuracy: 0.8371\n",
            "Epoch 2/20\n",
            "497/502 [============================>.] - ETA: 0s - loss: 0.2864 - accuracy: 0.9034\n",
            "Epoch 2: val_loss improved from 0.43324 to 0.37351, saving model to saved_models/nlp_model_2\n",
            "502/502 [==============================] - 3s 6ms/step - loss: 0.2861 - accuracy: 0.9035 - val_loss: 0.3735 - val_accuracy: 0.8737\n",
            "Epoch 3/20\n",
            "502/502 [==============================] - ETA: 0s - loss: 0.1778 - accuracy: 0.9454\n",
            "Epoch 3: val_loss did not improve from 0.37351\n",
            "502/502 [==============================] - 3s 6ms/step - loss: 0.1778 - accuracy: 0.9454 - val_loss: 0.3982 - val_accuracy: 0.8690\n",
            "Epoch 4/20\n",
            "491/502 [============================>.] - ETA: 0s - loss: 0.1285 - accuracy: 0.9642\n",
            "Epoch 4: val_loss did not improve from 0.37351\n",
            "502/502 [==============================] - 2s 4ms/step - loss: 0.1279 - accuracy: 0.9644 - val_loss: 0.4433 - val_accuracy: 0.8642\n",
            "Epoch 5/20\n",
            "502/502 [==============================] - ETA: 0s - loss: 0.0993 - accuracy: 0.9735\n",
            "Epoch 5: val_loss did not improve from 0.37351\n",
            "502/502 [==============================] - 3s 5ms/step - loss: 0.0993 - accuracy: 0.9735 - val_loss: 0.4928 - val_accuracy: 0.8615\n",
            "Epoch 6/20\n",
            "501/502 [============================>.] - ETA: 0s - loss: 0.0806 - accuracy: 0.9800\n",
            "Epoch 6: val_loss did not improve from 0.37351\n",
            "502/502 [==============================] - 3s 5ms/step - loss: 0.0805 - accuracy: 0.9800 - val_loss: 0.5407 - val_accuracy: 0.8570\n",
            "Epoch 7/20\n",
            "499/502 [============================>.] - ETA: 0s - loss: 0.0671 - accuracy: 0.9830\n",
            "Epoch 7: val_loss did not improve from 0.37351\n",
            "Restoring model weights from the end of the best epoch: 2.\n",
            "502/502 [==============================] - 2s 4ms/step - loss: 0.0672 - accuracy: 0.9829 - val_loss: 0.5966 - val_accuracy: 0.8520\n",
            "Epoch 7: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_2.evaluate(test_dataset)\n",
        "model_2_loaded = tf.keras.models.load_model(\"saved_models/nlp_model_2\")\n",
        "model_2_preds = model_2_loaded.predict(test_dataset)\n",
        "model_2_results = calculate_results(test_labels, tf.argmax(model_2_preds, axis=1))\n",
        "model_results_dataset['model_2'] = model_2_results\n",
        "model_2_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WdAWI0Hqhwka",
        "outputId": "0fc4efbb-8db7-49e6-e9bd-6ccfed93ab72"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "126/126 [==============================] - 0s 3ms/step - loss: 0.3735 - accuracy: 0.8737\n",
            "126/126 [==============================] - 1s 4ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 87.36920777279522,\n",
              " 'precision': 0.8730049120890256,\n",
              " 'recall': 0.8736920777279522,\n",
              " 'f1_score': 0.8721520826446647}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()"
      ],
      "metadata": {
        "id": "kC8xC_JBhzbB"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "model_3_embedding = layers.Embedding(input_dim=10000, output_dim=128, embeddings_initializer=\"uniform\", input_length=output_seq_length, name=\"embedding_2\")\n",
        "\n",
        "inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
        "x = tv_layer(inputs)\n",
        "x = model_3_embedding(x)\n",
        "x = layers.LSTM(64)(x)\n",
        "x = layers.Dense(64, activation='relu')(x)\n",
        "output = layers.Dense(NUM_CLASSES, activation='softmax')(x)\n",
        "\n",
        "model_3 = tf.keras.Model(inputs, output, name=\"nlp_model_3\")\n",
        "model_3.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DwVaB2gsh1af",
        "outputId": "64d75b31-437d-4aa2-9ecf-20379ef7dfa1"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"nlp_model_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization (TextVec  (None, 16)               0         \n",
            " torization)                                                     \n",
            "                                                                 \n",
            " embedding_2 (Embedding)     (None, 16, 128)           1280000   \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 64)                49408     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 3)                 195       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,333,763\n",
            "Trainable params: 1,333,763\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_3.compile(loss=\"categorical_crossentropy\", optimizer=tf.keras.optimizers.Adam(), metrics=[\"accuracy\"])\n",
        "history_3 = model_3.fit(train_dataset, epochs=20, validation_data=test_dataset,callbacks=return_callbacks(model_3.name))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PwvUkx7th2_o",
        "outputId": "ecbd0e6d-ca7b-4c11-f026-5dea7a3fb56a"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "495/502 [============================>.] - ETA: 0s - loss: 0.5652 - accuracy: 0.7750\n",
            "Epoch 1: val_loss improved from inf to 0.34702, saving model to saved_models/nlp_model_3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r502/502 [==============================] - 14s 19ms/step - loss: 0.5626 - accuracy: 0.7761 - val_loss: 0.3470 - val_accuracy: 0.8807\n",
            "Epoch 2/20\n",
            "496/502 [============================>.] - ETA: 0s - loss: 0.2444 - accuracy: 0.9202\n",
            "Epoch 2: val_loss did not improve from 0.34702\n",
            "502/502 [==============================] - 4s 8ms/step - loss: 0.2443 - accuracy: 0.9202 - val_loss: 0.3561 - val_accuracy: 0.8819\n",
            "Epoch 3/20\n",
            "500/502 [============================>.] - ETA: 0s - loss: 0.1682 - accuracy: 0.9480\n",
            "Epoch 3: val_loss did not improve from 0.34702\n",
            "502/502 [==============================] - 4s 8ms/step - loss: 0.1683 - accuracy: 0.9479 - val_loss: 0.3726 - val_accuracy: 0.8874\n",
            "Epoch 4/20\n",
            "501/502 [============================>.] - ETA: 0s - loss: 0.1285 - accuracy: 0.9618\n",
            "Epoch 4: val_loss did not improve from 0.34702\n",
            "502/502 [==============================] - 3s 6ms/step - loss: 0.1284 - accuracy: 0.9618 - val_loss: 0.3884 - val_accuracy: 0.8899\n",
            "Epoch 5/20\n",
            "496/502 [============================>.] - ETA: 0s - loss: 0.0982 - accuracy: 0.9708\n",
            "Epoch 5: val_loss did not improve from 0.34702\n",
            "502/502 [==============================] - 4s 7ms/step - loss: 0.0983 - accuracy: 0.9708 - val_loss: 0.4290 - val_accuracy: 0.8859\n",
            "Epoch 6/20\n",
            "497/502 [============================>.] - ETA: 0s - loss: 0.0792 - accuracy: 0.9756\n",
            "Epoch 6: val_loss did not improve from 0.34702\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "502/502 [==============================] - 3s 6ms/step - loss: 0.0790 - accuracy: 0.9757 - val_loss: 0.4944 - val_accuracy: 0.8817\n",
            "Epoch 6: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_3.evaluate(test_dataset)\n",
        "model_3_loaded = tf.keras.models.load_model(\"saved_models/nlp_model_3\")\n",
        "model_3_preds = model_3_loaded.predict(test_dataset)\n",
        "model_3_results = calculate_results(test_labels, tf.argmax(model_3_preds, axis=1))\n",
        "model_results_dataset['model_3'] = model_3_results\n",
        "model_3_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jrRX3Kvfh5hx",
        "outputId": "b417e148-43b6-4554-ee14-543e441f9a06"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "126/126 [==============================] - 0s 4ms/step - loss: 0.3470 - accuracy: 0.8807\n",
            "126/126 [==============================] - 1s 3ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 88.06676631788739,\n",
              " 'precision': 0.8807399972773913,\n",
              " 'recall': 0.8806676631788739,\n",
              " 'f1_score': 0.8796374634146443}"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()"
      ],
      "metadata": {
        "id": "pa1wn7yFh8CO"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "model_4_embedding = layers.Embedding(input_dim=10000, output_dim=128, embeddings_initializer=\"uniform\", input_length=output_seq_length, name=\"embedding_4\")\n",
        "\n",
        "inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
        "x = tv_layer(inputs)\n",
        "x = model_4_embedding(x)\n",
        "x = layers.LSTM(64, return_sequences=True)(x)\n",
        "x = layers.GRU(64)(x)\n",
        "x = layers.Dense(64, activation='relu')(x)\n",
        "output = layers.Dense(NUM_CLASSES, activation='softmax')(x)\n",
        "\n",
        "model_4 = tf.keras.Model(inputs, output, name=\"nlp_model_4\")\n",
        "model_4.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZsHNE_Mh-Uu",
        "outputId": "cbec033f-4d08-49af-e24f-73b0fedcc961"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"nlp_model_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization (TextVec  (None, 16)               0         \n",
            " torization)                                                     \n",
            "                                                                 \n",
            " embedding_4 (Embedding)     (None, 16, 128)           1280000   \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 16, 64)            49408     \n",
            "                                                                 \n",
            " gru (GRU)                   (None, 64)                24960     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 3)                 195       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,358,723\n",
            "Trainable params: 1,358,723\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_4.compile(loss=\"categorical_crossentropy\", optimizer=tf.keras.optimizers.Adam(), metrics=[\"accuracy\"])\n",
        "history_4 = model_4.fit(train_dataset, epochs=20, validation_data=test_dataset,callbacks=return_callbacks(model_4.name))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mpYoj0gWiAEV",
        "outputId": "12607a4f-c0da-4fa1-8eb9-06553bff63b7"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "498/502 [============================>.] - ETA: 0s - loss: 0.5608 - accuracy: 0.7787\n",
            "Epoch 1: val_loss improved from inf to 0.35924, saving model to saved_models/nlp_model_4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, gru_cell_layer_call_fn, gru_cell_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r502/502 [==============================] - 17s 28ms/step - loss: 0.5593 - accuracy: 0.7791 - val_loss: 0.3592 - val_accuracy: 0.8739\n",
            "Epoch 2/20\n",
            "502/502 [==============================] - ETA: 0s - loss: 0.2465 - accuracy: 0.9200\n",
            "Epoch 2: val_loss improved from 0.35924 to 0.33643, saving model to saved_models/nlp_model_4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, gru_cell_layer_call_fn, gru_cell_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r502/502 [==============================] - 12s 24ms/step - loss: 0.2465 - accuracy: 0.9200 - val_loss: 0.3364 - val_accuracy: 0.8901\n",
            "Epoch 3/20\n",
            "498/502 [============================>.] - ETA: 0s - loss: 0.1675 - accuracy: 0.9486\n",
            "Epoch 3: val_loss did not improve from 0.33643\n",
            "502/502 [==============================] - 5s 9ms/step - loss: 0.1674 - accuracy: 0.9486 - val_loss: 0.3815 - val_accuracy: 0.8792\n",
            "Epoch 4/20\n",
            "501/502 [============================>.] - ETA: 0s - loss: 0.1265 - accuracy: 0.9625\n",
            "Epoch 4: val_loss did not improve from 0.33643\n",
            "502/502 [==============================] - 5s 10ms/step - loss: 0.1264 - accuracy: 0.9625 - val_loss: 0.4033 - val_accuracy: 0.8844\n",
            "Epoch 5/20\n",
            "497/502 [============================>.] - ETA: 0s - loss: 0.0996 - accuracy: 0.9709\n",
            "Epoch 5: val_loss did not improve from 0.33643\n",
            "502/502 [==============================] - 4s 8ms/step - loss: 0.0994 - accuracy: 0.9708 - val_loss: 0.4486 - val_accuracy: 0.8752\n",
            "Epoch 6/20\n",
            "499/502 [============================>.] - ETA: 0s - loss: 0.0748 - accuracy: 0.9785\n",
            "Epoch 6: val_loss did not improve from 0.33643\n",
            "502/502 [==============================] - 5s 9ms/step - loss: 0.0751 - accuracy: 0.9784 - val_loss: 0.4913 - val_accuracy: 0.8847\n",
            "Epoch 7/20\n",
            "498/502 [============================>.] - ETA: 0s - loss: 0.0625 - accuracy: 0.9804\n",
            "Epoch 7: val_loss did not improve from 0.33643\n",
            "Restoring model weights from the end of the best epoch: 2.\n",
            "502/502 [==============================] - 4s 8ms/step - loss: 0.0626 - accuracy: 0.9803 - val_loss: 0.5591 - val_accuracy: 0.8854\n",
            "Epoch 7: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_4.evaluate(test_dataset)\n",
        "model_4_loaded = tf.keras.models.load_model(\"saved_models/nlp_model_4\")\n",
        "model_4_preds = model_4_loaded.predict(test_dataset)\n",
        "model_4_results = calculate_results(test_labels, tf.argmax(model_4_preds, axis=1))\n",
        "model_results_dataset['model_4'] = model_4_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z3MTfX_CiCMw",
        "outputId": "f3f8ddaf-1750-4dab-b106-aaf8291dbf74"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "126/126 [==============================] - 1s 4ms/step - loss: 0.3364 - accuracy: 0.8901\n",
            "126/126 [==============================] - 1s 3ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()"
      ],
      "metadata": {
        "id": "UFmF1mgViFtB"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "model_5_embedding = layers.Embedding(input_dim=10000, output_dim=128, embeddings_initializer=\"uniform\", input_length=output_seq_length, name=\"embedding_5\")\n",
        "\n",
        "inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
        "x = tv_layer(inputs)\n",
        "x = model_5_embedding(x)\n",
        "x = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(x)\n",
        "x = layers.Bidirectional(layers.GRU(64))(x)\n",
        "x = layers.Dense(64, activation='relu')(x)\n",
        "output = layers.Dense(NUM_CLASSES, activation='softmax')(x)\n",
        "\n",
        "model_5 = tf.keras.Model(inputs, output, name=\"nlp_model_5\")\n",
        "model_5.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-al-mTRYiHhT",
        "outputId": "733bb297-a8d9-4161-ef4b-36a8afb35856"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"nlp_model_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization (TextVec  (None, 16)               0         \n",
            " torization)                                                     \n",
            "                                                                 \n",
            " embedding_5 (Embedding)     (None, 16, 128)           1280000   \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 16, 128)          98816     \n",
            " l)                                                              \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirectio  (None, 128)              74496     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 3)                 195       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,461,763\n",
            "Trainable params: 1,461,763\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_5.compile(loss=\"categorical_crossentropy\", optimizer=tf.keras.optimizers.Adam(), metrics=[\"accuracy\"])\n",
        "history_5 = model_5.fit(train_dataset, epochs=20, validation_data=test_dataset,callbacks=return_callbacks(model_5.name))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZE6AH_LiJEr",
        "outputId": "40b8c01a-5112-48d3-dc4a-a96ad116363c"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "500/502 [============================>.] - ETA: 0s - loss: 0.5530 - accuracy: 0.7856\n",
            "Epoch 1: val_loss improved from inf to 0.34491, saving model to saved_models/nlp_model_5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, gru_cell_1_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r502/502 [==============================] - 34s 58ms/step - loss: 0.5524 - accuracy: 0.7858 - val_loss: 0.3449 - val_accuracy: 0.8809\n",
            "Epoch 2/20\n",
            "500/502 [============================>.] - ETA: 0s - loss: 0.2438 - accuracy: 0.9226\n",
            "Epoch 2: val_loss improved from 0.34491 to 0.33457, saving model to saved_models/nlp_model_5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, gru_cell_1_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r502/502 [==============================] - 28s 56ms/step - loss: 0.2438 - accuracy: 0.9224 - val_loss: 0.3346 - val_accuracy: 0.8884\n",
            "Epoch 3/20\n",
            "498/502 [============================>.] - ETA: 0s - loss: 0.1635 - accuracy: 0.9499\n",
            "Epoch 3: val_loss did not improve from 0.33457\n",
            "502/502 [==============================] - 8s 15ms/step - loss: 0.1636 - accuracy: 0.9499 - val_loss: 0.3758 - val_accuracy: 0.8837\n",
            "Epoch 4/20\n",
            "499/502 [============================>.] - ETA: 0s - loss: 0.1206 - accuracy: 0.9633\n",
            "Epoch 4: val_loss did not improve from 0.33457\n",
            "502/502 [==============================] - 6s 13ms/step - loss: 0.1205 - accuracy: 0.9632 - val_loss: 0.4276 - val_accuracy: 0.8794\n",
            "Epoch 5/20\n",
            "498/502 [============================>.] - ETA: 0s - loss: 0.0897 - accuracy: 0.9725\n",
            "Epoch 5: val_loss did not improve from 0.33457\n",
            "502/502 [==============================] - 7s 13ms/step - loss: 0.0895 - accuracy: 0.9725 - val_loss: 0.4590 - val_accuracy: 0.8934\n",
            "Epoch 6/20\n",
            "502/502 [==============================] - ETA: 0s - loss: 0.0674 - accuracy: 0.9788\n",
            "Epoch 6: val_loss did not improve from 0.33457\n",
            "502/502 [==============================] - 8s 17ms/step - loss: 0.0674 - accuracy: 0.9788 - val_loss: 0.5021 - val_accuracy: 0.8827\n",
            "Epoch 7/20\n",
            "499/502 [============================>.] - ETA: 0s - loss: 0.0508 - accuracy: 0.9837\n",
            "Epoch 7: val_loss did not improve from 0.33457\n",
            "Restoring model weights from the end of the best epoch: 2.\n",
            "502/502 [==============================] - 7s 15ms/step - loss: 0.0511 - accuracy: 0.9836 - val_loss: 0.6288 - val_accuracy: 0.8797\n",
            "Epoch 7: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_5.evaluate(test_dataset)\n",
        "model_5_loaded = tf.keras.models.load_model(\"saved_models/nlp_model_5\")\n",
        "model_5_preds = model_5_loaded.predict(test_dataset)\n",
        "model_5_results = calculate_results(test_labels, tf.argmax(model_5_preds, axis=1))\n",
        "model_results_dataset['model_5'] = model_5_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x3V-eOgkiLBH",
        "outputId": "31607405-b10f-4b9a-eca1-76e2ac665f0f"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "126/126 [==============================] - 1s 6ms/step - loss: 0.3346 - accuracy: 0.8884\n",
            "126/126 [==============================] - 2s 5ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "model_6_embedding = layers.Embedding(input_dim=10000, output_dim=128, embeddings_initializer=\"uniform\", input_length=output_seq_length, name=\"embedding_6\")\n",
        "\n",
        "# Create 1D convolutional model to process sequences\n",
        "inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
        "text_vectors = tv_layer(inputs) # vectorize text inputs\n",
        "token_embeddings = model_6_embedding(text_vectors) # create embedding\n",
        "x = layers.Conv1D(64, kernel_size=5, padding=\"same\", activation=\"relu\")(token_embeddings)\n",
        "x = layers.GlobalAveragePooling1D()(x) # condense the output of our feature vector\n",
        "outputs = layers.Dense(NUM_CLASSES, activation=\"softmax\")(x)\n",
        "model_6 = tf.keras.Model(inputs, outputs, name=\"nlp_model_6\")\n",
        "\n",
        "# Compile\n",
        "model_6.compile(loss=\"categorical_crossentropy\", # if your labels are integer form (not one hot) use sparse_categorical_crossentropy\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "history_6 = model_6.fit(train_dataset, epochs=20, validation_data=test_dataset,callbacks=return_callbacks(model_6.name))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IQS95OC4iNif",
        "outputId": "0a4f6db9-e03b-4858-ed15-15bcad5dac45"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "502/502 [==============================] - ETA: 0s - loss: 0.5829 - accuracy: 0.7678\n",
            "Epoch 1: val_loss improved from inf to 0.37510, saving model to saved_models/nlp_model_6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r502/502 [==============================] - 7s 7ms/step - loss: 0.5829 - accuracy: 0.7678 - val_loss: 0.3751 - val_accuracy: 0.8700\n",
            "Epoch 2/20\n",
            "496/502 [============================>.] - ETA: 0s - loss: 0.2641 - accuracy: 0.9173\n",
            "Epoch 2: val_loss improved from 0.37510 to 0.35710, saving model to saved_models/nlp_model_6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r502/502 [==============================] - 4s 9ms/step - loss: 0.2643 - accuracy: 0.9172 - val_loss: 0.3571 - val_accuracy: 0.8886\n",
            "Epoch 3/20\n",
            "502/502 [==============================] - ETA: 0s - loss: 0.1737 - accuracy: 0.9478\n",
            "Epoch 3: val_loss did not improve from 0.35710\n",
            "502/502 [==============================] - 2s 5ms/step - loss: 0.1737 - accuracy: 0.9478 - val_loss: 0.3942 - val_accuracy: 0.8802\n",
            "Epoch 4/20\n",
            "500/502 [============================>.] - ETA: 0s - loss: 0.1263 - accuracy: 0.9653\n",
            "Epoch 4: val_loss did not improve from 0.35710\n",
            "502/502 [==============================] - 3s 6ms/step - loss: 0.1263 - accuracy: 0.9653 - val_loss: 0.4454 - val_accuracy: 0.8744\n",
            "Epoch 5/20\n",
            "496/502 [============================>.] - ETA: 0s - loss: 0.0942 - accuracy: 0.9736\n",
            "Epoch 5: val_loss did not improve from 0.35710\n",
            "502/502 [==============================] - 3s 6ms/step - loss: 0.0941 - accuracy: 0.9736 - val_loss: 0.5125 - val_accuracy: 0.8702\n",
            "Epoch 6/20\n",
            "501/502 [============================>.] - ETA: 0s - loss: 0.0719 - accuracy: 0.9812\n",
            "Epoch 6: val_loss did not improve from 0.35710\n",
            "502/502 [==============================] - 3s 6ms/step - loss: 0.0718 - accuracy: 0.9813 - val_loss: 0.5735 - val_accuracy: 0.8622\n",
            "Epoch 7/20\n",
            "493/502 [============================>.] - ETA: 0s - loss: 0.0566 - accuracy: 0.9854\n",
            "Epoch 7: val_loss did not improve from 0.35710\n",
            "Restoring model weights from the end of the best epoch: 2.\n",
            "502/502 [==============================] - 3s 5ms/step - loss: 0.0562 - accuracy: 0.9855 - val_loss: 0.6399 - val_accuracy: 0.8590\n",
            "Epoch 7: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_6.evaluate(test_dataset)\n",
        "model_6_loaded = tf.keras.models.load_model(\"saved_models/nlp_model_6\")\n",
        "model_6_preds = model_6_loaded.predict(test_dataset)\n",
        "model_6_results = calculate_results(test_labels, tf.argmax(model_6_preds, axis=1))\n",
        "model_results_dataset['model_6'] = model_6_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XRaRkYZ5iPa4",
        "outputId": "ab1e74da-f4ea-45a0-ae4c-825e8b32aa45"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "126/126 [==============================] - 0s 3ms/step - loss: 0.3571 - accuracy: 0.8886\n",
            "126/126 [==============================] - 0s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "import tensorflow_hub as hub\n",
        "tf_hub_embedding_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
        "                                        trainable=False,\n",
        "                                        name=\"universal_sentence_encoder\")\n",
        "\n",
        "model_7 = tf.keras.Sequential([\n",
        "  layers.Input(shape=[], dtype=tf.string),\n",
        "  tf_hub_embedding_layer, # take in sentences and then encode them into an embedding\n",
        "  layers.Dense(128, activation=\"relu\"),\n",
        "  layers.Dense(NUM_CLASSES, activation=\"softmax\")\n",
        "], name=\"nlp_model_7\")\n",
        "\n",
        "model_7.summary()\n",
        "\n",
        "model_7.compile(loss=\"categorical_crossentropy\", # if your labels are integer form (not one hot) use sparse_categorical_crossentropy\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "history_7 = model_7.fit(train_dataset, epochs=20, validation_data=test_dataset,callbacks=return_callbacks(model_7.name))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UbVMAcNZiR1R",
        "outputId": "703e967f-bd71-4d5b-aee1-45257e0376b6"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"nlp_model_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " universal_sentence_encoder   (None, 512)              256797824 \n",
            " (KerasLayer)                                                    \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               65664     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 3)                 387       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 256,863,875\n",
            "Trainable params: 66,051\n",
            "Non-trainable params: 256,797,824\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "497/502 [============================>.] - ETA: 0s - loss: 0.7654 - accuracy: 0.6641\n",
            "Epoch 1: val_loss improved from inf to 0.70139, saving model to saved_models/nlp_model_7\n",
            "502/502 [==============================] - 20s 34ms/step - loss: 0.7639 - accuracy: 0.6647 - val_loss: 0.7014 - val_accuracy: 0.6901\n",
            "Epoch 2/20\n",
            "501/502 [============================>.] - ETA: 0s - loss: 0.6776 - accuracy: 0.7086\n",
            "Epoch 2: val_loss improved from 0.70139 to 0.67645, saving model to saved_models/nlp_model_7\n",
            "502/502 [==============================] - 15s 30ms/step - loss: 0.6773 - accuracy: 0.7087 - val_loss: 0.6764 - val_accuracy: 0.7058\n",
            "Epoch 3/20\n",
            "501/502 [============================>.] - ETA: 0s - loss: 0.6451 - accuracy: 0.7233\n",
            "Epoch 3: val_loss improved from 0.67645 to 0.66114, saving model to saved_models/nlp_model_7\n",
            "502/502 [==============================] - 17s 33ms/step - loss: 0.6449 - accuracy: 0.7234 - val_loss: 0.6611 - val_accuracy: 0.7145\n",
            "Epoch 4/20\n",
            "500/502 [============================>.] - ETA: 0s - loss: 0.6184 - accuracy: 0.7356\n",
            "Epoch 4: val_loss improved from 0.66114 to 0.65151, saving model to saved_models/nlp_model_7\n",
            "502/502 [==============================] - 15s 30ms/step - loss: 0.6179 - accuracy: 0.7358 - val_loss: 0.6515 - val_accuracy: 0.7210\n",
            "Epoch 5/20\n",
            "498/502 [============================>.] - ETA: 0s - loss: 0.5946 - accuracy: 0.7498\n",
            "Epoch 5: val_loss improved from 0.65151 to 0.64632, saving model to saved_models/nlp_model_7\n",
            "502/502 [==============================] - 15s 30ms/step - loss: 0.5940 - accuracy: 0.7501 - val_loss: 0.6463 - val_accuracy: 0.7250\n",
            "Epoch 6/20\n",
            "499/502 [============================>.] - ETA: 0s - loss: 0.5711 - accuracy: 0.7643\n",
            "Epoch 6: val_loss improved from 0.64632 to 0.64347, saving model to saved_models/nlp_model_7\n",
            "502/502 [==============================] - 15s 30ms/step - loss: 0.5709 - accuracy: 0.7645 - val_loss: 0.6435 - val_accuracy: 0.7280\n",
            "Epoch 7/20\n",
            "497/502 [============================>.] - ETA: 0s - loss: 0.5494 - accuracy: 0.7761\n",
            "Epoch 7: val_loss improved from 0.64347 to 0.64250, saving model to saved_models/nlp_model_7\n",
            "502/502 [==============================] - 16s 32ms/step - loss: 0.5483 - accuracy: 0.7768 - val_loss: 0.6425 - val_accuracy: 0.7282\n",
            "Epoch 8/20\n",
            "499/502 [============================>.] - ETA: 0s - loss: 0.5260 - accuracy: 0.7880\n",
            "Epoch 8: val_loss did not improve from 0.64250\n",
            "502/502 [==============================] - 6s 12ms/step - loss: 0.5258 - accuracy: 0.7882 - val_loss: 0.6427 - val_accuracy: 0.7257\n",
            "Epoch 9/20\n",
            "501/502 [============================>.] - ETA: 0s - loss: 0.5034 - accuracy: 0.7985\n",
            "Epoch 9: val_loss did not improve from 0.64250\n",
            "502/502 [==============================] - 6s 13ms/step - loss: 0.5031 - accuracy: 0.7986 - val_loss: 0.6442 - val_accuracy: 0.7272\n",
            "Epoch 10/20\n",
            "499/502 [============================>.] - ETA: 0s - loss: 0.4807 - accuracy: 0.8107\n",
            "Epoch 10: val_loss did not improve from 0.64250\n",
            "502/502 [==============================] - 6s 12ms/step - loss: 0.4805 - accuracy: 0.8109 - val_loss: 0.6473 - val_accuracy: 0.7294\n",
            "Epoch 11/20\n",
            "500/502 [============================>.] - ETA: 0s - loss: 0.4580 - accuracy: 0.8216\n",
            "Epoch 11: val_loss did not improve from 0.64250\n",
            "502/502 [==============================] - 6s 12ms/step - loss: 0.4576 - accuracy: 0.8218 - val_loss: 0.6513 - val_accuracy: 0.7257\n",
            "Epoch 12/20\n",
            "502/502 [==============================] - ETA: 0s - loss: 0.4348 - accuracy: 0.8326\n",
            "Epoch 12: val_loss did not improve from 0.64250\n",
            "Restoring model weights from the end of the best epoch: 7.\n",
            "502/502 [==============================] - 7s 13ms/step - loss: 0.4348 - accuracy: 0.8326 - val_loss: 0.6568 - val_accuracy: 0.7232\n",
            "Epoch 12: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_7.evaluate(test_dataset)\n",
        "model_7_loaded = tf.keras.models.load_model(\"saved_models/nlp_model_7\")\n",
        "model_7_preds = model_7_loaded.predict(test_dataset)\n",
        "model_7_results = calculate_results(test_labels, tf.argmax(model_7_preds, axis=1))\n",
        "model_results_dataset['model_7'] = model_7_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1cE1fZi_iTn6",
        "outputId": "aa0a3fef-9cf1-484e-870e-60b7ab372836"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "126/126 [==============================] - 1s 10ms/step - loss: 0.6425 - accuracy: 0.7282\n",
            "126/126 [==============================] - 1s 9ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()"
      ],
      "metadata": {
        "id": "YbaV69SxiWEc"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make function to split sentences into characters\n",
        "def split_chars(text):\n",
        "  return \" \".join(list(text))\n",
        "\n",
        "# Split sequence-level data splits into character-level data splits\n",
        "train_chars = [split_chars(sentence) for sentence in train_data]\n",
        "test_chars = [split_chars(sentence) for sentence in test_data]\n",
        "print(train_chars[0])\n",
        "char_lens = [len(sentence) for sentence in train_data]\n",
        "mean_char_len = np.mean(char_lens)\n",
        "mean_char_len\n",
        "output_seq_char_len = int(np.percentile(char_lens, 95))\n",
        "output_seq_char_len"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U4rNtlybiXkC",
        "outputId": "d4a602c8-2009-4a86-ab76-35c2c8c93bfc"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# T h e S o c i a l D i l e m m a   \n",
            " \n",
            " W e l l ,   e v e r y o n e   s h o u l d   w a t c h   t h i s .   S u c h   a   c r i t i c a l   s t u f f . \n",
            " \n",
            " -   N e v e r   a c c e p t   a   v i d e o   r e c o m m e n d e d   t o …   h t t p s : / / t . c o / 0 W b e n T B A d D\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "140"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "alphabet = string.ascii_lowercase + string.digits + string.punctuation\n",
        "alphabet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "cSwb3As6iY-L",
        "outputId": "21c6896c-8288-499f-e6bb-5ee11f24ad1e"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'abcdefghijklmnopqrstuvwxyz0123456789!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create char-level token vectorizer instance\n",
        "NUM_CHAR_TOKENS = len(alphabet) + 2 # num characters in alphabet + space + OOV token\n",
        "char_vectorizer = TextVectorization(max_tokens=NUM_CHAR_TOKENS,  \n",
        "                                    output_sequence_length=output_seq_char_len,\n",
        "                                    standardize=\"lower_and_strip_punctuation\",\n",
        "                                    name=\"char_vectorizer\")\n",
        "\n",
        "# Adapt character vectorizer to training characters\n",
        "char_vectorizer.adapt(train_chars)\n",
        "     "
      ],
      "metadata": {
        "id": "aCfXA9KNicjC"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create char embedding layer\n",
        "char_embed = layers.Embedding(input_dim=NUM_CHAR_TOKENS, # number of different characters\n",
        "                              output_dim=25, # embedding dimension of each character (same as Figure 1 in https://arxiv.org/pdf/1612.05251.pdf)\n",
        "                              mask_zero=False, # don't use masks (this messes up model_5 if set to True)\n",
        "                              name=\"char_embed\")"
      ],
      "metadata": {
        "id": "r8yqI8oOieLj"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make Conv1D on chars only\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
        "char_vectors = char_vectorizer(inputs)\n",
        "char_embeddings = char_embed(char_vectors)\n",
        "x = layers.Conv1D(64, kernel_size=5, padding=\"same\", activation=\"relu\")(char_embeddings)\n",
        "x = layers.GlobalMaxPool1D()(x)\n",
        "outputs = layers.Dense(NUM_CLASSES, activation=\"softmax\")(x)\n",
        "model_8 = tf.keras.Model(inputs=inputs,\n",
        "                         outputs=outputs,\n",
        "                         name=\"nlp_model_8\")\n",
        "\n",
        "# Compile model\n",
        "model_8.compile(loss=\"categorical_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "1WxWygUHifw3"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_char_dataset = tf.data.Dataset.from_tensor_slices((train_chars, train_labels_one_hot)).batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "val_char_dataset = tf.data.Dataset.from_tensor_slices((test_chars, test_labels_one_hot)).batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "train_char_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "haf2AXJ5ih6a",
        "outputId": "4d46db0b-18b5-4902-a2d2-2e18e2a4a88a"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PrefetchDataset element_spec=(TensorSpec(shape=(None,), dtype=tf.string, name=None), TensorSpec(shape=(None, 3), dtype=tf.float64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history_8 = model_8.fit(train_char_dataset, epochs=20, validation_data=val_char_dataset,callbacks=return_callbacks(model_8.name))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BOpeSYqoijhC",
        "outputId": "5b2c09b7-b53f-4979-cf9b-ce3c501200ee"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "502/502 [==============================] - ETA: 0s - loss: 0.9432 - accuracy: 0.5533\n",
            "Epoch 1: val_loss improved from inf to 0.87799, saving model to saved_models/nlp_model_8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r502/502 [==============================] - 5s 8ms/step - loss: 0.9432 - accuracy: 0.5533 - val_loss: 0.8780 - val_accuracy: 0.5989\n",
            "Epoch 2/20\n",
            "497/502 [============================>.] - ETA: 0s - loss: 0.8311 - accuracy: 0.6207\n",
            "Epoch 2: val_loss improved from 0.87799 to 0.80839, saving model to saved_models/nlp_model_8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r502/502 [==============================] - 3s 7ms/step - loss: 0.8297 - accuracy: 0.6218 - val_loss: 0.8084 - val_accuracy: 0.6520\n",
            "Epoch 3/20\n",
            "500/502 [============================>.] - ETA: 0s - loss: 0.7674 - accuracy: 0.6622\n",
            "Epoch 3: val_loss improved from 0.80839 to 0.77047, saving model to saved_models/nlp_model_8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r502/502 [==============================] - 3s 7ms/step - loss: 0.7666 - accuracy: 0.6628 - val_loss: 0.7705 - val_accuracy: 0.6672\n",
            "Epoch 4/20\n",
            "501/502 [============================>.] - ETA: 0s - loss: 0.7235 - accuracy: 0.6879\n",
            "Epoch 4: val_loss improved from 0.77047 to 0.74731, saving model to saved_models/nlp_model_8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r502/502 [==============================] - 3s 7ms/step - loss: 0.7231 - accuracy: 0.6881 - val_loss: 0.7473 - val_accuracy: 0.6796\n",
            "Epoch 5/20\n",
            "499/502 [============================>.] - ETA: 0s - loss: 0.6894 - accuracy: 0.7047\n",
            "Epoch 5: val_loss improved from 0.74731 to 0.73179, saving model to saved_models/nlp_model_8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r502/502 [==============================] - 3s 7ms/step - loss: 0.6887 - accuracy: 0.7052 - val_loss: 0.7318 - val_accuracy: 0.6921\n",
            "Epoch 6/20\n",
            "500/502 [============================>.] - ETA: 0s - loss: 0.6608 - accuracy: 0.7203\n",
            "Epoch 6: val_loss improved from 0.73179 to 0.72181, saving model to saved_models/nlp_model_8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r502/502 [==============================] - 4s 7ms/step - loss: 0.6601 - accuracy: 0.7208 - val_loss: 0.7218 - val_accuracy: 0.6958\n",
            "Epoch 7/20\n",
            "493/502 [============================>.] - ETA: 0s - loss: 0.6364 - accuracy: 0.7302\n",
            "Epoch 7: val_loss improved from 0.72181 to 0.71634, saving model to saved_models/nlp_model_8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r502/502 [==============================] - 3s 7ms/step - loss: 0.6362 - accuracy: 0.7309 - val_loss: 0.7163 - val_accuracy: 0.6973\n",
            "Epoch 8/20\n",
            "496/502 [============================>.] - ETA: 0s - loss: 0.6160 - accuracy: 0.7427\n",
            "Epoch 8: val_loss improved from 0.71634 to 0.71307, saving model to saved_models/nlp_model_8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r502/502 [==============================] - 3s 7ms/step - loss: 0.6152 - accuracy: 0.7435 - val_loss: 0.7131 - val_accuracy: 0.6963\n",
            "Epoch 9/20\n",
            "495/502 [============================>.] - ETA: 0s - loss: 0.5972 - accuracy: 0.7535\n",
            "Epoch 9: val_loss improved from 0.71307 to 0.70911, saving model to saved_models/nlp_model_8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r502/502 [==============================] - 3s 7ms/step - loss: 0.5968 - accuracy: 0.7542 - val_loss: 0.7091 - val_accuracy: 0.6998\n",
            "Epoch 10/20\n",
            "495/502 [============================>.] - ETA: 0s - loss: 0.5802 - accuracy: 0.7626\n",
            "Epoch 10: val_loss improved from 0.70911 to 0.70764, saving model to saved_models/nlp_model_8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r502/502 [==============================] - 3s 7ms/step - loss: 0.5799 - accuracy: 0.7632 - val_loss: 0.7076 - val_accuracy: 0.7025\n",
            "Epoch 11/20\n",
            "496/502 [============================>.] - ETA: 0s - loss: 0.5651 - accuracy: 0.7713\n",
            "Epoch 11: val_loss improved from 0.70764 to 0.70651, saving model to saved_models/nlp_model_8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r502/502 [==============================] - 3s 7ms/step - loss: 0.5645 - accuracy: 0.7720 - val_loss: 0.7065 - val_accuracy: 0.7010\n",
            "Epoch 12/20\n",
            "496/502 [============================>.] - ETA: 0s - loss: 0.5511 - accuracy: 0.7775\n",
            "Epoch 12: val_loss improved from 0.70651 to 0.70650, saving model to saved_models/nlp_model_8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r502/502 [==============================] - 3s 7ms/step - loss: 0.5505 - accuracy: 0.7781 - val_loss: 0.7065 - val_accuracy: 0.7038\n",
            "Epoch 13/20\n",
            "493/502 [============================>.] - ETA: 0s - loss: 0.5377 - accuracy: 0.7835\n",
            "Epoch 13: val_loss did not improve from 0.70650\n",
            "502/502 [==============================] - 3s 5ms/step - loss: 0.5380 - accuracy: 0.7839 - val_loss: 0.7068 - val_accuracy: 0.7060\n",
            "Epoch 14/20\n",
            "499/502 [============================>.] - ETA: 0s - loss: 0.5265 - accuracy: 0.7911\n",
            "Epoch 14: val_loss did not improve from 0.70650\n",
            "502/502 [==============================] - 3s 5ms/step - loss: 0.5262 - accuracy: 0.7913 - val_loss: 0.7098 - val_accuracy: 0.7035\n",
            "Epoch 15/20\n",
            "496/502 [============================>.] - ETA: 0s - loss: 0.5161 - accuracy: 0.7946\n",
            "Epoch 15: val_loss did not improve from 0.70650\n",
            "502/502 [==============================] - 3s 5ms/step - loss: 0.5157 - accuracy: 0.7950 - val_loss: 0.7127 - val_accuracy: 0.7033\n",
            "Epoch 16/20\n",
            "499/502 [============================>.] - ETA: 0s - loss: 0.5060 - accuracy: 0.7997\n",
            "Epoch 16: val_loss did not improve from 0.70650\n",
            "502/502 [==============================] - 3s 5ms/step - loss: 0.5056 - accuracy: 0.7999 - val_loss: 0.7157 - val_accuracy: 0.7028\n",
            "Epoch 17/20\n",
            "495/502 [============================>.] - ETA: 0s - loss: 0.4966 - accuracy: 0.8031\n",
            "Epoch 17: val_loss did not improve from 0.70650\n",
            "Restoring model weights from the end of the best epoch: 12.\n",
            "502/502 [==============================] - 3s 5ms/step - loss: 0.4967 - accuracy: 0.8033 - val_loss: 0.7199 - val_accuracy: 0.7048\n",
            "Epoch 17: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_8.evaluate(test_dataset)\n",
        "model_8_loaded = tf.keras.models.load_model(\"saved_models/nlp_model_8\")\n",
        "model_8_preds = model_8_loaded.predict(test_dataset)\n",
        "model_8_results = calculate_results(test_labels, tf.argmax(model_8_preds, axis=1))\n",
        "model_results_dataset['model_8'] = model_8_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MUp672VuilhL",
        "outputId": "3e97db14-9bdb-4c18-8a67-d3e1023af627"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "126/126 [==============================] - 0s 3ms/step - loss: 3.6517 - accuracy: 0.3351\n",
            "126/126 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()"
      ],
      "metadata": {
        "id": "3ifg-Yq3iuMM"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Setup token inputs/model\n",
        "token_inputs = layers.Input(shape=[], dtype=tf.string, name=\"token_input\")\n",
        "token_embeddings = tf_hub_embedding_layer(token_inputs)\n",
        "token_output = layers.Dense(128, activation=\"relu\")(token_embeddings)\n",
        "token_model = tf.keras.Model(inputs=token_inputs,\n",
        "                             outputs=token_output)\n",
        "\n",
        "# 2. Setup char inputs/model\n",
        "char_inputs = layers.Input(shape=(1,), dtype=tf.string, name=\"char_input\")\n",
        "char_vectors = char_vectorizer(char_inputs)\n",
        "char_embeddings = char_embed(char_vectors)\n",
        "char_bi_lstm = layers.Bidirectional(layers.LSTM(25))(char_embeddings) # bi-LSTM shown in Figure 1 of https://arxiv.org/pdf/1612.05251.pdf\n",
        "char_model = tf.keras.Model(inputs=char_inputs,\n",
        "                            outputs=char_bi_lstm)\n",
        "\n",
        "# 3. Concatenate token and char inputs (create hybrid token embedding)\n",
        "token_char_concat = layers.Concatenate(name=\"token_char_hybrid\")([token_model.output, \n",
        "                                                                  char_model.output])\n",
        "\n",
        "# 4. Create output layers - addition of dropout discussed in 4.2 of https://arxiv.org/pdf/1612.05251.pdf\n",
        "combined_dropout = layers.Dropout(0.5)(token_char_concat)\n",
        "combined_dense = layers.Dense(200, activation=\"relu\")(combined_dropout) # slightly different to Figure 1 due to different shapes of token/char embedding layers\n",
        "final_dropout = layers.Dropout(0.5)(combined_dense)\n",
        "output_layer = layers.Dense(4, activation=\"softmax\")(final_dropout)\n",
        "\n",
        "# 5. Construct model with char and token inputs\n",
        "model_9 = tf.keras.Model(inputs=[token_model.input, char_model.input],\n",
        "                         outputs=output_layer,\n",
        "                         name=\"nlp_model_9\")"
      ],
      "metadata": {
        "id": "VIs6woVGiw8Y"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile token char model\n",
        "model_9.compile(loss=\"categorical_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(), # section 4.2 of https://arxiv.org/pdf/1612.05251.pdf mentions using SGD but we'll stick with Adam\n",
        "                metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "ZgxWKaSXiy4E"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine chars and tokens into a dataset\n",
        "train_char_token_data = tf.data.Dataset.from_tensor_slices((train_data, train_chars)) # make data\n",
        "train_char_token_labels = tf.data.Dataset.from_tensor_slices(train_labels_one_hot) # make labels\n",
        "train_char_token_dataset = tf.data.Dataset.zip((train_char_token_data, train_char_token_labels)) # combine data and labels\n",
        "\n",
        "# Prefetch and batch train data\n",
        "train_char_token_dataset = train_char_token_dataset.batch(32).prefetch(tf.data.AUTOTUNE) \n",
        "\n",
        "# Repeat same steps validation data\n",
        "val_char_token_data = tf.data.Dataset.from_tensor_slices((test_data, test_chars))\n",
        "val_char_token_labels = tf.data.Dataset.from_tensor_slices(test_labels_one_hot)\n",
        "val_char_token_dataset = tf.data.Dataset.zip((val_char_token_data, val_char_token_labels))\n",
        "val_char_token_dataset = val_char_token_dataset.batch(32).prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "GDcZKDlxi0b9"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_9 = model_9.fit(train_char_token_dataset, epochs=20, validation_data=val_char_token_dataset, callbacks=return_callbacks(model_9.name))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 744
        },
        "id": "k-sZ8kIDi2Vx",
        "outputId": "97067a01-038a-4fb4-ae0c-a3b51bc07409"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-58-52aa9280dfc8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory_9\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_9\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_char_token_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_char_token_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_9\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 890, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 948, in compute_loss\n        return self.compiled_loss(\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/compile_utils.py\", line 201, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/losses.py\", line 139, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/losses.py\", line 243, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/losses.py\", line 1787, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"/usr/local/lib/python3.8/dist-packages/keras/backend.py\", line 5119, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 3) and (None, 4) are incompatible\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()"
      ],
      "metadata": {
        "id": "v1ietYX9i4fz"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_10_embedding = tf.keras.layers.Embedding(input_dim=10000, output_dim=128, embeddings_initializer=\"uniform\", input_length=output_seq_length, name=\"embedding_6\")\n",
        "\n",
        "inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
        "x = tv_layer(inputs)\n",
        "x = model_10_embedding(x)\n",
        "x = layers.Conv1D(128, 5, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling1D(5)(x)\n",
        "x = layers.Conv1D(128, 5, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling1D(5)(x)\n",
        "x = layers.Conv1D(128, 5, activation=\"relu\")(x)\n",
        "x = layers.GlobalMaxPooling1D()(x)\n",
        "x = layers.Dense(128, activation=\"relu\")(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "preds = layers.Dense(NUM_CLASSES, activation=\"softmax\")(x)\n",
        "model_10 = tf.keras.Model(inputs, preds, name=\"nlp_model_10\")\n",
        "model_10.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "KDza402Ki6rJ",
        "outputId": "a0208249-3cb3-45ff-eb02-13725dc250b1"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-63-c185d84d6009>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"relu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaxPooling1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"relu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaxPooling1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"relu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/layers/convolutional/base_conv.py\u001b[0m in \u001b[0;36mcompute_output_shape\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m       raise ValueError(\n\u001b[0m\u001b[1;32m    308\u001b[0m           \u001b[0;34mf'One of the dimensions in the output is <= 0 '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m           \u001b[0;34mf'due to downsampling in {self.name}. Consider '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: One of the dimensions in the output is <= 0 due to downsampling in conv1d_3. Consider increasing the input size. Received input shape [None, 2, 128] which would produce output shape with a zero or negative value in a dimension."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_10.compile(loss=\"categorical_crossentropy\", # if your labels are integer form (not one hot) use sparse_categorical_crossentropy\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "history_10 = model_10.fit(train_dataset, epochs=20, validation_data=test_dataset,callbacks=return_callbacks(model_10.name))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "id": "G8dqGVZIi8NW",
        "outputId": "66e4f4c3-d22f-487c-bc6b-f7aef396f581"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-61-e254edf43ef9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m model_10.compile(loss=\"categorical_crossentropy\", # if your labels are integer form (not one hot) use sparse_categorical_crossentropy\n\u001b[0m\u001b[1;32m      2\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                 metrics=[\"accuracy\"])\n\u001b[1;32m      4\u001b[0m \u001b[0mhistory_10\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_10\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_10\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model_10' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_10.evaluate(test_dataset)\n",
        "model_10_loaded = tf.keras.models.load_model(\"saved_models/nlp_model_10\")\n",
        "model_10_preds = model_10_loaded.predict(test_dataset)\n",
        "model_10_results = calculate_results(test_labels, tf.argmax(model_10_preds, axis=1))\n",
        "model_results_dataset['model_10'] = model_10_results"
      ],
      "metadata": {
        "id": "Ho58Uougi98w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe = pd.DataFrame(model_results_dataset).T\n",
        "dataframe['accuracy'] = dataframe['accuracy'].div(100)\n",
        "dataframe"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "CF1Kr45ujAL3",
        "outputId": "709533f3-844a-4f19-e5d0-739dd9f11056"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         accuracy  precision    recall  f1_score\n",
              "model_0  0.618585   0.745130  0.618585  0.560000\n",
              "model_1  0.868710   0.869509  0.868710  0.866308\n",
              "model_2  0.873692   0.873005  0.873692  0.872152\n",
              "model_3  0.880668   0.880740  0.880668  0.879637\n",
              "model_4  0.890135   0.889577  0.890135  0.889752\n",
              "model_5  0.888391   0.888014  0.888391  0.888115\n",
              "model_6  0.888640   0.888147  0.888640  0.887519\n",
              "model_7  0.728201   0.724687  0.728201  0.722025\n",
              "model_8  0.335077   0.112277  0.335077  0.168195"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a5e3ef76-5908-4feb-a2b0-090e06db8c7c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accuracy</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>model_0</th>\n",
              "      <td>0.618585</td>\n",
              "      <td>0.745130</td>\n",
              "      <td>0.618585</td>\n",
              "      <td>0.560000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>model_1</th>\n",
              "      <td>0.868710</td>\n",
              "      <td>0.869509</td>\n",
              "      <td>0.868710</td>\n",
              "      <td>0.866308</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>model_2</th>\n",
              "      <td>0.873692</td>\n",
              "      <td>0.873005</td>\n",
              "      <td>0.873692</td>\n",
              "      <td>0.872152</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>model_3</th>\n",
              "      <td>0.880668</td>\n",
              "      <td>0.880740</td>\n",
              "      <td>0.880668</td>\n",
              "      <td>0.879637</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>model_4</th>\n",
              "      <td>0.890135</td>\n",
              "      <td>0.889577</td>\n",
              "      <td>0.890135</td>\n",
              "      <td>0.889752</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>model_5</th>\n",
              "      <td>0.888391</td>\n",
              "      <td>0.888014</td>\n",
              "      <td>0.888391</td>\n",
              "      <td>0.888115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>model_6</th>\n",
              "      <td>0.888640</td>\n",
              "      <td>0.888147</td>\n",
              "      <td>0.888640</td>\n",
              "      <td>0.887519</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>model_7</th>\n",
              "      <td>0.728201</td>\n",
              "      <td>0.724687</td>\n",
              "      <td>0.728201</td>\n",
              "      <td>0.722025</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>model_8</th>\n",
              "      <td>0.335077</td>\n",
              "      <td>0.112277</td>\n",
              "      <td>0.335077</td>\n",
              "      <td>0.168195</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a5e3ef76-5908-4feb-a2b0-090e06db8c7c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a5e3ef76-5908-4feb-a2b0-090e06db8c7c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a5e3ef76-5908-4feb-a2b0-090e06db8c7c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe.plot.bar()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "kloWwtWMjBtO",
        "outputId": "1ba7d11f-3c59-4eb2-87b4-0e1dd8b99b37"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f3bd71ff220>"
            ]
          },
          "metadata": {},
          "execution_count": 65
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M3T6t38yjDTf"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMWDmhv8epmqLcgqv8uZtHU",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}