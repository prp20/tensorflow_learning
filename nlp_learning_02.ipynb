{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNuxPc9uLW7AcJfGChWKnlT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prp20/tensorflow_learning/blob/main/nlp_learning_02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "bKzB8hJif5PD",
        "outputId": "49eeaee2-fac3-4adc-8f6f-14164daf4c9b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.9.2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "tf.__version__"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, val_data, test_data = tfds.load(name=\"ag_news_subset\", split=('train[:80%]', 'train[80%:]', 'test'), batch_size=-1, as_supervised=True)"
      ],
      "metadata": {
        "id": "mIG01te3gNKS"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_examples, train_labels = tfds.as_numpy(train_data)\n",
        "train_labels = np.asarray(train_labels).astype('float32').reshape((-1,1))\n",
        "val_examples, val_labels = tfds.as_numpy(val_data)\n",
        "val_labels = np.asarray(val_labels).astype('float32').reshape((-1,1))\n",
        "test_examples, test_labels = tfds.as_numpy(test_data)\n",
        "test_labels = np.asarray(test_labels).astype('float32').reshape((-1,1))"
      ],
      "metadata": {
        "id": "xymV6HZcgWbv"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "one_hot_encoder = OneHotEncoder(sparse=False)\n",
        "train_labels_one_hot = one_hot_encoder.fit_transform(train_labels)\n",
        "val_labels_one_hot = one_hot_encoder.transform(val_labels)\n",
        "test_labels_one_hot = one_hot_encoder.transform(test_labels)\n",
        "\n",
        "# Check what training labels look like\n",
        "train_labels_one_hot"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GGSARSJft0B9",
        "outputId": "58875882-656b-46cd-9fdf-3241647b62ab"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 1.],\n",
              "       [0., 1., 0., 0.],\n",
              "       [0., 0., 1., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., 1.],\n",
              "       [1., 0., 0., 0.],\n",
              "       [0., 0., 0., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_examples), len(val_examples), len(test_examples)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hpX9_Nmehu22",
        "outputId": "5895a68f-c438-4580-86dd-863f936fc125"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(96000, 24000, 7600)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_examples[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKsgcmITh3uk",
        "outputId": "1bde7277-c33d-4a36-ebce-f5692d6b7e3a"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([b'AMD #39;s new dual-core Opteron chip is designed mainly for corporate computing applications, including databases, Web services, and financial transactions.',\n",
              "       b'Reuters - Major League Baseball\\\\Monday announced a decision on the appeal filed by Chicago Cubs\\\\pitcher Kerry Wood regarding a suspension stemming from an\\\\incident earlier this season.',\n",
              "       b'President Bush #39;s  quot;revenue-neutral quot; tax reform needs losers to balance its winners, and people claiming the federal deduction for state and local taxes may be in administration planners #39; sights, news reports say.',\n",
              "       b'Britain will run out of leading scientists unless science education is improved, says Professor Colin Pillinger.',\n",
              "       b'London, England (Sports Network) - England midfielder Steven Gerrard injured his groin late in Thursday #39;s training session, but is hopeful he will be ready for Saturday #39;s World Cup qualifier against Austria.',\n",
              "       b'TOKYO - Sony Corp. is banking on the \\\\$3 billion deal to acquire Hollywood studio Metro-Goldwyn-Mayer Inc...',\n",
              "       b'Giant pandas may well prefer bamboo to laptops, but wireless technology is helping researchers in China in their efforts to protect the engandered animals living in the remote Wolong Nature Reserve.',\n",
              "       b'VILNIUS, Lithuania - Lithuania #39;s main parties formed an alliance to try to keep a Russian-born tycoon and his populist promises out of the government in Sunday #39;s second round of parliamentary elections in this Baltic country.',\n",
              "       b'Witnesses in the trial of a US soldier charged with abusing prisoners at Abu Ghraib have told the court that the CIA sometimes directed abuse and orders were received from military command to toughen interrogations.',\n",
              "       b'Dan Olsen of Ponte Vedra Beach, Fla., shot a 7-under 65 Thursday to take a one-shot lead after two rounds of the PGA Tour qualifying tournament.'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CgFBHvFJiAt6",
        "outputId": "fddb17db-3d3a-4aed-91c9-a001324fd473"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3.],\n",
              "       [1.],\n",
              "       [2.],\n",
              "       [3.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [3.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import TextVectorization"
      ],
      "metadata": {
        "id": "Wxh290c9i2Mu"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_seq_length = round(sum([len(i.split()) for i in train_examples])/len(train_examples))"
      ],
      "metadata": {
        "id": "Xlx331OojDbI"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_seq_length"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tDTaOAE5jH87",
        "outputId": "0471f483-9962-44f2-d45f-3b858b79edb5"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "31"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tv_layer = TextVectorization(max_tokens=10000, standardize=\"lower_and_strip_punctuation\", split=\"whitespace\", output_mode=\"int\", output_sequence_length=output_seq_length, pad_to_max_tokens=True)\n",
        "tv_layer.adapt(train_examples)"
      ],
      "metadata": {
        "id": "npg0lPcRjKAl"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "embedding_layer = layers.Embedding(input_dim=10000, output_dim=128, input_length=output_seq_length)"
      ],
      "metadata": {
        "id": "HpdTiLnfjbM9"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 0: Baseline Model"
      ],
      "metadata": {
        "id": "iBWP2T29VlTv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "model_0 = Pipeline([\n",
        "    (\"tfidf\", TfidfVectorizer()),\n",
        "    (\"clf\", MultinomialNB())\n",
        "])\n",
        "model_0.fit(train_examples, train_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZb0bMeFjv_i",
        "outputId": "e28c1af7-143b-47ff-f23b-f98dfb014fe6"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('tfidf', TfidfVectorizer()), ('clf', MultinomialNB())])"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluate the baseline model\n",
        "\n",
        "model_0_score = model_0.score(val_examples, val_labels)\n",
        "model_0_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VbbiW8aNj1w0",
        "outputId": "4011d42b-769f-4370-f367-ea1e9e74d6be"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8945833333333333"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_0_preds = model_0.predict(val_examples)"
      ],
      "metadata": {
        "id": "2znmTg6XlQbW"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "def calculate_results(y_true, y_pred):\n",
        "  model_accuracy = accuracy_score(y_true, y_pred) * 100\n",
        "  model_precision, model_recall, model_f1_score, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
        "  model_results = {\n",
        "      \"accuracy\": model_accuracy,\n",
        "      \"precision\":model_precision,\n",
        "      \"recall\": model_recall,\n",
        "      \"f1_score\": model_f1_score\n",
        "  }\n",
        "  return model_results\n",
        "\n",
        "def return_callbacks(model_name):\n",
        "  callbacks_list = []\n",
        "  callbacks_list.append(tf.keras.callbacks.ModelCheckpoint(\"saved_models/\"+model_name, monitor='val_loss', save_best_only='True', verbose=1))\n",
        "  callbacks_list.append(tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1, restore_best_weights='True'))\n",
        "  return callbacks_list"
      ],
      "metadata": {
        "id": "WUhzLsCilWWG"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_0_results = calculate_results(val_labels, model_0_preds)\n",
        "model_0_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rZb82QiJlaul",
        "outputId": "0fb933ca-bca1-490b-a3d2-bafea38044f5"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 89.45833333333333,\n",
              " 'precision': 0.8942110979847542,\n",
              " 'recall': 0.8945833333333333,\n",
              " 'f1_score': 0.8942914902694554}"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_results_dataset = {}\n",
        "model_results_dataset['model_0'] = model_0_results"
      ],
      "metadata": {
        "id": "omE4gUyWleoF"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_examples, train_labels_one_hot))\n",
        "valid_dataset = tf.data.Dataset.from_tensor_slices((val_examples, val_labels_one_hot))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_examples, test_labels_one_hot))\n",
        "\n",
        "# Take the TensorSliceDataset's and turn them into prefetched batches\n",
        "train_dataset = train_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "valid_dataset = valid_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "test_dataset = test_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "train_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47G601NIucg6",
        "outputId": "bb5e25f3-acd2-466d-fbfc-51eb461969f6"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PrefetchDataset element_spec=(TensorSpec(shape=(None,), dtype=tf.string, name=None), TensorSpec(shape=(None, 4), dtype=tf.float64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 1: Simple NN Model"
      ],
      "metadata": {
        "id": "hupkYZ6vVrQg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
        "x = tv_layer(inputs)\n",
        "x = embedding_layer(x)\n",
        "x = layers.GlobalAveragePooling1D()(x)\n",
        "output = layers.Dense(4, activation='softmax')(x)\n",
        "\n",
        "model_1 = tf.keras.Model(inputs, output, name=\"nlp_model_1\")\n",
        "model_1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NTpiSR6Vl5DP",
        "outputId": "c50e548b-0a69-44b1-8546-7e84a4511732"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"nlp_model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 31)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding_1 (Embedding)     (None, 31, 128)           1280000   \n",
            "                                                                 \n",
            " global_average_pooling1d_3   (None, 128)              0         \n",
            " (GlobalAveragePooling1D)                                        \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 4)                 516       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,280,516\n",
            "Trainable params: 1,280,516\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.compile(loss=\"categorical_crossentropy\", optimizer=tf.keras.optimizers.Adam(), metrics=[\"accuracy\"])\n",
        "history_1 = model_1.fit(train_dataset, epochs=20, validation_data=valid_dataset, callbacks=return_callbacks(model_1.name))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aHvtDdl4l7vB",
        "outputId": "e4b32d04-b421-415c-919a-cfb76f2fd6f5"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "2991/3000 [============================>.] - ETA: 0s - loss: 0.3359 - accuracy: 0.9085\n",
            "Epoch 1: val_loss improved from inf to 0.29563, saving model to saved_models/nlp_model_1\n",
            "3000/3000 [==============================] - 14s 5ms/step - loss: 0.3356 - accuracy: 0.9085 - val_loss: 0.2956 - val_accuracy: 0.9015\n",
            "Epoch 2/20\n",
            "2996/3000 [============================>.] - ETA: 0s - loss: 0.2215 - accuracy: 0.9250\n",
            "Epoch 2: val_loss did not improve from 0.29563\n",
            "3000/3000 [==============================] - 13s 4ms/step - loss: 0.2214 - accuracy: 0.9250 - val_loss: 0.3022 - val_accuracy: 0.8983\n",
            "Epoch 3/20\n",
            "2986/3000 [============================>.] - ETA: 0s - loss: 0.2033 - accuracy: 0.9308\n",
            "Epoch 3: val_loss did not improve from 0.29563\n",
            "3000/3000 [==============================] - 14s 5ms/step - loss: 0.2031 - accuracy: 0.9308 - val_loss: 0.3135 - val_accuracy: 0.8958\n",
            "Epoch 4/20\n",
            "2991/3000 [============================>.] - ETA: 0s - loss: 0.1911 - accuracy: 0.9343\n",
            "Epoch 4: val_loss did not improve from 0.29563\n",
            "3000/3000 [==============================] - 13s 4ms/step - loss: 0.1911 - accuracy: 0.9344 - val_loss: 0.3260 - val_accuracy: 0.8926\n",
            "Epoch 5/20\n",
            "2989/3000 [============================>.] - ETA: 0s - loss: 0.1822 - accuracy: 0.9373\n",
            "Epoch 5: val_loss did not improve from 0.29563\n",
            "3000/3000 [==============================] - 13s 4ms/step - loss: 0.1821 - accuracy: 0.9374 - val_loss: 0.3391 - val_accuracy: 0.8898\n",
            "Epoch 6/20\n",
            "2994/3000 [============================>.] - ETA: 0s - loss: 0.1750 - accuracy: 0.9398\n",
            "Epoch 6: val_loss did not improve from 0.29563\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "3000/3000 [==============================] - 13s 4ms/step - loss: 0.1749 - accuracy: 0.9398 - val_loss: 0.3526 - val_accuracy: 0.8876\n",
            "Epoch 6: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.evaluate(valid_dataset)\n",
        "model_1_loaded = tf.keras.models.load_model(\"saved_models/nlp_model_1\")\n",
        "model_1_preds = model_1_loaded.predict(valid_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4oiynGw4mQDI",
        "outputId": "e35ce84b-f077-4488-b8f5-3002d101d6df"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "750/750 [==============================] - 3s 3ms/step - loss: 0.2956 - accuracy: 0.9015\n",
            "750/750 [==============================] - 2s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_1_results = calculate_results(val_labels, tf.argmax(model_1_preds, axis=1))\n",
        "model_results_dataset['model_1'] = model_1_results"
      ],
      "metadata": {
        "id": "MEpANS_nsaWh"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_results_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G5D9XkJts-EN",
        "outputId": "5e04277b-82c6-4fc3-c805-db6fc15daef0"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'model_0': {'accuracy': 89.45833333333333,\n",
              "  'precision': 0.8942110979847542,\n",
              "  'recall': 0.8945833333333333,\n",
              "  'f1_score': 0.8942914902694554},\n",
              " 'model_1': {'accuracy': 90.15416666666667,\n",
              "  'precision': 0.9018170319238884,\n",
              "  'recall': 0.9015416666666667,\n",
              "  'f1_score': 0.9014919230703585}}"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()"
      ],
      "metadata": {
        "id": "rr_D8GeswGPv"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 2"
      ],
      "metadata": {
        "id": "GD6coUPXwMHy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "model_2_embedding = layers.Embedding(input_dim=10000, output_dim=128, embeddings_initializer=\"uniform\", input_length=output_seq_length, name=\"embedding_2\")\n",
        "inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
        "x = tv_layer(inputs)\n",
        "x = model_2_embedding(x)\n",
        "x = layers.GlobalAveragePooling1D()(x)\n",
        "x = layers.Dense(64, activation='relu')(x)\n",
        "output = layers.Dense(4, activation='softmax')(x)\n",
        "\n",
        "model_2 = tf.keras.Model(inputs, output, name=\"nlp_model_2\")\n",
        "model_2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4f44wu3wK5n",
        "outputId": "88a7a2a7-eec1-4617-a855-8e2bf45bcb9b"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"nlp_model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 31)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding_2 (Embedding)     (None, 31, 128)           1280000   \n",
            "                                                                 \n",
            " global_average_pooling1d (G  (None, 128)              0         \n",
            " lobalAveragePooling1D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 4)                 260       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,288,516\n",
            "Trainable params: 1,288,516\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_2.compile(loss=\"categorical_crossentropy\", optimizer=tf.keras.optimizers.Adam(), metrics=[\"accuracy\"])\n",
        "history_2 = model_2.fit(train_dataset, epochs=20, validation_data=valid_dataset,callbacks=return_callbacks(model_2.name))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wvgS6wqYwa9v",
        "outputId": "241a7fae-3d22-463c-df50-39ecdf99799b"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "2990/3000 [============================>.] - ETA: 0s - loss: 0.3694 - accuracy: 0.8746\n",
            "Epoch 1: val_loss improved from inf to 0.29245, saving model to saved_models/nlp_model_2\n",
            "3000/3000 [==============================] - 16s 5ms/step - loss: 0.3692 - accuracy: 0.8746 - val_loss: 0.2924 - val_accuracy: 0.8991\n",
            "Epoch 2/20\n",
            "2988/3000 [============================>.] - ETA: 0s - loss: 0.2356 - accuracy: 0.9172\n",
            "Epoch 2: val_loss did not improve from 0.29245\n",
            "3000/3000 [==============================] - 17s 6ms/step - loss: 0.2355 - accuracy: 0.9172 - val_loss: 0.3007 - val_accuracy: 0.8969\n",
            "Epoch 3/20\n",
            "2998/3000 [============================>.] - ETA: 0s - loss: 0.1999 - accuracy: 0.9291\n",
            "Epoch 3: val_loss did not improve from 0.29245\n",
            "3000/3000 [==============================] - 16s 5ms/step - loss: 0.1999 - accuracy: 0.9290 - val_loss: 0.3217 - val_accuracy: 0.8940\n",
            "Epoch 4/20\n",
            "2996/3000 [============================>.] - ETA: 0s - loss: 0.1719 - accuracy: 0.9384\n",
            "Epoch 4: val_loss did not improve from 0.29245\n",
            "3000/3000 [==============================] - 14s 5ms/step - loss: 0.1718 - accuracy: 0.9384 - val_loss: 0.3549 - val_accuracy: 0.8914\n",
            "Epoch 5/20\n",
            "2988/3000 [============================>.] - ETA: 0s - loss: 0.1466 - accuracy: 0.9477\n",
            "Epoch 5: val_loss did not improve from 0.29245\n",
            "3000/3000 [==============================] - 13s 4ms/step - loss: 0.1464 - accuracy: 0.9477 - val_loss: 0.4029 - val_accuracy: 0.8902\n",
            "Epoch 6/20\n",
            "2999/3000 [============================>.] - ETA: 0s - loss: 0.1225 - accuracy: 0.9574\n",
            "Epoch 6: val_loss did not improve from 0.29245\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "3000/3000 [==============================] - 13s 4ms/step - loss: 0.1226 - accuracy: 0.9573 - val_loss: 0.4629 - val_accuracy: 0.8866\n",
            "Epoch 6: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_2.evaluate(valid_dataset)\n",
        "model_2_loaded = tf.keras.models.load_model(\"saved_models/nlp_model_2\")\n",
        "model_2_preds = model_2_loaded.predict(valid_dataset)\n",
        "model_2_results = calculate_results(val_labels, tf.argmax(model_2_preds, axis=1))\n",
        "model_results_dataset['model_2'] = model_2_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cIu1_iOCwqND",
        "outputId": "aba82741-0427-4a9f-9ffc-b1e6d2af8362"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2924 - accuracy: 0.8991\n",
            "750/750 [==============================] - 2s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 3: LSTM"
      ],
      "metadata": {
        "id": "RQXaT1MsxIPS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()"
      ],
      "metadata": {
        "id": "Wx1jQDHCw49y"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "model_3_embedding = layers.Embedding(input_dim=10000, output_dim=128, embeddings_initializer=\"uniform\", input_length=output_seq_length, name=\"embedding_2\")\n",
        "\n",
        "inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
        "x = tv_layer(inputs)\n",
        "x = model_3_embedding(x)\n",
        "x = layers.LSTM(64)(x)\n",
        "x = layers.Dense(64, activation='relu')(x)\n",
        "output = layers.Dense(4, activation='softmax')(x)\n",
        "\n",
        "model_3 = tf.keras.Model(inputs, output, name=\"nlp_model_3\")\n",
        "model_3.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_WFrDJRMxNYB",
        "outputId": "2077a577-1ac1-4151-b9f6-57f4333a3d3e"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"nlp_model_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 31)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding_2 (Embedding)     (None, 31, 128)           1280000   \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 64)                49408     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 4)                 260       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,333,828\n",
            "Trainable params: 1,333,828\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_3.compile(loss=\"categorical_crossentropy\", optimizer=tf.keras.optimizers.Adam(), metrics=[\"accuracy\"])\n",
        "history_3 = model_3.fit(train_dataset, epochs=20, validation_data=valid_dataset,callbacks=return_callbacks(model_3.name))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gl7WQVuVxRtg",
        "outputId": "f4b8a9da-d8f5-4933-c729-adafb63095ba"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "2999/3000 [============================>.] - ETA: 0s - loss: 0.3831 - accuracy: 0.8655\n",
            "Epoch 1: val_loss improved from inf to 0.32339, saving model to saved_models/nlp_model_3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3000/3000 [==============================] - 31s 10ms/step - loss: 0.3832 - accuracy: 0.8655 - val_loss: 0.3234 - val_accuracy: 0.8874\n",
            "Epoch 2/20\n",
            "2997/3000 [============================>.] - ETA: 0s - loss: 0.2570 - accuracy: 0.9130\n",
            "Epoch 2: val_loss did not improve from 0.32339\n",
            "3000/3000 [==============================] - 24s 8ms/step - loss: 0.2571 - accuracy: 0.9130 - val_loss: 0.3381 - val_accuracy: 0.8894\n",
            "Epoch 3/20\n",
            "3000/3000 [==============================] - ETA: 0s - loss: 0.1986 - accuracy: 0.9319\n",
            "Epoch 3: val_loss did not improve from 0.32339\n",
            "3000/3000 [==============================] - 21s 7ms/step - loss: 0.1986 - accuracy: 0.9319 - val_loss: 0.3783 - val_accuracy: 0.8866\n",
            "Epoch 4/20\n",
            "2998/3000 [============================>.] - ETA: 0s - loss: 0.1452 - accuracy: 0.9490\n",
            "Epoch 4: val_loss did not improve from 0.32339\n",
            "3000/3000 [==============================] - 22s 7ms/step - loss: 0.1452 - accuracy: 0.9490 - val_loss: 0.4092 - val_accuracy: 0.8870\n",
            "Epoch 5/20\n",
            "2996/3000 [============================>.] - ETA: 0s - loss: 0.1062 - accuracy: 0.9629\n",
            "Epoch 5: val_loss did not improve from 0.32339\n",
            "3000/3000 [==============================] - 22s 7ms/step - loss: 0.1061 - accuracy: 0.9629 - val_loss: 0.4757 - val_accuracy: 0.8867\n",
            "Epoch 6/20\n",
            "2995/3000 [============================>.] - ETA: 0s - loss: 0.0771 - accuracy: 0.9735\n",
            "Epoch 6: val_loss did not improve from 0.32339\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "3000/3000 [==============================] - 21s 7ms/step - loss: 0.0771 - accuracy: 0.9735 - val_loss: 0.5393 - val_accuracy: 0.8782\n",
            "Epoch 6: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_3.evaluate(valid_dataset)\n",
        "model_3_loaded = tf.keras.models.load_model(\"saved_models/nlp_model_3\")\n",
        "model_3_preds = model_3_loaded.predict(valid_dataset)\n",
        "model_3_results = calculate_results(val_labels, tf.argmax(model_3_preds, axis=1))\n",
        "model_results_dataset['model_3'] = model_3_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Xgk-zDTxZIu",
        "outputId": "a69c1a62-96c1-457b-d582-ec240419a49d"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "750/750 [==============================] - 3s 4ms/step - loss: 0.3234 - accuracy: 0.8874\n",
            "750/750 [==============================] - 3s 3ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 4: GRU"
      ],
      "metadata": {
        "id": "Ip6yZ2vbyH-e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()"
      ],
      "metadata": {
        "id": "80-Jji6qxmn-"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "model_4_embedding = layers.Embedding(input_dim=10000, output_dim=128, embeddings_initializer=\"uniform\", input_length=output_seq_length, name=\"embedding_4\")\n",
        "\n",
        "inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
        "x = tv_layer(inputs)\n",
        "x = model_4_embedding(x)\n",
        "x = layers.LSTM(64, return_sequences=True)(x)\n",
        "x = layers.GRU(64)(x)\n",
        "x = layers.Dense(64, activation='relu')(x)\n",
        "output = layers.Dense(4, activation='softmax')(x)\n",
        "\n",
        "model_4 = tf.keras.Model(inputs, output, name=\"nlp_model_4\")\n",
        "model_4.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5V2BGvw4yMSX",
        "outputId": "b7d5d205-5f5f-429a-bf2f-989c27d2bdb2"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"nlp_model_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 31)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding_4 (Embedding)     (None, 31, 128)           1280000   \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 31, 64)            49408     \n",
            "                                                                 \n",
            " gru (GRU)                   (None, 64)                24960     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 4)                 260       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,358,788\n",
            "Trainable params: 1,358,788\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_4.compile(loss=\"categorical_crossentropy\", optimizer=tf.keras.optimizers.Adam(), metrics=[\"accuracy\"])\n",
        "history_4 = model_4.fit(train_dataset, epochs=20, validation_data=valid_dataset,callbacks=return_callbacks(model_4.name))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eacrd_ChyRmZ",
        "outputId": "7ba03ea4-e8ec-47e6-feb1-b8e4be09e56f"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "2997/3000 [============================>.] - ETA: 0s - loss: 0.3925 - accuracy: 0.8611\n",
            "Epoch 1: val_loss improved from inf to 0.31742, saving model to saved_models/nlp_model_4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, gru_cell_layer_call_fn, gru_cell_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3000/3000 [==============================] - 45s 14ms/step - loss: 0.3925 - accuracy: 0.8611 - val_loss: 0.3174 - val_accuracy: 0.8945\n",
            "Epoch 2/20\n",
            "2997/3000 [============================>.] - ETA: 0s - loss: 0.2584 - accuracy: 0.9132\n",
            "Epoch 2: val_loss did not improve from 0.31742\n",
            "3000/3000 [==============================] - 29s 10ms/step - loss: 0.2584 - accuracy: 0.9132 - val_loss: 0.3275 - val_accuracy: 0.8914\n",
            "Epoch 3/20\n",
            "2997/3000 [============================>.] - ETA: 0s - loss: 0.1970 - accuracy: 0.9328\n",
            "Epoch 3: val_loss did not improve from 0.31742\n",
            "3000/3000 [==============================] - 34s 11ms/step - loss: 0.1970 - accuracy: 0.9327 - val_loss: 0.3466 - val_accuracy: 0.8916\n",
            "Epoch 4/20\n",
            "3000/3000 [==============================] - ETA: 0s - loss: 0.1403 - accuracy: 0.9521\n",
            "Epoch 4: val_loss did not improve from 0.31742\n",
            "3000/3000 [==============================] - 35s 12ms/step - loss: 0.1403 - accuracy: 0.9521 - val_loss: 0.4290 - val_accuracy: 0.8848\n",
            "Epoch 5/20\n",
            "2994/3000 [============================>.] - ETA: 0s - loss: 0.1025 - accuracy: 0.9652\n",
            "Epoch 5: val_loss did not improve from 0.31742\n",
            "3000/3000 [==============================] - 30s 10ms/step - loss: 0.1024 - accuracy: 0.9653 - val_loss: 0.4901 - val_accuracy: 0.8801\n",
            "Epoch 6/20\n",
            "2997/3000 [============================>.] - ETA: 0s - loss: 0.0772 - accuracy: 0.9738\n",
            "Epoch 6: val_loss did not improve from 0.31742\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "3000/3000 [==============================] - 32s 11ms/step - loss: 0.0772 - accuracy: 0.9738 - val_loss: 0.5891 - val_accuracy: 0.8794\n",
            "Epoch 6: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_4.evaluate(valid_dataset)\n",
        "model_4_loaded = tf.keras.models.load_model(\"saved_models/nlp_model_4\")\n",
        "model_4_preds = model_4_loaded.predict(valid_dataset)\n",
        "model_4_results = calculate_results(val_labels, tf.argmax(model_4_preds, axis=1))\n",
        "model_results_dataset['model_4'] = model_4_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z9icn7OnycK8",
        "outputId": "b4ced563-c6f5-4f04-df58-95be3ff5977f"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "750/750 [==============================] - 4s 5ms/step - loss: 0.3174 - accuracy: 0.8945\n",
            "750/750 [==============================] - 4s 4ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 5: Bi-Directional RNN"
      ],
      "metadata": {
        "id": "3c_ZbYtfyk3K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()"
      ],
      "metadata": {
        "id": "gx6nk4C7yjTP"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "model_5_embedding = layers.Embedding(input_dim=10000, output_dim=128, embeddings_initializer=\"uniform\", input_length=output_seq_length, name=\"embedding_5\")\n",
        "\n",
        "inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
        "x = tv_layer(inputs)\n",
        "x = model_5_embedding(x)\n",
        "x = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(x)\n",
        "x = layers.Bidirectional(layers.GRU(64))(x)\n",
        "x = layers.Dense(64, activation='relu')(x)\n",
        "output = layers.Dense(4, activation='softmax')(x)\n",
        "\n",
        "model_5 = tf.keras.Model(inputs, output, name=\"nlp_model_5\")\n",
        "model_5.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QiOSFbmlys0b",
        "outputId": "443f0ec4-6678-4635-d050-59c5b00491c5"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"nlp_model_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 31)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding_5 (Embedding)     (None, 31, 128)           1280000   \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 31, 128)          98816     \n",
            " l)                                                              \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirectio  (None, 128)              74496     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 4)                 260       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,461,828\n",
            "Trainable params: 1,461,828\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_5.compile(loss=\"categorical_crossentropy\", optimizer=tf.keras.optimizers.Adam(), metrics=[\"accuracy\"])\n",
        "history_5 = model_5.fit(train_dataset, epochs=20, validation_data=valid_dataset,callbacks=return_callbacks(model_5.name))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFPVszAGyyFx",
        "outputId": "6472bac4-c5e9-43d5-c817-7724bf0afb7f"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "2998/3000 [============================>.] - ETA: 0s - loss: 0.3589 - accuracy: 0.8727\n",
            "Epoch 1: val_loss improved from inf to 0.29922, saving model to saved_models/nlp_model_5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, gru_cell_1_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3000/3000 [==============================] - 84s 26ms/step - loss: 0.3590 - accuracy: 0.8727 - val_loss: 0.2992 - val_accuracy: 0.8967\n",
            "Epoch 2/20\n",
            "3000/3000 [==============================] - ETA: 0s - loss: 0.2330 - accuracy: 0.9190\n",
            "Epoch 2: val_loss did not improve from 0.29922\n",
            "3000/3000 [==============================] - 54s 18ms/step - loss: 0.2330 - accuracy: 0.9190 - val_loss: 0.3199 - val_accuracy: 0.8960\n",
            "Epoch 3/20\n",
            "2999/3000 [============================>.] - ETA: 0s - loss: 0.1653 - accuracy: 0.9428\n",
            "Epoch 3: val_loss did not improve from 0.29922\n",
            "3000/3000 [==============================] - 50s 17ms/step - loss: 0.1653 - accuracy: 0.9428 - val_loss: 0.3710 - val_accuracy: 0.8911\n",
            "Epoch 4/20\n",
            "2997/3000 [============================>.] - ETA: 0s - loss: 0.1112 - accuracy: 0.9617\n",
            "Epoch 4: val_loss did not improve from 0.29922\n",
            "3000/3000 [==============================] - 50s 17ms/step - loss: 0.1111 - accuracy: 0.9618 - val_loss: 0.4653 - val_accuracy: 0.8862\n",
            "Epoch 5/20\n",
            "2998/3000 [============================>.] - ETA: 0s - loss: 0.0753 - accuracy: 0.9741\n",
            "Epoch 5: val_loss did not improve from 0.29922\n",
            "3000/3000 [==============================] - 50s 17ms/step - loss: 0.0753 - accuracy: 0.9741 - val_loss: 0.5329 - val_accuracy: 0.8860\n",
            "Epoch 6/20\n",
            "2998/3000 [============================>.] - ETA: 0s - loss: 0.0539 - accuracy: 0.9815\n",
            "Epoch 6: val_loss did not improve from 0.29922\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "3000/3000 [==============================] - 47s 16ms/step - loss: 0.0540 - accuracy: 0.9815 - val_loss: 0.5826 - val_accuracy: 0.8842\n",
            "Epoch 6: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_5.evaluate(valid_dataset)\n",
        "model_5_loaded = tf.keras.models.load_model(\"saved_models/nlp_model_5\")\n",
        "model_5_preds = model_5_loaded.predict(valid_dataset)\n",
        "model_5_results = calculate_results(val_labels, tf.argmax(model_5_preds, axis=1))\n",
        "model_results_dataset['model_5'] = model_5_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "398Rr1rPy7Mm",
        "outputId": "46e6ef3c-da96-480c-b521-dcb17d048553"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "750/750 [==============================] - 5s 7ms/step - loss: 0.2992 - accuracy: 0.8967\n",
            "750/750 [==============================] - 7s 8ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 6: CNN"
      ],
      "metadata": {
        "id": "pTEcjKtIzK9u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()"
      ],
      "metadata": {
        "id": "3ajpdqS7zJ5E"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_6_embedding = layers.Embedding(input_dim=10000, output_dim=128, embeddings_initializer=\"uniform\", input_length=output_seq_length, name=\"embedding_6\")\n",
        "\n",
        "# Create 1D convolutional model to process sequences\n",
        "inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
        "text_vectors = tv_layer(inputs) # vectorize text inputs\n",
        "token_embeddings = model_6_embedding(text_vectors) # create embedding\n",
        "x = layers.Conv1D(64, kernel_size=5, padding=\"same\", activation=\"relu\")(token_embeddings)\n",
        "x = layers.GlobalAveragePooling1D()(x) # condense the output of our feature vector\n",
        "outputs = layers.Dense(4, activation=\"softmax\")(x)\n",
        "model_6 = tf.keras.Model(inputs, outputs, name=\"nlp_model_6\")\n",
        "\n",
        "# Compile\n",
        "model_6.compile(loss=\"categorical_crossentropy\", # if your labels are integer form (not one hot) use sparse_categorical_crossentropy\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "history_6 = model_6.fit(train_dataset, epochs=20, validation_data=valid_dataset,callbacks=return_callbacks(model_6.name))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L2w4fsTdzUKl",
        "outputId": "dfb3da75-6010-4d02-832c-b709db10ad40"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "2995/3000 [============================>.] - ETA: 0s - loss: 0.3650 - accuracy: 0.8742\n",
            "Epoch 1: val_loss improved from inf to 0.30199, saving model to saved_models/nlp_model_6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3000/3000 [==============================] - 25s 6ms/step - loss: 0.3649 - accuracy: 0.8742 - val_loss: 0.3020 - val_accuracy: 0.9006\n",
            "Epoch 2/20\n",
            "2993/3000 [============================>.] - ETA: 0s - loss: 0.2436 - accuracy: 0.9161\n",
            "Epoch 2: val_loss did not improve from 0.30199\n",
            "3000/3000 [==============================] - 18s 6ms/step - loss: 0.2434 - accuracy: 0.9162 - val_loss: 0.3114 - val_accuracy: 0.8972\n",
            "Epoch 3/20\n",
            "3000/3000 [==============================] - ETA: 0s - loss: 0.2022 - accuracy: 0.9303\n",
            "Epoch 3: val_loss did not improve from 0.30199\n",
            "3000/3000 [==============================] - 17s 6ms/step - loss: 0.2022 - accuracy: 0.9303 - val_loss: 0.3399 - val_accuracy: 0.8924\n",
            "Epoch 4/20\n",
            "2998/3000 [============================>.] - ETA: 0s - loss: 0.1637 - accuracy: 0.9447\n",
            "Epoch 4: val_loss did not improve from 0.30199\n",
            "3000/3000 [==============================] - 17s 6ms/step - loss: 0.1637 - accuracy: 0.9446 - val_loss: 0.3865 - val_accuracy: 0.8863\n",
            "Epoch 5/20\n",
            "3000/3000 [==============================] - ETA: 0s - loss: 0.1254 - accuracy: 0.9586\n",
            "Epoch 5: val_loss did not improve from 0.30199\n",
            "3000/3000 [==============================] - 22s 7ms/step - loss: 0.1254 - accuracy: 0.9586 - val_loss: 0.4528 - val_accuracy: 0.8801\n",
            "Epoch 6/20\n",
            "2997/3000 [============================>.] - ETA: 0s - loss: 0.0923 - accuracy: 0.9715\n",
            "Epoch 6: val_loss did not improve from 0.30199\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "3000/3000 [==============================] - 20s 7ms/step - loss: 0.0923 - accuracy: 0.9715 - val_loss: 0.5394 - val_accuracy: 0.8730\n",
            "Epoch 6: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_6.evaluate(valid_dataset)\n",
        "model_6_loaded = tf.keras.models.load_model(\"saved_models/nlp_model_6\")\n",
        "model_6_preds = model_6_loaded.predict(valid_dataset)\n",
        "model_6_results = calculate_results(val_labels, tf.argmax(model_6_preds, axis=1))\n",
        "model_results_dataset['model_6'] = model_6_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LoOCsVjo0A4-",
        "outputId": "9ffd1a97-dc88-482a-e2b1-c58fbf4b233e"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "750/750 [==============================] - 2s 3ms/step - loss: 0.3020 - accuracy: 0.9006\n",
            "750/750 [==============================] - 2s 3ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 7: Pre-trained Layer"
      ],
      "metadata": {
        "id": "HtVLmol10RNo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()"
      ],
      "metadata": {
        "id": "g80wrU830JM3"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download pretrained TensorFlow Hub USE\n",
        "import tensorflow_hub as hub\n",
        "tf_hub_embedding_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
        "                                        trainable=False,\n",
        "                                        name=\"universal_sentence_encoder\")"
      ],
      "metadata": {
        "id": "pVtwIPNL0WI2"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_7 = tf.keras.Sequential([\n",
        "  layers.Input(shape=[], dtype=tf.string),\n",
        "  tf_hub_embedding_layer, # take in sentences and then encode them into an embedding\n",
        "  layers.Dense(128, activation=\"relu\"),\n",
        "  layers.Dense(4, activation=\"softmax\")\n",
        "], name=\"nlp_model_7\")\n",
        "\n",
        "model_7.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OlNMzjcX0muU",
        "outputId": "84beb410-92c4-4a23-e425-87d3fcaac885"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"nlp_model_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " universal_sentence_encoder   (None, 512)              256797824 \n",
            " (KerasLayer)                                                    \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 128)               65664     \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 4)                 516       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 256,864,004\n",
            "Trainable params: 66,180\n",
            "Non-trainable params: 256,797,824\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_7.compile(loss=\"categorical_crossentropy\", # if your labels are integer form (not one hot) use sparse_categorical_crossentropy\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "history_7 = model_7.fit(train_dataset, epochs=20, validation_data=valid_dataset,callbacks=return_callbacks(model_7.name))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SixmA0Qz093J",
        "outputId": "2359f61f-0b6d-4075-de9f-6fb75ed3dce9"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "2999/3000 [============================>.] - ETA: 0s - loss: 0.3486 - accuracy: 0.8810\n",
            "Epoch 1: val_loss improved from inf to 0.31757, saving model to saved_models/nlp_model_7\n",
            "3000/3000 [==============================] - 60s 19ms/step - loss: 0.3486 - accuracy: 0.8810 - val_loss: 0.3176 - val_accuracy: 0.8851\n",
            "Epoch 2/20\n",
            "3000/3000 [==============================] - ETA: 0s - loss: 0.3018 - accuracy: 0.8925\n",
            "Epoch 2: val_loss improved from 0.31757 to 0.30670, saving model to saved_models/nlp_model_7\n",
            "3000/3000 [==============================] - 51s 17ms/step - loss: 0.3018 - accuracy: 0.8925 - val_loss: 0.3067 - val_accuracy: 0.8894\n",
            "Epoch 3/20\n",
            "2998/3000 [============================>.] - ETA: 0s - loss: 0.2843 - accuracy: 0.8984\n",
            "Epoch 3: val_loss improved from 0.30670 to 0.29768, saving model to saved_models/nlp_model_7\n",
            "3000/3000 [==============================] - 51s 17ms/step - loss: 0.2842 - accuracy: 0.8984 - val_loss: 0.2977 - val_accuracy: 0.8933\n",
            "Epoch 4/20\n",
            "3000/3000 [==============================] - ETA: 0s - loss: 0.2682 - accuracy: 0.9040\n",
            "Epoch 4: val_loss improved from 0.29768 to 0.29041, saving model to saved_models/nlp_model_7\n",
            "3000/3000 [==============================] - 52s 17ms/step - loss: 0.2682 - accuracy: 0.9040 - val_loss: 0.2904 - val_accuracy: 0.8968\n",
            "Epoch 5/20\n",
            "3000/3000 [==============================] - ETA: 0s - loss: 0.2534 - accuracy: 0.9095\n",
            "Epoch 5: val_loss improved from 0.29041 to 0.28544, saving model to saved_models/nlp_model_7\n",
            "3000/3000 [==============================] - 50s 17ms/step - loss: 0.2534 - accuracy: 0.9095 - val_loss: 0.2854 - val_accuracy: 0.8984\n",
            "Epoch 6/20\n",
            "2997/3000 [============================>.] - ETA: 0s - loss: 0.2395 - accuracy: 0.9151\n",
            "Epoch 6: val_loss improved from 0.28544 to 0.28303, saving model to saved_models/nlp_model_7\n",
            "3000/3000 [==============================] - 62s 21ms/step - loss: 0.2395 - accuracy: 0.9151 - val_loss: 0.2830 - val_accuracy: 0.8999\n",
            "Epoch 7/20\n",
            "2999/3000 [============================>.] - ETA: 0s - loss: 0.2267 - accuracy: 0.9202\n",
            "Epoch 7: val_loss improved from 0.28303 to 0.28269, saving model to saved_models/nlp_model_7\n",
            "3000/3000 [==============================] - 57s 19ms/step - loss: 0.2267 - accuracy: 0.9202 - val_loss: 0.2827 - val_accuracy: 0.9012\n",
            "Epoch 8/20\n",
            "3000/3000 [==============================] - ETA: 0s - loss: 0.2149 - accuracy: 0.9248\n",
            "Epoch 8: val_loss did not improve from 0.28269\n",
            "3000/3000 [==============================] - 45s 15ms/step - loss: 0.2149 - accuracy: 0.9248 - val_loss: 0.2836 - val_accuracy: 0.9013\n",
            "Epoch 9/20\n",
            "3000/3000 [==============================] - ETA: 0s - loss: 0.2038 - accuracy: 0.9288\n",
            "Epoch 9: val_loss did not improve from 0.28269\n",
            "3000/3000 [==============================] - 45s 15ms/step - loss: 0.2038 - accuracy: 0.9288 - val_loss: 0.2861 - val_accuracy: 0.9012\n",
            "Epoch 10/20\n",
            "2997/3000 [============================>.] - ETA: 0s - loss: 0.1934 - accuracy: 0.9330\n",
            "Epoch 10: val_loss did not improve from 0.28269\n",
            "3000/3000 [==============================] - 43s 14ms/step - loss: 0.1934 - accuracy: 0.9330 - val_loss: 0.2896 - val_accuracy: 0.9006\n",
            "Epoch 11/20\n",
            "2996/3000 [============================>.] - ETA: 0s - loss: 0.1834 - accuracy: 0.9368\n",
            "Epoch 11: val_loss did not improve from 0.28269\n",
            "3000/3000 [==============================] - 43s 14ms/step - loss: 0.1833 - accuracy: 0.9368 - val_loss: 0.2948 - val_accuracy: 0.9000\n",
            "Epoch 12/20\n",
            "2996/3000 [============================>.] - ETA: 0s - loss: 0.1739 - accuracy: 0.9399\n",
            "Epoch 12: val_loss did not improve from 0.28269\n",
            "Restoring model weights from the end of the best epoch: 7.\n",
            "3000/3000 [==============================] - 45s 15ms/step - loss: 0.1738 - accuracy: 0.9399 - val_loss: 0.3004 - val_accuracy: 0.8993\n",
            "Epoch 12: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_7.evaluate(valid_dataset)\n",
        "model_7_loaded = tf.keras.models.load_model(\"saved_models/nlp_model_7\")\n",
        "model_7_preds = model_7_loaded.predict(valid_dataset)\n",
        "model_7_results = calculate_results(val_labels, tf.argmax(model_7_preds, axis=1))\n",
        "model_results_dataset['model_7'] = model_7_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bhSMm2jH1FAJ",
        "outputId": "4101c322-01c3-4dde-f0ea-a761bdc7f3cb"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "750/750 [==============================] - 9s 12ms/step - loss: 0.2827 - accuracy: 0.9012\n",
            "750/750 [==============================] - 8s 11ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 8: Conv1D with character embeddings"
      ],
      "metadata": {
        "id": "keC1XyNO1TEO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()"
      ],
      "metadata": {
        "id": "2tWqpBvO3CX5"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make function to split sentences into characters\n",
        "def split_chars(text):\n",
        "  text = text.decode()\n",
        "  return \" \".join(list(text))\n",
        "\n",
        "# Split sequence-level data splits into character-level data splits\n",
        "train_chars = [split_chars(sentence) for sentence in train_examples]\n",
        "val_chars = [split_chars(sentence) for sentence in val_examples]\n",
        "test_chars = [split_chars(sentence) for sentence in test_examples]\n",
        "print(train_chars[0])\n",
        "char_lens = [len(sentence) for sentence in train_examples]\n",
        "mean_char_len = np.mean(char_lens)\n",
        "mean_char_len\n",
        "output_seq_char_len = int(np.percentile(char_lens, 95))\n",
        "output_seq_char_len\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wCtg9hf_1Mq9",
        "outputId": "f61b8bf9-3b78-4e45-819a-0b8717112fd1"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A M D   # 3 9 ; s   n e w   d u a l - c o r e   O p t e r o n   c h i p   i s   d e s i g n e d   m a i n l y   f o r   c o r p o r a t e   c o m p u t i n g   a p p l i c a t i o n s ,   i n c l u d i n g   d a t a b a s e s ,   W e b   s e r v i c e s ,   a n d   f i n a n c i a l   t r a n s a c t i o n s .\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "296"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "alphabet = string.ascii_lowercase + string.digits + string.punctuation\n",
        "alphabet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "SuJPQoG_3NNf",
        "outputId": "f137a542-4f2a-497c-a512-0f3ba9f54dcc"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'abcdefghijklmnopqrstuvwxyz0123456789!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create char-level token vectorizer instance\n",
        "NUM_CHAR_TOKENS = len(alphabet) + 2 # num characters in alphabet + space + OOV token\n",
        "char_vectorizer = TextVectorization(max_tokens=NUM_CHAR_TOKENS,  \n",
        "                                    output_sequence_length=output_seq_char_len,\n",
        "                                    standardize=\"lower_and_strip_punctuation\",\n",
        "                                    name=\"char_vectorizer\")\n",
        "\n",
        "# Adapt character vectorizer to training characters\n",
        "char_vectorizer.adapt(train_chars)"
      ],
      "metadata": {
        "id": "kKmokP9Q3UuF"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create char embedding layer\n",
        "char_embed = layers.Embedding(input_dim=NUM_CHAR_TOKENS, # number of different characters\n",
        "                              output_dim=25, # embedding dimension of each character (same as Figure 1 in https://arxiv.org/pdf/1612.05251.pdf)\n",
        "                              mask_zero=False, # don't use masks (this messes up model_5 if set to True)\n",
        "                              name=\"char_embed\")"
      ],
      "metadata": {
        "id": "89mHZ1rE7Ttf"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make Conv1D on chars only\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
        "char_vectors = char_vectorizer(inputs)\n",
        "char_embeddings = char_embed(char_vectors)\n",
        "x = layers.Conv1D(64, kernel_size=5, padding=\"same\", activation=\"relu\")(char_embeddings)\n",
        "x = layers.GlobalMaxPool1D()(x)\n",
        "outputs = layers.Dense(4, activation=\"softmax\")(x)\n",
        "model_8 = tf.keras.Model(inputs=inputs,\n",
        "                         outputs=outputs,\n",
        "                         name=\"nlp_model_8\")\n",
        "\n",
        "# Compile model\n",
        "model_8.compile(loss=\"categorical_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "8_YFZVX77mXf"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_char_dataset = tf.data.Dataset.from_tensor_slices((train_chars, train_labels_one_hot)).batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "val_char_dataset = tf.data.Dataset.from_tensor_slices((val_chars, val_labels_one_hot)).batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "train_char_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WfUsXuVv71Ru",
        "outputId": "b4b31b8b-3695-464f-a38a-57c20415e8b0"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PrefetchDataset element_spec=(TensorSpec(shape=(None,), dtype=tf.string, name=None), TensorSpec(shape=(None, 4), dtype=tf.float64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history_8 = model_8.fit(train_char_dataset, epochs=20, validation_data=val_char_dataset,callbacks=return_callbacks(model_8.name))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zd9WHSFE76_B",
        "outputId": "5ab68e8c-d05e-4eeb-f9c2-df9318266826"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "2996/3000 [============================>.] - ETA: 0s - loss: 0.7818 - accuracy: 0.6995\n",
            "Epoch 1: val_loss improved from inf to 0.60444, saving model to saved_models/nlp_model_8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3000/3000 [==============================] - 20s 6ms/step - loss: 0.7815 - accuracy: 0.6995 - val_loss: 0.6044 - val_accuracy: 0.7817\n",
            "Epoch 2/20\n",
            "2992/3000 [============================>.] - ETA: 0s - loss: 0.5708 - accuracy: 0.7931\n",
            "Epoch 2: val_loss improved from 0.60444 to 0.55433, saving model to saved_models/nlp_model_8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3000/3000 [==============================] - 24s 8ms/step - loss: 0.5708 - accuracy: 0.7932 - val_loss: 0.5543 - val_accuracy: 0.8015\n",
            "Epoch 3/20\n",
            "2998/3000 [============================>.] - ETA: 0s - loss: 0.5284 - accuracy: 0.8104\n",
            "Epoch 3: val_loss improved from 0.55433 to 0.53091, saving model to saved_models/nlp_model_8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3000/3000 [==============================] - 21s 7ms/step - loss: 0.5284 - accuracy: 0.8104 - val_loss: 0.5309 - val_accuracy: 0.8108\n",
            "Epoch 4/20\n",
            "2997/3000 [============================>.] - ETA: 0s - loss: 0.5050 - accuracy: 0.8191\n",
            "Epoch 4: val_loss improved from 0.53091 to 0.51683, saving model to saved_models/nlp_model_8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3000/3000 [==============================] - 21s 7ms/step - loss: 0.5049 - accuracy: 0.8191 - val_loss: 0.5168 - val_accuracy: 0.8165\n",
            "Epoch 5/20\n",
            "3000/3000 [==============================] - ETA: 0s - loss: 0.4884 - accuracy: 0.8254\n",
            "Epoch 5: val_loss improved from 0.51683 to 0.50799, saving model to saved_models/nlp_model_8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3000/3000 [==============================] - 19s 6ms/step - loss: 0.4884 - accuracy: 0.8254 - val_loss: 0.5080 - val_accuracy: 0.8202\n",
            "Epoch 6/20\n",
            "2998/3000 [============================>.] - ETA: 0s - loss: 0.4759 - accuracy: 0.8303\n",
            "Epoch 6: val_loss improved from 0.50799 to 0.50322, saving model to saved_models/nlp_model_8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3000/3000 [==============================] - 19s 6ms/step - loss: 0.4759 - accuracy: 0.8303 - val_loss: 0.5032 - val_accuracy: 0.8214\n",
            "Epoch 7/20\n",
            "2999/3000 [============================>.] - ETA: 0s - loss: 0.4665 - accuracy: 0.8328\n",
            "Epoch 7: val_loss improved from 0.50322 to 0.49822, saving model to saved_models/nlp_model_8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3000/3000 [==============================] - 21s 7ms/step - loss: 0.4665 - accuracy: 0.8328 - val_loss: 0.4982 - val_accuracy: 0.8240\n",
            "Epoch 8/20\n",
            "2990/3000 [============================>.] - ETA: 0s - loss: 0.4587 - accuracy: 0.8359\n",
            "Epoch 8: val_loss improved from 0.49822 to 0.49356, saving model to saved_models/nlp_model_8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3000/3000 [==============================] - 20s 7ms/step - loss: 0.4587 - accuracy: 0.8359 - val_loss: 0.4936 - val_accuracy: 0.8252\n",
            "Epoch 9/20\n",
            "2997/3000 [============================>.] - ETA: 0s - loss: 0.4514 - accuracy: 0.8391\n",
            "Epoch 9: val_loss improved from 0.49356 to 0.49057, saving model to saved_models/nlp_model_8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3000/3000 [==============================] - 23s 8ms/step - loss: 0.4513 - accuracy: 0.8391 - val_loss: 0.4906 - val_accuracy: 0.8250\n",
            "Epoch 10/20\n",
            "2997/3000 [============================>.] - ETA: 0s - loss: 0.4463 - accuracy: 0.8404\n",
            "Epoch 10: val_loss improved from 0.49057 to 0.48777, saving model to saved_models/nlp_model_8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3000/3000 [==============================] - 24s 8ms/step - loss: 0.4462 - accuracy: 0.8404 - val_loss: 0.4878 - val_accuracy: 0.8251\n",
            "Epoch 11/20\n",
            "2994/3000 [============================>.] - ETA: 0s - loss: 0.4418 - accuracy: 0.8415\n",
            "Epoch 11: val_loss improved from 0.48777 to 0.48587, saving model to saved_models/nlp_model_8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3000/3000 [==============================] - 23s 8ms/step - loss: 0.4416 - accuracy: 0.8416 - val_loss: 0.4859 - val_accuracy: 0.8289\n",
            "Epoch 12/20\n",
            "2999/3000 [============================>.] - ETA: 0s - loss: 0.4369 - accuracy: 0.8439\n",
            "Epoch 12: val_loss improved from 0.48587 to 0.48456, saving model to saved_models/nlp_model_8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3000/3000 [==============================] - 28s 9ms/step - loss: 0.4369 - accuracy: 0.8439 - val_loss: 0.4846 - val_accuracy: 0.8286\n",
            "Epoch 13/20\n",
            "2994/3000 [============================>.] - ETA: 0s - loss: 0.4339 - accuracy: 0.8445\n",
            "Epoch 13: val_loss improved from 0.48456 to 0.48218, saving model to saved_models/nlp_model_8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3000/3000 [==============================] - 21s 7ms/step - loss: 0.4337 - accuracy: 0.8446 - val_loss: 0.4822 - val_accuracy: 0.8292\n",
            "Epoch 14/20\n",
            "2998/3000 [============================>.] - ETA: 0s - loss: 0.4299 - accuracy: 0.8461\n",
            "Epoch 14: val_loss improved from 0.48218 to 0.48016, saving model to saved_models/nlp_model_8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3000/3000 [==============================] - 22s 7ms/step - loss: 0.4298 - accuracy: 0.8461 - val_loss: 0.4802 - val_accuracy: 0.8307\n",
            "Epoch 15/20\n",
            "2997/3000 [============================>.] - ETA: 0s - loss: 0.4268 - accuracy: 0.8480\n",
            "Epoch 15: val_loss improved from 0.48016 to 0.47911, saving model to saved_models/nlp_model_8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3000/3000 [==============================] - 23s 8ms/step - loss: 0.4267 - accuracy: 0.8480 - val_loss: 0.4791 - val_accuracy: 0.8314\n",
            "Epoch 16/20\n",
            "2994/3000 [============================>.] - ETA: 0s - loss: 0.4240 - accuracy: 0.8494\n",
            "Epoch 16: val_loss improved from 0.47911 to 0.47703, saving model to saved_models/nlp_model_8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3000/3000 [==============================] - 19s 6ms/step - loss: 0.4238 - accuracy: 0.8495 - val_loss: 0.4770 - val_accuracy: 0.8325\n",
            "Epoch 17/20\n",
            "3000/3000 [==============================] - ETA: 0s - loss: 0.4216 - accuracy: 0.8497\n",
            "Epoch 17: val_loss improved from 0.47703 to 0.47653, saving model to saved_models/nlp_model_8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3000/3000 [==============================] - 18s 6ms/step - loss: 0.4216 - accuracy: 0.8497 - val_loss: 0.4765 - val_accuracy: 0.8331\n",
            "Epoch 18/20\n",
            "2994/3000 [============================>.] - ETA: 0s - loss: 0.4192 - accuracy: 0.8504\n",
            "Epoch 18: val_loss improved from 0.47653 to 0.47639, saving model to saved_models/nlp_model_8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3000/3000 [==============================] - 22s 7ms/step - loss: 0.4190 - accuracy: 0.8505 - val_loss: 0.4764 - val_accuracy: 0.8322\n",
            "Epoch 19/20\n",
            "2994/3000 [============================>.] - ETA: 0s - loss: 0.4170 - accuracy: 0.8518\n",
            "Epoch 19: val_loss improved from 0.47639 to 0.47459, saving model to saved_models/nlp_model_8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3000/3000 [==============================] - 19s 6ms/step - loss: 0.4169 - accuracy: 0.8519 - val_loss: 0.4746 - val_accuracy: 0.8333\n",
            "Epoch 20/20\n",
            "3000/3000 [==============================] - ETA: 0s - loss: 0.4146 - accuracy: 0.8528\n",
            "Epoch 20: val_loss improved from 0.47459 to 0.47411, saving model to saved_models/nlp_model_8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3000/3000 [==============================] - 18s 6ms/step - loss: 0.4146 - accuracy: 0.8528 - val_loss: 0.4741 - val_accuracy: 0.8331\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_8.evaluate(valid_dataset)\n",
        "model_8_loaded = tf.keras.models.load_model(\"saved_models/nlp_model_8\")\n",
        "model_8_preds = model_8_loaded.predict(valid_dataset)\n",
        "model_8_results = calculate_results(val_labels, tf.argmax(model_8_preds, axis=1))\n",
        "model_results_dataset['model_8'] = model_8_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "euD17c5y8HDc",
        "outputId": "7934b003-377b-42e9-99d9-a9964ee837a2"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "750/750 [==============================] - 3s 3ms/step - loss: 3.4048 - accuracy: 0.2722\n",
            "750/750 [==============================] - 2s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 9: Combining pretrained token embeddings + character embeddings"
      ],
      "metadata": {
        "id": "JWZt0_P38bIF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()"
      ],
      "metadata": {
        "id": "so8kXrql8TkW"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Setup token inputs/model\n",
        "token_inputs = layers.Input(shape=[], dtype=tf.string, name=\"token_input\")\n",
        "token_embeddings = tf_hub_embedding_layer(token_inputs)\n",
        "token_output = layers.Dense(128, activation=\"relu\")(token_embeddings)\n",
        "token_model = tf.keras.Model(inputs=token_inputs,\n",
        "                             outputs=token_output)\n",
        "\n",
        "# 2. Setup char inputs/model\n",
        "char_inputs = layers.Input(shape=(1,), dtype=tf.string, name=\"char_input\")\n",
        "char_vectors = char_vectorizer(char_inputs)\n",
        "char_embeddings = char_embed(char_vectors)\n",
        "char_bi_lstm = layers.Bidirectional(layers.LSTM(25))(char_embeddings) # bi-LSTM shown in Figure 1 of https://arxiv.org/pdf/1612.05251.pdf\n",
        "char_model = tf.keras.Model(inputs=char_inputs,\n",
        "                            outputs=char_bi_lstm)\n",
        "\n",
        "# 3. Concatenate token and char inputs (create hybrid token embedding)\n",
        "token_char_concat = layers.Concatenate(name=\"token_char_hybrid\")([token_model.output, \n",
        "                                                                  char_model.output])\n",
        "\n",
        "# 4. Create output layers - addition of dropout discussed in 4.2 of https://arxiv.org/pdf/1612.05251.pdf\n",
        "combined_dropout = layers.Dropout(0.5)(token_char_concat)\n",
        "combined_dense = layers.Dense(200, activation=\"relu\")(combined_dropout) # slightly different to Figure 1 due to different shapes of token/char embedding layers\n",
        "final_dropout = layers.Dropout(0.5)(combined_dense)\n",
        "output_layer = layers.Dense(4, activation=\"softmax\")(final_dropout)\n",
        "\n",
        "# 5. Construct model with char and token inputs\n",
        "model_9 = tf.keras.Model(inputs=[token_model.input, char_model.input],\n",
        "                         outputs=output_layer,\n",
        "                         name=\"nlp_model_9\")"
      ],
      "metadata": {
        "id": "sTaXGQLx8joG"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile token char model\n",
        "model_9.compile(loss=\"categorical_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(), # section 4.2 of https://arxiv.org/pdf/1612.05251.pdf mentions using SGD but we'll stick with Adam\n",
        "                metrics=[\"accuracy\"])\n"
      ],
      "metadata": {
        "id": "XaRxiY-v8wxS"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine chars and tokens into a dataset\n",
        "train_char_token_data = tf.data.Dataset.from_tensor_slices((train_examples, train_chars)) # make data\n",
        "train_char_token_labels = tf.data.Dataset.from_tensor_slices(train_labels_one_hot) # make labels\n",
        "train_char_token_dataset = tf.data.Dataset.zip((train_char_token_data, train_char_token_labels)) # combine data and labels\n",
        "\n",
        "# Prefetch and batch train data\n",
        "train_char_token_dataset = train_char_token_dataset.batch(32).prefetch(tf.data.AUTOTUNE) \n",
        "\n",
        "# Repeat same steps validation data\n",
        "val_char_token_data = tf.data.Dataset.from_tensor_slices((val_examples, val_chars))\n",
        "val_char_token_labels = tf.data.Dataset.from_tensor_slices(val_labels_one_hot)\n",
        "val_char_token_dataset = tf.data.Dataset.zip((val_char_token_data, val_char_token_labels))\n",
        "val_char_token_dataset = val_char_token_dataset.batch(32).prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "5bRU2bDe9BKo"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_9 = model_9.fit(train_char_token_dataset, epochs=20, validation_data=val_char_token_dataset, callbacks=return_callbacks(model_9.name))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7GE7GMIc9E-y",
        "outputId": "ca61626d-ad8f-4cd8-ab94-20acecacd6f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "2999/3000 [============================>.] - ETA: 0s - loss: 0.3751 - accuracy: 0.8706\n",
            "Epoch 1: val_loss improved from inf to 0.30257, saving model to saved_models/nlp_model_9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3000/3000 [==============================] - 139s 45ms/step - loss: 0.3752 - accuracy: 0.8705 - val_loss: 0.3026 - val_accuracy: 0.8895\n",
            "Epoch 2/20\n",
            "3000/3000 [==============================] - ETA: 0s - loss: 0.3184 - accuracy: 0.8894\n",
            "Epoch 2: val_loss improved from 0.30257 to 0.29026, saving model to saved_models/nlp_model_9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3000/3000 [==============================] - 136s 45ms/step - loss: 0.3184 - accuracy: 0.8894 - val_loss: 0.2903 - val_accuracy: 0.8936\n",
            "Epoch 3/20\n",
            "2999/3000 [============================>.] - ETA: 0s - loss: 0.3009 - accuracy: 0.8962\n",
            "Epoch 3: val_loss improved from 0.29026 to 0.28210, saving model to saved_models/nlp_model_9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3000/3000 [==============================] - 133s 44ms/step - loss: 0.3009 - accuracy: 0.8961 - val_loss: 0.2821 - val_accuracy: 0.8961\n",
            "Epoch 4/20\n",
            "2999/3000 [============================>.] - ETA: 0s - loss: 0.2877 - accuracy: 0.8992\n",
            "Epoch 4: val_loss improved from 0.28210 to 0.27618, saving model to saved_models/nlp_model_9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3000/3000 [==============================] - 135s 45ms/step - loss: 0.2877 - accuracy: 0.8992 - val_loss: 0.2762 - val_accuracy: 0.8985\n",
            "Epoch 5/20\n",
            "3000/3000 [==============================] - ETA: 0s - loss: 0.2807 - accuracy: 0.9024\n",
            "Epoch 5: val_loss improved from 0.27618 to 0.27489, saving model to saved_models/nlp_model_9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3000/3000 [==============================] - 133s 44ms/step - loss: 0.2807 - accuracy: 0.9024 - val_loss: 0.2749 - val_accuracy: 0.8999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_9.evaluate(valid_dataset)\n",
        "model_9_loaded = tf.keras.models.load_model(\"saved_models/nlp_model_9\")\n",
        "model_9_preds = model_9_loaded.predict(valid_dataset)\n",
        "model_9_results = calculate_results(val_labels, tf.argmax(model_9_preds, axis=1))\n",
        "model_results_dataset['model_9'] = model_9_results"
      ],
      "metadata": {
        "id": "HhRM92u09bjk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OcGWeRya9eP8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}