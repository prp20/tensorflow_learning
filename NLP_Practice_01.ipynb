{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prp20/tensorflow_learning/blob/main/NLP_Practice_01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "e_Kf6KrwP7EU",
        "outputId": "e77fa7b9-5e69-46ac-f457-ad8135b71b3b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.9.2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "tf.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GqJzhe8EQVwI"
      },
      "outputs": [],
      "source": [
        "train_data, validation_data, test_data = tfds.load(name=\"imdb_reviews\", split=('train[:80%]', 'train[80%:]', 'test'), as_supervised=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "58kAKoCjQr-8"
      },
      "outputs": [],
      "source": [
        "train_data, test_data = tfds.load(name=\"imdb_reviews\", split=[\"train\", \"test\"], \n",
        "                                  batch_size=-1, as_supervised=True)\n",
        "\n",
        "train_examples, train_labels = tfds.as_numpy(train_data)\n",
        "train_labels = np.asarray(train_labels).astype('float32').reshape((-1,1))\n",
        "test_examples, test_labels = tfds.as_numpy(test_data)\n",
        "test_labels = np.asarray(test_labels).astype('float32').reshape((-1,1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jp7vwVvDUNit",
        "outputId": "62d42524-bc0d-48f2-e7aa-5ba8719ff48c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[b'This', b'was', b'an', b'absolutely', b'terrible', b'movie.', b\"Don't\", b'be', b'lured', b'in', b'by', b'Christopher', b'Walken', b'or', b'Michael', b'Ironside.', b'Both', b'are', b'great', b'actors,', b'but', b'this', b'must', b'simply', b'be', b'their', b'worst', b'role', b'in', b'history.', b'Even', b'their', b'great', b'acting', b'could', b'not', b'redeem', b'this', b\"movie's\", b'ridiculous', b'storyline.', b'This', b'movie', b'is', b'an', b'early', b'nineties', b'US', b'propaganda', b'piece.', b'The', b'most', b'pathetic', b'scenes', b'were', b'those', b'when', b'the', b'Columbian', b'rebels', b'were', b'making', b'their', b'cases', b'for', b'revolutions.', b'Maria', b'Conchita', b'Alonso', b'appeared', b'phony,', b'and', b'her', b'pseudo-love', b'affair', b'with', b'Walken', b'was', b'nothing', b'but', b'a', b'pathetic', b'emotional', b'plug', b'in', b'a', b'movie', b'that', b'was', b'devoid', b'of', b'any', b'real', b'meaning.', b'I', b'am', b'disappointed', b'that', b'there', b'are', b'movies', b'like', b'this,', b'ruining', b\"actor's\", b'like', b'Christopher', b\"Walken's\", b'good', b'name.', b'I', b'could', b'barely', b'sit', b'through', b'it.']]\n",
            "[[b'I', b'have', b'been', b'known', b'to', b'fall', b'asleep', b'during', b'films,', b'but', b'this', b'is', b'usually', b'due', b'to', b'a', b'combination', b'of', b'things', b'including,', b'really', b'tired,', b'being', b'warm', b'and', b'comfortable', b'on', b'the', b'sette', b'and', b'having', b'just', b'eaten', b'a', b'lot.', b'However', b'on', b'this', b'occasion', b'I', b'fell', b'asleep', b'because', b'the', b'film', b'was', b'rubbish.', b'The', b'plot', b'development', b'was', b'constant.', b'Constantly', b'slow', b'and', b'boring.', b'Things', b'seemed', b'to', b'happen,', b'but', b'with', b'no', b'explanation', b'of', b'what', b'was', b'causing', b'them', b'or', b'why.', b'I', b'admit,', b'I', b'may', b'have', b'missed', b'part', b'of', b'the', b'film,', b'but', b'i', b'watched', b'the', b'majority', b'of', b'it', b'and', b'everything', b'just', b'seemed', b'to', b'happen', b'of', b'its', b'own', b'accord', b'without', b'any', b'real', b'concern', b'for', b'anything', b'else.', b'I', b'cant', b'recommend', b'this', b'film', b'at', b'all.']]\n",
            "[[b'Mann', b'photographs', b'the', b'Alberta', b'Rocky', b'Mountains', b'in', b'a', b'superb', b'fashion,', b'and', b'Jimmy', b'Stewart', b'and', b'Walter', b'Brennan', b'give', b'enjoyable', b'performances', b'as', b'they', b'always', b'seem', b'to', b'do.', b'<br', b'/><br', b'/>But', b'come', b'on', b'Hollywood', b'-', b'a', b'Mountie', b'telling', b'the', b'people', b'of', b'Dawson', b'City,', b'Yukon', b'to', b'elect', b'themselves', b'a', b'marshal', b'(yes', b'a', b'marshal!)', b'and', b'to', b'enforce', b'the', b'law', b'themselves,', b'then', b'gunfighters', b'battling', b'it', b'out', b'on', b'the', b'streets', b'for', b'control', b'of', b'the', b'town?', b'<br', b'/><br', b'/>Nothing', b'even', b'remotely', b'resembling', b'that', b'happened', b'on', b'the', b'Canadian', b'side', b'of', b'the', b'border', b'during', b'the', b'Klondike', b'gold', b'rush.', b'Mr.', b'Mann', b'and', b'company', b'appear', b'to', b'have', b'mistaken', b'Dawson', b'City', b'for', b'Deadwood,', b'the', b'Canadian', b'North', b'for', b'the', b'American', b'Wild', b'West.<br', b'/><br', b'/>Canadian', b'viewers', b'be', b'prepared', b'for', b'a', b'Reefer', b'Madness', b'type', b'of', b'enjoyable', b'howl', b'with', b'this', b'ludicrous', b'plot,', b'or,', b'to', b'shake', b'your', b'head', b'in', b'disgust.']]\n",
            "[[b'This', b'is', b'the', b'kind', b'of', b'film', b'for', b'a', b'snowy', b'Sunday', b'afternoon', b'when', b'the', b'rest', b'of', b'the', b'world', b'can', b'go', b'ahead', b'with', b'its', b'own', b'business', b'as', b'you', b'descend', b'into', b'a', b'big', b'arm-chair', b'and', b'mellow', b'for', b'a', b'couple', b'of', b'hours.', b'Wonderful', b'performances', b'from', b'Cher', b'and', b'Nicolas', b'Cage', b'(as', b'always)', b'gently', b'row', b'the', b'plot', b'along.', b'There', b'are', b'no', b'rapids', b'to', b'cross,', b'no', b'dangerous', b'waters,', b'just', b'a', b'warm', b'and', b'witty', b'paddle', b'through', b'New', b'York', b'life', b'at', b'its', b'best.', b'A', b'family', b'film', b'in', b'every', b'sense', b'and', b'one', b'that', b'deserves', b'the', b'praise', b'it', b'received.']]\n",
            "[[b'As', b'others', b'have', b'mentioned,', b'all', b'the', b'women', b'that', b'go', b'nude', b'in', b'this', b'film', b'are', b'mostly', b'absolutely', b'gorgeous.', b'The', b'plot', b'very', b'ably', b'shows', b'the', b'hypocrisy', b'of', b'the', b'female', b'libido.', b'When', b'men', b'are', b'around', b'they', b'want', b'to', b'be', b'pursued,', b'but', b'when', b'no', b'\"men\"', b'are', b'around,', b'they', b'become', b'the', b'pursuers', b'of', b'a', b'14', b'year', b'old', b'boy.', b'And', b'the', b'boy', b'becomes', b'a', b'man', b'really', b'fast', b'(we', b'should', b'all', b'be', b'so', b'lucky', b'at', b'this', b'age!).', b'He', b'then', b'gets', b'up', b'the', b'courage', b'to', b'pursue', b'his', b'true', b'love.']]\n",
            "[[b'This', b'is', b'a', b'film', b'which', b'should', b'be', b'seen', b'by', b'anybody', b'interested', b'in,', b'effected', b'by,', b'or', b'suffering', b'from', b'an', b'eating', b'disorder.', b'It', b'is', b'an', b'amazingly', b'accurate', b'and', b'sensitive', b'portrayal', b'of', b'bulimia', b'in', b'a', b'teenage', b'girl,', b'its', b'causes', b'and', b'its', b'symptoms.', b'The', b'girl', b'is', b'played', b'by', b'one', b'of', b'the', b'most', b'brilliant', b'young', b'actresses', b'working', b'in', b'cinema', b'today,', b'Alison', b'Lohman,', b'who', b'was', b'later', b'so', b'spectacular', b'in', b\"'Where\", b'the', b'Truth', b\"Lies'.\", b'I', b'would', b'recommend', b'that', b'this', b'film', b'be', b'shown', b'in', b'all', b'schools,', b'as', b'you', b'will', b'never', b'see', b'a', b'better', b'on', b'this', b'subject.', b'Alison', b'Lohman', b'is', b'absolutely', b'outstanding,', b'and', b'one', b'marvels', b'at', b'her', b'ability', b'to', b'convey', b'the', b'anguish', b'of', b'a', b'girl', b'suffering', b'from', b'this', b'compulsive', b'disorder.', b'If', b'barometers', b'tell', b'us', b'the', b'air', b'pressure,', b'Alison', b'Lohman', b'tells', b'us', b'the', b'emotional', b'pressure', b'with', b'the', b'same', b'degree', b'of', b'accuracy.', b'Her', b'emotional', b'range', b'is', b'so', b'precise,', b'each', b'scene', b'could', b'be', b'measured', b'microscopically', b'for', b'its', b'gradations', b'of', b'trauma,', b'on', b'a', b'scale', b'of', b'rising', b'hysteria', b'and', b'desperation', b'which', b'reaches', b'unbearable', b'intensity.', b'Mare', b'Winningham', b'is', b'the', b'perfect', b'choice', b'to', b'play', b'her', b'mother,', b'and', b'does', b'so', b'with', b'immense', b'sympathy', b'and', b'a', b'range', b'of', b'emotions', b'just', b'as', b'finely', b'tuned', b'as', b\"Lohman's.\", b'Together,', b'they', b'make', b'a', b'pair', b'of', b'sensitive', b'emotional', b'oscillators', b'vibrating', b'in', b'resonance', b'with', b'one', b'another.', b'This', b'film', b'is', b'really', b'an', b'astonishing', b'achievement,', b'and', b'director', b'Katt', b'Shea', b'should', b'be', b'proud', b'of', b'it.', b'The', b'only', b'reason', b'for', b'not', b'seeing', b'it', b'is', b'if', b'you', b'are', b'not', b'interested', b'in', b'people.', b'But', b'even', b'if', b'you', b'like', b'nature', b'films', b'best,', b'this', b'is', b'after', b'all', b'animal', b'behaviour', b'at', b'the', b'sharp', b'edge.', b'Bulimia', b'is', b'an', b'extreme', b'version', b'of', b'how', b'a', b'tormented', b'soul', b'can', b'destroy', b'her', b'own', b'body', b'in', b'a', b'frenzy', b'of', b'despair.', b'And', b'if', b'we', b\"don't\", b'sympathise', b'with', b'people', b'suffering', b'from', b'the', b'depths', b'of', b'despair,', b'then', b'we', b'are', b'dead', b'inside.']]\n",
            "[[b'Okay,', b'you', b'have:<br', b'/><br', b'/>Penelope', b'Keith', b'as', b'Miss', b'Herringbone-Tweed,', b'B.B.E.', b'(Backbone', b'of', b'England.)', b\"She's\", b'killed', b'off', b'in', b'the', b'first', b'scene', b'-', b\"that's\", b'right,', b'folks;', b'this', b'show', b'has', b'no', b'backbone!<br', b'/><br', b'/>Peter', b\"O'Toole\", b'as', b\"Ol'\", b'Colonel', b'Cricket', b'from', b'The', b'First', b'War', b'and', b'now', b'the', b'emblazered', b'Lord', b'of', b'the', b'Manor.<br', b'/><br', b'/>Joanna', b'Lumley', b'as', b'the', b'ensweatered', b'Lady', b'of', b'the', b'Manor,', b'20', b'years', b'younger', b'than', b'the', b'colonel', b'and', b'20', b'years', b'past', b'her', b'own', b'prime', b'but', b'still', b'glamourous', b'(Brit', b'spelling,', b'not', b'mine)', b'enough', b'to', b'have', b'a', b'toy-boy', b'on', b'the', b'side.', b\"It's\", b'alright,', b'they', b'have', b'Col.', b\"Cricket's\", b'full', b'knowledge', b'and', b'consent', b'(they', b'guy', b'even', b'comes', b\"'round\", b'for', b'Christmas!)', b'Still,', b\"she's\", b'considerate', b'of', b'the', b'colonel', b'enough', b'to', b'have', b'said', b'toy-boy', b'her', b'own', b'age', b'(what', b'a', b'gal!)<br', b'/><br', b'/>David', b'McCallum', b'as', b'said', b'toy-boy,', b'equally', b'as', b'pointlessly', b'glamourous', b'as', b'his', b'squeeze.', b'Pilcher', b\"couldn't\", b'come', b'up', b'with', b'any', b'cover', b'for', b'him', b'within', b'the', b'story,', b'so', b'she', b'gave', b'him', b'a', b'hush-hush', b'job', b'at', b'the', b'Circus.<br', b'/><br', b'/>and', b'finally:<br', b'/><br', b'/>Susan', b'Hampshire', b'as', b'Miss', b'Polonia', b'Teacups,', b'Venerable', b'Headmistress', b'of', b'the', b'Venerable', b\"Girls'\", b'Boarding-School,', b'serving', b'tea', b'in', b'her', b'office', b'with', b'a', b'dash', b'of', b'deep,', b'poignant', b'advice', b'for', b'life', b'in', b'the', b'outside', b'world', b'just', b'before', b'graduation.', b'Her', b'best', b'bit', b'of', b'advice:', b'\"I\\'ve', b'only', b'been', b'to', b'Nancherrow', b'(the', b'local', b'Stately', b'Home', b'of', b'England)', b'once.', b'I', b'thought', b'it', b'was', b'very', b'beautiful', b'but,', b'somehow,', b'not', b'part', b'of', b'the', b'real', b'world.\"', b'Well,', b'we', b\"can't\", b'say', b'they', b\"didn't\", b'warn', b'us.<br', b'/><br', b'/>Ah,', b'Susan', b'-', b'time', b'was,', b'your', b'character', b'would', b'have', b'been', b'running', b'the', b'whole', b'show.', b'They', b\"don't\", b'write', b\"'em\", b'like', b'that', b'any', b'more.', b'Our', b'loss,', b'not', b'yours.<br', b'/><br', b'/>So', b'-', b'with', b'a', b'cast', b'and', b'setting', b'like', b'this,', b'you', b'have', b'the', b're-makings', b'of', b'\"Brideshead', b'Revisited,\"', b'right?<br', b'/><br', b'/>Wrong!', b'They', b'took', b'these', b'1-dimensional', b'supporting', b'roles', b'because', b'they', b'paid', b'so', b'well.', b'After', b'all,', b'acting', b'is', b'one', b'of', b'the', b'oldest', b'temp-jobs', b'there', b'is', b'(YOU', b'name', b'another!)<br', b'/><br', b'/>First', b'warning', b'sign:', b'lots', b'and', b'lots', b'of', b'backlighting.', b'They', b'get', b'around', b'it', b'by', b'shooting', b'outdoors', b'-', b'\"hey,', b\"it's\", b'just', b'the', b'sunlight!\"<br', b'/><br', b'/>Second', b'warning', b'sign:', b'Leading', b'Lady', b'cries', b'a', b'lot.', b'When', b'not', b'crying,', b'her', b'eyes', b'are', b'moist.', b\"That's\", b'the', b'law', b'of', b'romance', b'novels:', b'Leading', b'Lady', b'is', b'\"dewy-eyed.\"<br', b'/><br', b'/>Henceforth,', b'Leading', b'Lady', b'shall', b'be', b'known', b'as', b'L.L.<br', b'/><br', b'/>Third', b'warning', b'sign:', b'L.L.', b'actually', b'has', b'stars', b'in', b'her', b'eyes', b'when', b\"she's\", b'in', b'love.', b'Still,', b\"I'll\", b'give', b'Emily', b'Mortimer', b'an', b'award', b'just', b'for', b'having', b'to', b'act', b'with', b'that', b'spotlight', b'in', b'her', b'eyes', b'(I', b'wonder', b'.', b'did', b'they', b'use', b'contacts?)<br', b'/><br', b'/>And', b'lastly,', b'fourth', b'warning', b'sign:', b'no', b'on-screen', b'female', b'character', b'is', b'\"Mrs.\"', b\"She's\", b'either', b'\"Miss\"', b'or', b'\"Lady.\"<br', b'/><br', b'/>When', b'all', b'was', b'said', b'and', b'done,', b'I', b'still', b\"couldn't\", b'tell', b'you', b'who', b'was', b'pursuing', b'whom', b'and', b'why.', b'I', b\"couldn't\", b'even', b'tell', b'you', b'what', b'was', b'said', b'and', b'done.<br', b'/><br', b'/>To', b'sum', b'up:', b'they', b'all', b'live', b'through', b'World', b'War', b'II', b'without', b'anything', b'happening', b'to', b'them', b'at', b'all.<br', b'/><br', b'/>OK,', b'at', b'the', b'end,', b'L.L.', b'finds', b\"she's\", b'lost', b'her', b'parents', b'to', b'the', b'Japanese', b'prison', b'camps', b'and', b'baby', b'sis', b'comes', b'home', b'catatonic.', b'Meanwhile', b\"(there's\", b'always', b'a', b'\"meanwhile,\")', b'some', b'young', b'guy', b'L.L.', b'had', b'a', b'crush', b'on', b'(when,', b'I', b\"don't\", b'know)', b'comes', b'home', b'from', b'some', b'wartime', b'tough', b'spot', b'and', b'is', b'found', b'living', b'on', b'the', b'street', b'by', b'Lady', b'of', b'the', b'Manor', b'(must', b'be', b'some', b'street', b'if', b\"SHE's\", b'going', b'to', b'find', b'him', b'there.)', b'Both', b'war', b'casualties', b'are', b'whisked', b'away', b'to', b'recover', b'at', b'Nancherrow', b'(SOMEBODY', b'has', b'to', b'be', b'\"whisked', b'away\"', b'SOMEWHERE', b'in', b'these', b'romance', b'stories!)<br', b'/><br', b'/>Great', b'drama.']]\n",
            "[[b'The', b'film', b'is', b'based', b'on', b'a', b'genuine', b'1950s', b'novel.<br', b'/><br', b'/>Journalist', b'Colin', b'McInnes', b'wrote', b'a', b'set', b'of', b'three', b'\"London', b'novels\":', b'\"Absolute', b'Beginners\",', b'\"City', b'of', b'Spades\"', b'and', b'\"Mr', b'Love', b'and', b'Justice\".', b'I', b'have', b'read', b'all', b'three.', b'The', b'first', b'two', b'are', b'excellent.', b'The', b'last,', b'perhaps', b'an', b'experiment', b'that', b'did', b'not', b'come', b'off.', b'But', b\"McInnes's\", b'work', b'is', b'highly', b'acclaimed;', b'and', b'rightly', b'so.', b'This', b'musical', b'is', b'the', b\"novelist's\", b'ultimate', b'nightmare', b'-', b'to', b'see', b'the', b'fruits', b'of', b\"one's\", b'mind', b'being', b'turned', b'into', b'a', b'glitzy,', b'badly-acted,', b'soporific', b'one-dimensional', b'apology', b'of', b'a', b'film', b'that', b'says', b'it', b'captures', b'the', b'spirit', b'of', b'1950s', b'London,', b'and', b'does', b'nothing', b'of', b'the', b'sort.<br', b'/><br', b'/>Thank', b'goodness', b'Colin', b'McInnes', b\"wasn't\", b'alive', b'to', b'witness', b'it.']]\n",
            "[[b'I', b'really', b'love', b'the', b'sexy', b'action', b'and', b'sci-fi', b'films', b'of', b'the', b'sixties', b'and', b'its', b'because', b'of', b'the', b\"actress's\", b'that', b'appeared', b'in', b'them.', b'They', b'found', b'the', b'sexiest', b'women', b'to', b'be', b'in', b'these', b'films', b'and', b'it', b\"didn't\", b'matter', b'if', b'they', b'could', b'act', b'(Remember', b'\"Candy\"?).', b'The', b'reason', b'I', b'was', b'disappointed', b'by', b'this', b'film', b'was', b'because', b'it', b\"wasn't\", b'nostalgic', b'enough.', b'The', b'story', b'here', b'has', b'a', b'European', b'sci-fi', b'film', b'called', b'\"Dragonfly\"', b'being', b'made', b'and', b'the', b'director', b'is', b'fired.', b'So', b'the', b'producers', b'decide', b'to', b'let', b'a', b'young', b'aspiring', b'filmmaker', b'(Jeremy', b'Davies)', b'to', b'complete', b'the', b'picture.', b\"They're\", b'is', b'one', b'real', b'beautiful', b'woman', b'in', b'the', b'film', b'who', b'plays', b'Dragonfly', b'but', b\"she's\", b'barely', b'in', b'it.', b'Film', b'is', b'written', b'and', b'directed', b'by', b'Roman', b'Coppola', b'who', b'uses', b'some', b'of', b'his', b'fathers', b'exploits', b'from', b'his', b'early', b'days', b'and', b'puts', b'it', b'into', b'the', b'script.', b'I', b'wish', b'the', b'film', b'could', b'have', b'been', b'an', b'homage', b'to', b'those', b'early', b'films.', b'They', b'could', b'have', b'lots', b'of', b'cameos', b'by', b'actors', b'who', b'appeared', b'in', b'them.', b'There', b'is', b'one', b'actor', b'in', b'this', b'film', b'who', b'was', b'popular', b'from', b'the', b'sixties', b'and', b'its', b'John', b'Phillip', b'Law', b'(Barbarella).', b'Gerard', b'Depardieu,', b'Giancarlo', b'Giannini', b'and', b'Dean', b'Stockwell', b'appear', b'as', b'well.', b'I', b'guess', b\"I'm\", b'going', b'to', b'have', b'to', b'continue', b'waiting', b'for', b'a', b'director', b'to', b'make', b'a', b'good', b'homage', b'to', b'the', b'films', b'of', b'the', b'sixties.', b'If', b'any', b'are', b'reading', b'this,', b'\"Make', b'it', b'as', b'sexy', b'as', b'you', b'can\"!', b\"I'll\", b'be', b'waiting!']]\n",
            "[[b'Sure,', b'this', b'one', b\"isn't\", b'really', b'a', b'blockbuster,', b'nor', b'does', b'it', b'target', b'such', b'a', b'position.', b'\"Dieter\"', b'is', b'the', b'first', b'name', b'of', b'a', b'quite', b'popular', b'German', b'musician,', b'who', b'is', b'either', b'loved', b'or', b'hated', b'for', b'his', b'kind', b'of', b'acting', b'and', b'thats', b'exactly', b'what', b'this', b'movie', b'is', b'about.', b'It', b'is', b'based', b'on', b'the', b'autobiography', b'\"Dieter', b'Bohlen\"', b'wrote', b'a', b'few', b'years', b'ago', b'but', b\"isn't\", b'meant', b'to', b'be', b'accurate', b'on', b'that.', b'The', b'movie', b'is', b'filled', b'with', b'some', b'sexual', b'offensive', b'content', b'(at', b'least', b'for', b'American', b'standard)', b'which', b'is', b'either', b'amusing', b'(not', b'for', b'the', b'other', b'\"actors\"', b'of', b'course)', b'or', b'dumb', b'-', b'it', b'depends', b'on', b'your', b'individual', b'kind', b'of', b'humor', b'or', b'on', b'you', b'being', b'a', b'\"Bohlen\"-Fan', b'or', b'not.', b'Technically', b'speaking', b'there', b\"isn't\", b'much', b'to', b'criticize.', b'Speaking', b'of', b'me', b'I', b'find', b'this', b'movie', b'to', b'be', b'an', b'OK-movie.']]\n"
          ]
        }
      ],
      "source": [
        "for val in range(10):\n",
        "  print([train_examples[val].split()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xOqYgqzjRDw8",
        "outputId": "cfc95c1d-3edf-419f-f101-1d9a47249645"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training entries: 25000, test entries: 25000\n"
          ]
        }
      ],
      "source": [
        "print(\"Training entries: {}, test entries: {}\".format(len(train_examples), len(test_examples)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YpaIIPZdRH9B"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import TextVectorization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rHh84OoQS63k"
      },
      "outputs": [],
      "source": [
        "tv_layer = TextVectorization(max_tokens=10000, standardize=\"lower_and_strip_punctuation\", split=\"whitespace\", ngrams=None, output_mode=\"int\", output_sequence_length=None, pad_to_max_tokens=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zyX2sU3iT0ex"
      },
      "outputs": [],
      "source": [
        "output_seq_length = round(sum([len(i.split()) for i in train_examples])/len(train_examples))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6JvHfTKaUKIc"
      },
      "outputs": [],
      "source": [
        "tv_layer = TextVectorization(max_tokens=10000, standardize=\"lower_and_strip_punctuation\", split=\"whitespace\", output_mode=\"int\", output_sequence_length=output_seq_length, pad_to_max_tokens=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8l8HDqPSVLCN"
      },
      "outputs": [],
      "source": [
        "tv_layer.adapt(train_examples)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NBE-VdkCVfg6"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "embedding_layer = layers.Embedding(input_dim=10000, output_dim=128, input_length=output_seq_length)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tEf0BzQGWZQG"
      },
      "source": [
        "## Model 0: Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rqli3hdlWITI"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "model_0 = Pipeline([\n",
        "    (\"tfidf\", TfidfVectorizer()),\n",
        "    (\"clf\", MultinomialNB())\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dwEH7gC8W0gq",
        "outputId": "e4d82412-8e78-4f86-ba8d-7703d7e66c77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('tfidf', TfidfVectorizer()), ('clf', MultinomialNB())])"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "model_0.fit(train_examples, train_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zi-9C92eXAJ1",
        "outputId": "f0f83da3-bc83-44df-8e32-3f9ada976c65"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.82956"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "#Evaluate the baseline model\n",
        "\n",
        "model_0_score = model_0.score(test_examples, test_labels)\n",
        "model_0_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SQYDAdXkXQdp"
      },
      "outputs": [],
      "source": [
        "model_0_preds = model_0.predict(test_examples)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GC1BZu2FYT9d"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "def calculate_results(y_true, y_pred):\n",
        "  model_accuracy = accuracy_score(y_true, y_pred) * 100\n",
        "  model_precision, model_recall, model_f1_score, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
        "  model_results = {\n",
        "      \"accuracy\": model_accuracy,\n",
        "      \"precision\":model_precision,\n",
        "      \"recall\": model_recall,\n",
        "      \"f1_score\": model_f1_score\n",
        "  }\n",
        "  return model_results\n",
        "\n",
        "def return_callbacks(model_name):\n",
        "  callbacks_list = []\n",
        "  callbacks_list.append(tf.keras.callbacks.ModelCheckpoint(\"saved_models/\"+model_name, monitor='val_loss', save_best_only='True', verbose=1))\n",
        "  callbacks_list.append(tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, verbose=1, restore_best_weights='True'))\n",
        "  return callbacks_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lNunU0BIarYB"
      },
      "outputs": [],
      "source": [
        "model_0_results = calculate_results(test_labels, model_0_preds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SGcfzYkVa205",
        "outputId": "8ae5b43e-7c7a-4d03-cd2a-13538e641855"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 82.956,\n",
              " 'precision': 0.8343036261758116,\n",
              " 'recall': 0.82956,\n",
              " 'f1_score': 0.828953229782028}"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "model_0_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvG9THYntkgi"
      },
      "source": [
        "## Model 1: Simple Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1e6itCFCa4vQ",
        "outputId": "2e45aacc-7e6b-4aea-c898-c67de88e51a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"nlp_model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 234)              0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 234, 128)          1280000   \n",
            "                                                                 \n",
            " global_average_pooling1d_2   (None, 128)              0         \n",
            " (GlobalAveragePooling1D)                                        \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,280,129\n",
            "Trainable params: 1,280,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
        "x = tv_layer(inputs)\n",
        "x = embedding_layer(x)\n",
        "x = layers.GlobalAveragePooling1D()(x)\n",
        "output = layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model_1 = tf.keras.Model(inputs, output, name=\"nlp_model_1\")\n",
        "model_1.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SMvtnhzLvBmZ"
      },
      "outputs": [],
      "source": [
        "model_1.compile(loss=\"binary_crossentropy\", optimizer=tf.keras.optimizers.Adam(), metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mTdE91knvdo-",
        "outputId": "76f9e98b-46dd-4a50-de13-0956894e9bc0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "775/782 [============================>.] - ETA: 0s - loss: 0.5360 - accuracy: 0.7744\n",
            "Epoch 1: val_loss improved from inf to 0.39833, saving model to saved_models/nlp_model_1\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.5352 - accuracy: 0.7746 - val_loss: 0.3983 - val_accuracy: 0.8435\n",
            "Epoch 2/20\n",
            "782/782 [==============================] - ETA: 0s - loss: 0.3225 - accuracy: 0.8738\n",
            "Epoch 2: val_loss improved from 0.39833 to 0.33239, saving model to saved_models/nlp_model_1\n",
            "782/782 [==============================] - 8s 11ms/step - loss: 0.3225 - accuracy: 0.8738 - val_loss: 0.3324 - val_accuracy: 0.8592\n",
            "Epoch 3/20\n",
            "780/782 [============================>.] - ETA: 0s - loss: 0.2582 - accuracy: 0.9012\n",
            "Epoch 3: val_loss improved from 0.33239 to 0.31347, saving model to saved_models/nlp_model_1\n",
            "782/782 [==============================] - 8s 11ms/step - loss: 0.2582 - accuracy: 0.9012 - val_loss: 0.3135 - val_accuracy: 0.8717\n",
            "Epoch 4/20\n",
            "781/782 [============================>.] - ETA: 0s - loss: 0.2207 - accuracy: 0.9165\n",
            "Epoch 4: val_loss improved from 0.31347 to 0.31193, saving model to saved_models/nlp_model_1\n",
            "782/782 [==============================] - 8s 11ms/step - loss: 0.2208 - accuracy: 0.9164 - val_loss: 0.3119 - val_accuracy: 0.8710\n",
            "Epoch 5/20\n",
            "782/782 [==============================] - ETA: 0s - loss: 0.1937 - accuracy: 0.9274\n",
            "Epoch 5: val_loss did not improve from 0.31193\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.1937 - accuracy: 0.9274 - val_loss: 0.3223 - val_accuracy: 0.8680\n",
            "Epoch 6/20\n",
            "781/782 [============================>.] - ETA: 0s - loss: 0.1732 - accuracy: 0.9372\n",
            "Epoch 6: val_loss did not improve from 0.31193\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.1733 - accuracy: 0.9372 - val_loss: 0.3417 - val_accuracy: 0.8620\n",
            "Epoch 7/20\n",
            "776/782 [============================>.] - ETA: 0s - loss: 0.1555 - accuracy: 0.9456\n",
            "Epoch 7: val_loss did not improve from 0.31193\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.1552 - accuracy: 0.9456 - val_loss: 0.3525 - val_accuracy: 0.8622\n",
            "Epoch 8/20\n",
            "781/782 [============================>.] - ETA: 0s - loss: 0.1392 - accuracy: 0.9534\n",
            "Epoch 8: val_loss did not improve from 0.31193\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.1392 - accuracy: 0.9534 - val_loss: 0.3736 - val_accuracy: 0.8578\n",
            "Epoch 9/20\n",
            "774/782 [============================>.] - ETA: 0s - loss: 0.1271 - accuracy: 0.9564\n",
            "Epoch 9: val_loss did not improve from 0.31193\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.1272 - accuracy: 0.9565 - val_loss: 0.3971 - val_accuracy: 0.8549\n",
            "Epoch 10/20\n",
            "775/782 [============================>.] - ETA: 0s - loss: 0.1146 - accuracy: 0.9634\n",
            "Epoch 10: val_loss did not improve from 0.31193\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.1146 - accuracy: 0.9634 - val_loss: 0.4328 - val_accuracy: 0.8507\n",
            "Epoch 11/20\n",
            "782/782 [==============================] - ETA: 0s - loss: 0.1045 - accuracy: 0.9674\n",
            "Epoch 11: val_loss did not improve from 0.31193\n",
            "782/782 [==============================] - 7s 10ms/step - loss: 0.1045 - accuracy: 0.9674 - val_loss: 0.4593 - val_accuracy: 0.8477\n",
            "Epoch 12/20\n",
            "775/782 [============================>.] - ETA: 0s - loss: 0.0947 - accuracy: 0.9711\n",
            "Epoch 12: val_loss did not improve from 0.31193\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.0952 - accuracy: 0.9708 - val_loss: 0.4889 - val_accuracy: 0.8461\n",
            "Epoch 13/20\n",
            "778/782 [============================>.] - ETA: 0s - loss: 0.0867 - accuracy: 0.9742\n",
            "Epoch 13: val_loss did not improve from 0.31193\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.0867 - accuracy: 0.9741 - val_loss: 0.5389 - val_accuracy: 0.8401\n",
            "Epoch 14/20\n",
            "779/782 [============================>.] - ETA: 0s - loss: 0.0789 - accuracy: 0.9769\n",
            "Epoch 14: val_loss did not improve from 0.31193\n",
            "Restoring model weights from the end of the best epoch: 4.\n",
            "782/782 [==============================] - 8s 11ms/step - loss: 0.0788 - accuracy: 0.9770 - val_loss: 0.5600 - val_accuracy: 0.8404\n",
            "Epoch 14: early stopping\n"
          ]
        }
      ],
      "source": [
        "history_1 = model_1.fit(train_examples, train_labels, epochs=20, validation_data=(test_examples, test_labels), callbacks=return_callbacks(model_1.name))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oc33gwgwzg5s",
        "outputId": "f4d360cb-8c78-4f8a-d03f-ae1df5c1ebe2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 3s 4ms/step - loss: 0.3119 - accuracy: 0.8710\n",
            "782/782 [==============================] - 3s 3ms/step\n"
          ]
        }
      ],
      "source": [
        "model_1.evaluate(test_examples, test_labels)\n",
        "model_1_preds = model_1.predict(test_examples)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uI5l0ZRBzhfQ",
        "outputId": "be18c274-6ffd-4ad3-df8e-b9fe2cc42725"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(25000, 1), dtype=float32, numpy=\n",
              "array([[1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       ...,\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ],
      "source": [
        "tf.round(model_1_preds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GDVB-pRNzh-K",
        "outputId": "64ba4343-7eec-4c4d-a844-caadc974be1e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       ...,\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ],
      "source": [
        "test_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p2cG4jQwvlt3"
      },
      "outputs": [],
      "source": [
        "model_1_results = calculate_results(test_labels, tf.round(model_1_preds))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gHKRfb_W24oC",
        "outputId": "693c470f-527e-45f4-a995-eea0ef3c1586"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 87.1,\n",
              " 'precision': 0.8710383006512077,\n",
              " 'recall': 0.871,\n",
              " 'f1_score': 0.8709966708884878}"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ],
      "source": [
        "model_1_results"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## model 2: Model with 1 or 2 layers"
      ],
      "metadata": {
        "id": "n87Zd5VZECPe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FWsDbPId28Xu"
      },
      "outputs": [],
      "source": [
        "tf.keras.backend.clear_session()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
        "x = tv_layer(inputs)\n",
        "x = embedding_layer(x)\n",
        "x = layers.GlobalAveragePooling1D()(x)\n",
        "x = layers.Dense(64, activation='relu')(x)\n",
        "output = layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model_2 = tf.keras.Model(inputs, output, name=\"nlp_model_2\")\n",
        "model_2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ItTqNwYIEIA8",
        "outputId": "a180c27d-8439-46ec-fd57-97718038cc71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"nlp_model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 234)              0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 234, 128)          1280000   \n",
            "                                                                 \n",
            " global_average_pooling1d (G  (None, 128)              0         \n",
            " lobalAveragePooling1D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,288,321\n",
            "Trainable params: 1,288,321\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_2.compile(loss=\"binary_crossentropy\", optimizer=tf.keras.optimizers.Adam(), metrics=[\"accuracy\"])\n",
        "history_2 = model_2.fit(train_examples, train_labels, epochs=20, validation_data=(test_examples, test_labels),callbacks=return_callbacks(model_2.name))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dk7aYdMBESsW",
        "outputId": "f9fef5f8-6f12-46d7-cc39-b5149e4c0ddf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "782/782 [==============================] - ETA: 0s - loss: 0.0799 - accuracy: 0.9767\n",
            "Epoch 1: val_loss improved from inf to 0.57213, saving model to saved_models/nlp_model_2\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.0799 - accuracy: 0.9767 - val_loss: 0.5721 - val_accuracy: 0.8404\n",
            "Epoch 2/20\n",
            "776/782 [============================>.] - ETA: 0s - loss: 0.0686 - accuracy: 0.9807\n",
            "Epoch 2: val_loss did not improve from 0.57213\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.0685 - accuracy: 0.9807 - val_loss: 0.6531 - val_accuracy: 0.8359\n",
            "Epoch 3/20\n",
            "780/782 [============================>.] - ETA: 0s - loss: 0.0591 - accuracy: 0.9844\n",
            "Epoch 3: val_loss did not improve from 0.57213\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.0590 - accuracy: 0.9844 - val_loss: 0.7415 - val_accuracy: 0.8368\n",
            "Epoch 4/20\n",
            "776/782 [============================>.] - ETA: 0s - loss: 0.0499 - accuracy: 0.9872\n",
            "Epoch 4: val_loss did not improve from 0.57213\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.0498 - accuracy: 0.9872 - val_loss: 0.8035 - val_accuracy: 0.8299\n",
            "Epoch 5/20\n",
            "777/782 [============================>.] - ETA: 0s - loss: 0.0427 - accuracy: 0.9882\n",
            "Epoch 5: val_loss did not improve from 0.57213\n",
            "782/782 [==============================] - 9s 12ms/step - loss: 0.0429 - accuracy: 0.9881 - val_loss: 0.9690 - val_accuracy: 0.8292\n",
            "Epoch 6/20\n",
            "781/782 [============================>.] - ETA: 0s - loss: 0.0365 - accuracy: 0.9898\n",
            "Epoch 6: val_loss did not improve from 0.57213\n",
            "782/782 [==============================] - 9s 12ms/step - loss: 0.0365 - accuracy: 0.9898 - val_loss: 0.9966 - val_accuracy: 0.8266\n",
            "Epoch 7/20\n",
            "774/782 [============================>.] - ETA: 0s - loss: 0.0290 - accuracy: 0.9920\n",
            "Epoch 7: val_loss did not improve from 0.57213\n",
            "782/782 [==============================] - 10s 12ms/step - loss: 0.0290 - accuracy: 0.9919 - val_loss: 1.1192 - val_accuracy: 0.8273\n",
            "Epoch 8/20\n",
            "781/782 [============================>.] - ETA: 0s - loss: 0.0251 - accuracy: 0.9924\n",
            "Epoch 8: val_loss did not improve from 0.57213\n",
            "782/782 [==============================] - 9s 12ms/step - loss: 0.0251 - accuracy: 0.9924 - val_loss: 1.3774 - val_accuracy: 0.8262\n",
            "Epoch 9/20\n",
            "776/782 [============================>.] - ETA: 0s - loss: 0.0215 - accuracy: 0.9930\n",
            "Epoch 9: val_loss did not improve from 0.57213\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.0214 - accuracy: 0.9930 - val_loss: 1.5199 - val_accuracy: 0.8251\n",
            "Epoch 10/20\n",
            "778/782 [============================>.] - ETA: 0s - loss: 0.0168 - accuracy: 0.9936\n",
            "Epoch 10: val_loss did not improve from 0.57213\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.0167 - accuracy: 0.9936 - val_loss: 1.6398 - val_accuracy: 0.8250\n",
            "Epoch 11/20\n",
            "778/782 [============================>.] - ETA: 0s - loss: 0.0150 - accuracy: 0.9939\n",
            "Epoch 11: val_loss did not improve from 0.57213\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 0.0153 - accuracy: 0.9938 - val_loss: 1.8966 - val_accuracy: 0.8240\n",
            "Epoch 11: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_2.evaluate(test_examples, test_labels)\n",
        "model_2_preds = model_2.predict(test_examples)\n",
        "model_2_results = calculate_results(test_labels, tf.round(model_2_preds))\n",
        "model_2_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmlh96vwEf5G",
        "outputId": "573fc7c7-6de6-453b-ae99-19752fe6a626"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 4s 5ms/step - loss: 0.5721 - accuracy: 0.8404\n",
            "782/782 [==============================] - 3s 4ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 84.04,\n",
              " 'precision': 0.8404263626175211,\n",
              " 'recall': 0.8404,\n",
              " 'f1_score': 0.8403969100841793}"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 3: LSTM"
      ],
      "metadata": {
        "id": "io1X5I3KHpbF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()"
      ],
      "metadata": {
        "id": "pmA2ki0ZHauZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "model_3_embedding = layers.Embedding(input_dim=10000, output_dim=128, embeddings_initializer=\"uniform\", input_length=output_seq_length, name=\"embedding_2\")\n",
        "\n",
        "inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
        "x = tv_layer(inputs)\n",
        "x = model_3_embedding(x)\n",
        "x = layers.LSTM(64)(x)\n",
        "x = layers.Dense(64, activation='relu')(x)\n",
        "output = layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model_3 = tf.keras.Model(inputs, output, name=\"nlp_model_3\")\n",
        "model_3.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXZuEFHyHuAs",
        "outputId": "cd11874c-faf1-4159-d140-03fcb71c7a39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"nlp_model_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 234)              0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding_2 (Embedding)     (None, 234, 128)          1280000   \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 64)                49408     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,333,633\n",
            "Trainable params: 1,333,633\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_3.compile(loss=\"binary_crossentropy\", optimizer=tf.keras.optimizers.Adam(), metrics=[\"accuracy\"])\n",
        "history_3 = model_3.fit(train_examples, train_labels, epochs=20, validation_data=(test_examples, test_labels),callbacks=return_callbacks(model_3.name))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aDZ4sUyzI068",
        "outputId": "00776705-a286-4bab-8575-f8881a255b5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "781/782 [============================>.] - ETA: 0s - loss: 0.6749 - accuracy: 0.5553\n",
            "Epoch 1: val_loss improved from inf to 0.70065, saving model to saved_models/nlp_model_3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r782/782 [==============================] - 27s 29ms/step - loss: 0.6749 - accuracy: 0.5552 - val_loss: 0.7006 - val_accuracy: 0.5000\n",
            "Epoch 2/20\n",
            "781/782 [============================>.] - ETA: 0s - loss: 0.6814 - accuracy: 0.5517\n",
            "Epoch 2: val_loss improved from 0.70065 to 0.68708, saving model to saved_models/nlp_model_3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r782/782 [==============================] - 24s 31ms/step - loss: 0.6814 - accuracy: 0.5517 - val_loss: 0.6871 - val_accuracy: 0.5287\n",
            "Epoch 3/20\n",
            "781/782 [============================>.] - ETA: 0s - loss: 0.6059 - accuracy: 0.6724\n",
            "Epoch 3: val_loss improved from 0.68708 to 0.58070, saving model to saved_models/nlp_model_3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r782/782 [==============================] - 21s 27ms/step - loss: 0.6059 - accuracy: 0.6724 - val_loss: 0.5807 - val_accuracy: 0.7876\n",
            "Epoch 4/20\n",
            "779/782 [============================>.] - ETA: 0s - loss: 0.3438 - accuracy: 0.8619\n",
            "Epoch 4: val_loss improved from 0.58070 to 0.34037, saving model to saved_models/nlp_model_3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r782/782 [==============================] - 21s 26ms/step - loss: 0.3434 - accuracy: 0.8620 - val_loss: 0.3404 - val_accuracy: 0.8568\n",
            "Epoch 5/20\n",
            "782/782 [==============================] - ETA: 0s - loss: 0.2119 - accuracy: 0.9192\n",
            "Epoch 5: val_loss did not improve from 0.34037\n",
            "782/782 [==============================] - 21s 27ms/step - loss: 0.2119 - accuracy: 0.9192 - val_loss: 0.3408 - val_accuracy: 0.8558\n",
            "Epoch 6/20\n",
            "780/782 [============================>.] - ETA: 0s - loss: 0.1447 - accuracy: 0.9503\n",
            "Epoch 6: val_loss did not improve from 0.34037\n",
            "782/782 [==============================] - 16s 21ms/step - loss: 0.1446 - accuracy: 0.9504 - val_loss: 0.4001 - val_accuracy: 0.8517\n",
            "Epoch 7/20\n",
            "779/782 [============================>.] - ETA: 0s - loss: 0.0945 - accuracy: 0.9710\n",
            "Epoch 7: val_loss did not improve from 0.34037\n",
            "782/782 [==============================] - 16s 21ms/step - loss: 0.0947 - accuracy: 0.9710 - val_loss: 0.4741 - val_accuracy: 0.8442\n",
            "Epoch 8/20\n",
            "781/782 [============================>.] - ETA: 0s - loss: 0.0586 - accuracy: 0.9833\n",
            "Epoch 8: val_loss did not improve from 0.34037\n",
            "782/782 [==============================] - 17s 21ms/step - loss: 0.0585 - accuracy: 0.9833 - val_loss: 0.5550 - val_accuracy: 0.8468\n",
            "Epoch 9/20\n",
            "780/782 [============================>.] - ETA: 0s - loss: 0.0397 - accuracy: 0.9895\n",
            "Epoch 9: val_loss did not improve from 0.34037\n",
            "782/782 [==============================] - 16s 21ms/step - loss: 0.0397 - accuracy: 0.9895 - val_loss: 0.6584 - val_accuracy: 0.8432\n",
            "Epoch 10/20\n",
            "782/782 [==============================] - ETA: 0s - loss: 0.0314 - accuracy: 0.9921\n",
            "Epoch 10: val_loss did not improve from 0.34037\n",
            "782/782 [==============================] - 16s 21ms/step - loss: 0.0314 - accuracy: 0.9921 - val_loss: 0.6687 - val_accuracy: 0.8382\n",
            "Epoch 11/20\n",
            "782/782 [==============================] - ETA: 0s - loss: 0.0246 - accuracy: 0.9939\n",
            "Epoch 11: val_loss did not improve from 0.34037\n",
            "782/782 [==============================] - 16s 21ms/step - loss: 0.0246 - accuracy: 0.9939 - val_loss: 0.7308 - val_accuracy: 0.8369\n",
            "Epoch 12/20\n",
            "781/782 [============================>.] - ETA: 0s - loss: 0.0201 - accuracy: 0.9952\n",
            "Epoch 12: val_loss did not improve from 0.34037\n",
            "782/782 [==============================] - 16s 21ms/step - loss: 0.0201 - accuracy: 0.9952 - val_loss: 0.8245 - val_accuracy: 0.8396\n",
            "Epoch 13/20\n",
            "780/782 [============================>.] - ETA: 0s - loss: 0.0165 - accuracy: 0.9961\n",
            "Epoch 13: val_loss did not improve from 0.34037\n",
            "782/782 [==============================] - 16s 21ms/step - loss: 0.0165 - accuracy: 0.9960 - val_loss: 0.7992 - val_accuracy: 0.8381\n",
            "Epoch 14/20\n",
            "780/782 [============================>.] - ETA: 0s - loss: 0.0181 - accuracy: 0.9947\n",
            "Epoch 14: val_loss did not improve from 0.34037\n",
            "Restoring model weights from the end of the best epoch: 4.\n",
            "782/782 [==============================] - 16s 21ms/step - loss: 0.0181 - accuracy: 0.9947 - val_loss: 0.8776 - val_accuracy: 0.8358\n",
            "Epoch 14: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_3.evaluate(test_examples, test_labels)\n",
        "model_3_preds = model_3.predict(test_examples)\n",
        "model_3_results = calculate_results(test_labels, tf.round(model_3_preds))\n",
        "model_3_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VGxztAjvI-Sh",
        "outputId": "c0ddb68d-f6d0-4980-d9fd-0ba26e1f2b0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 7s 9ms/step - loss: 0.3404 - accuracy: 0.8568\n",
            "782/782 [==============================] - 6s 7ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 85.68,\n",
              " 'precision': 0.8568036536694135,\n",
              " 'recall': 0.8568,\n",
              " 'f1_score': 0.8567996334070617}"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 4: LSTM AND GRU"
      ],
      "metadata": {
        "id": "8x1Ll110JH98"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()"
      ],
      "metadata": {
        "id": "vtrpGOsMJHNr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "model_4_embedding = layers.Embedding(input_dim=10000, output_dim=128, embeddings_initializer=\"uniform\", input_length=output_seq_length, name=\"embedding_4\")\n",
        "\n",
        "inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
        "x = tv_layer(inputs)\n",
        "x = model_4_embedding(x)\n",
        "x = layers.LSTM(64, return_sequences=True)(x)\n",
        "x = layers.GRU(64)(x)\n",
        "x = layers.Dense(64, activation='relu')(x)\n",
        "output = layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model_4 = tf.keras.Model(inputs, output, name=\"nlp_model_4\")\n",
        "model_4.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zqDyA4dWLa75",
        "outputId": "26f4719e-0068-46e2-8375-16d1a1789204"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"nlp_model_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 234)              0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding_4 (Embedding)     (None, 234, 128)          1280000   \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 234, 64)           49408     \n",
            "                                                                 \n",
            " gru_1 (GRU)                 (None, 64)                24960     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,358,593\n",
            "Trainable params: 1,358,593\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_4.compile(loss=\"binary_crossentropy\", optimizer=tf.keras.optimizers.Adam(), metrics=[\"accuracy\"])\n",
        "history_4 = model_4.fit(train_examples, train_labels, epochs=20, validation_data=(test_examples, test_labels),callbacks=return_callbacks(model_4.name))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_bopOrz9L1nH",
        "outputId": "f626fd95-46fb-4f5c-b477-b86aa1c511f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "782/782 [==============================] - ETA: 0s - loss: 0.6854 - accuracy: 0.5507\n",
            "Epoch 1: val_loss improved from inf to 0.68581, saving model to saved_models/nlp_model_4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, gru_cell_1_layer_call_fn, gru_cell_1_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r782/782 [==============================] - 37s 44ms/step - loss: 0.6854 - accuracy: 0.5507 - val_loss: 0.6858 - val_accuracy: 0.5391\n",
            "Epoch 2/20\n",
            "780/782 [============================>.] - ETA: 0s - loss: 0.5160 - accuracy: 0.7227\n",
            "Epoch 2: val_loss improved from 0.68581 to 0.36252, saving model to saved_models/nlp_model_4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, gru_cell_1_layer_call_fn, gru_cell_1_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r782/782 [==============================] - 32s 41ms/step - loss: 0.5158 - accuracy: 0.7229 - val_loss: 0.3625 - val_accuracy: 0.8386\n",
            "Epoch 3/20\n",
            "781/782 [============================>.] - ETA: 0s - loss: 0.2495 - accuracy: 0.9014\n",
            "Epoch 3: val_loss improved from 0.36252 to 0.32268, saving model to saved_models/nlp_model_4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, gru_cell_1_layer_call_fn, gru_cell_1_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r782/782 [==============================] - 31s 39ms/step - loss: 0.2495 - accuracy: 0.9014 - val_loss: 0.3227 - val_accuracy: 0.8585\n",
            "Epoch 4/20\n",
            "781/782 [============================>.] - ETA: 0s - loss: 0.1618 - accuracy: 0.9402\n",
            "Epoch 4: val_loss did not improve from 0.32268\n",
            "782/782 [==============================] - 24s 31ms/step - loss: 0.1618 - accuracy: 0.9402 - val_loss: 0.3265 - val_accuracy: 0.8690\n",
            "Epoch 5/20\n",
            "780/782 [============================>.] - ETA: 0s - loss: 0.0917 - accuracy: 0.9701\n",
            "Epoch 5: val_loss did not improve from 0.32268\n",
            "782/782 [==============================] - 24s 31ms/step - loss: 0.0916 - accuracy: 0.9701 - val_loss: 0.4377 - val_accuracy: 0.8530\n",
            "Epoch 6/20\n",
            "780/782 [============================>.] - ETA: 0s - loss: 0.0517 - accuracy: 0.9846\n",
            "Epoch 6: val_loss did not improve from 0.32268\n",
            "782/782 [==============================] - 24s 31ms/step - loss: 0.0516 - accuracy: 0.9846 - val_loss: 0.5097 - val_accuracy: 0.8499\n",
            "Epoch 7/20\n",
            "782/782 [==============================] - ETA: 0s - loss: 0.0369 - accuracy: 0.9883\n",
            "Epoch 7: val_loss did not improve from 0.32268\n",
            "782/782 [==============================] - 24s 30ms/step - loss: 0.0369 - accuracy: 0.9883 - val_loss: 0.6468 - val_accuracy: 0.8401\n",
            "Epoch 8/20\n",
            "782/782 [==============================] - ETA: 0s - loss: 0.0209 - accuracy: 0.9946\n",
            "Epoch 8: val_loss did not improve from 0.32268\n",
            "782/782 [==============================] - 24s 30ms/step - loss: 0.0209 - accuracy: 0.9946 - val_loss: 0.6429 - val_accuracy: 0.8533\n",
            "Epoch 9/20\n",
            "780/782 [============================>.] - ETA: 0s - loss: 0.0207 - accuracy: 0.9932\n",
            "Epoch 9: val_loss did not improve from 0.32268\n",
            "782/782 [==============================] - 24s 30ms/step - loss: 0.0207 - accuracy: 0.9932 - val_loss: 0.6723 - val_accuracy: 0.8523\n",
            "Epoch 10/20\n",
            "781/782 [============================>.] - ETA: 0s - loss: 0.0172 - accuracy: 0.9945\n",
            "Epoch 10: val_loss did not improve from 0.32268\n",
            "782/782 [==============================] - 24s 30ms/step - loss: 0.0172 - accuracy: 0.9945 - val_loss: 0.6428 - val_accuracy: 0.8422\n",
            "Epoch 11/20\n",
            "781/782 [============================>.] - ETA: 0s - loss: 0.0151 - accuracy: 0.9951\n",
            "Epoch 11: val_loss did not improve from 0.32268\n",
            "782/782 [==============================] - 24s 30ms/step - loss: 0.0151 - accuracy: 0.9951 - val_loss: 0.7904 - val_accuracy: 0.8470\n",
            "Epoch 12/20\n",
            "781/782 [============================>.] - ETA: 0s - loss: 0.0108 - accuracy: 0.9970\n",
            "Epoch 12: val_loss did not improve from 0.32268\n",
            "782/782 [==============================] - 24s 30ms/step - loss: 0.0108 - accuracy: 0.9970 - val_loss: 0.8902 - val_accuracy: 0.8517\n",
            "Epoch 13/20\n",
            "780/782 [============================>.] - ETA: 0s - loss: 0.0112 - accuracy: 0.9966\n",
            "Epoch 13: val_loss did not improve from 0.32268\n",
            "Restoring model weights from the end of the best epoch: 3.\n",
            "782/782 [==============================] - 24s 31ms/step - loss: 0.0111 - accuracy: 0.9966 - val_loss: 0.8890 - val_accuracy: 0.8400\n",
            "Epoch 13: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_4.evaluate(test_examples, test_labels)\n",
        "model_4_preds = model_4.predict(test_examples)\n",
        "model_4_results = calculate_results(test_labels, tf.round(model_4_preds))\n",
        "model_4_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K_QKHFswMC-5",
        "outputId": "ea14811b-8db9-4b2a-a620-b0a50fb00822"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 9s 11ms/step - loss: 0.3227 - accuracy: 0.8585\n",
            "782/782 [==============================] - 9s 10ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 85.85199999999999,\n",
              " 'precision': 0.8648228523777816,\n",
              " 'recall': 0.85852,\n",
              " 'f1_score': 0.8579062804011561}"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 5: BI-Directional RNN"
      ],
      "metadata": {
        "id": "oLzG9qF-NfjI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()"
      ],
      "metadata": {
        "id": "jFGJzx1DMI3-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "model_5_embedding = layers.Embedding(input_dim=10000, output_dim=128, embeddings_initializer=\"uniform\", input_length=output_seq_length, name=\"embedding_5\")\n",
        "\n",
        "inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
        "x = tv_layer(inputs)\n",
        "x = model_5_embedding(x)\n",
        "x = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(x)\n",
        "x = layers.Bidirectional(layers.GRU(64))(x)\n",
        "x = layers.Dense(64, activation='relu')(x)\n",
        "output = layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model_5 = tf.keras.Model(inputs, output, name=\"nlp_model_5\")\n",
        "model_5.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9rg-sL1NlXd",
        "outputId": "8ff94ffa-b7f1-48c2-9d4f-289bcb1ae953"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"nlp_model_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 234)              0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding_5 (Embedding)     (None, 234, 128)          1280000   \n",
            "                                                                 \n",
            " bidirectional_2 (Bidirectio  (None, 234, 128)         98816     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " bidirectional_3 (Bidirectio  (None, 128)              74496     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,461,633\n",
            "Trainable params: 1,461,633\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_5.compile(loss=\"binary_crossentropy\", optimizer=tf.keras.optimizers.Adam(), metrics=[\"accuracy\"])\n",
        "history_5 = model_5.fit(train_examples, train_labels, epochs=20, validation_data=(test_examples, test_labels),callbacks=return_callbacks(model_5.name))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QG0mW0kZNxsN",
        "outputId": "b11b2c99-a845-45f2-9ad7-2724f8efc6d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "781/782 [============================>.] - ETA: 0s - loss: 0.4589 - accuracy: 0.7774\n",
            "Epoch 1: val_loss improved from inf to 0.36475, saving model to saved_models/nlp_model_5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_4_layer_call_fn, lstm_cell_4_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses, gru_cell_4_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r782/782 [==============================] - 95s 114ms/step - loss: 0.4590 - accuracy: 0.7774 - val_loss: 0.3647 - val_accuracy: 0.8515\n",
            "Epoch 2/20\n",
            "782/782 [==============================] - ETA: 0s - loss: 0.2764 - accuracy: 0.8935\n",
            "Epoch 2: val_loss improved from 0.36475 to 0.35377, saving model to saved_models/nlp_model_5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_4_layer_call_fn, lstm_cell_4_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses, gru_cell_4_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r782/782 [==============================] - 61s 78ms/step - loss: 0.2764 - accuracy: 0.8935 - val_loss: 0.3538 - val_accuracy: 0.8528\n",
            "Epoch 3/20\n",
            "781/782 [============================>.] - ETA: 0s - loss: 0.2017 - accuracy: 0.9257\n",
            "Epoch 3: val_loss improved from 0.35377 to 0.34702, saving model to saved_models/nlp_model_5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_4_layer_call_fn, lstm_cell_4_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses, gru_cell_4_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r782/782 [==============================] - 62s 80ms/step - loss: 0.2018 - accuracy: 0.9257 - val_loss: 0.3470 - val_accuracy: 0.8527\n",
            "Epoch 4/20\n",
            "782/782 [==============================] - ETA: 0s - loss: 0.1399 - accuracy: 0.9507\n",
            "Epoch 4: val_loss did not improve from 0.34702\n",
            "782/782 [==============================] - 41s 53ms/step - loss: 0.1399 - accuracy: 0.9507 - val_loss: 0.3742 - val_accuracy: 0.8447\n",
            "Epoch 5/20\n",
            "781/782 [============================>.] - ETA: 0s - loss: 0.0977 - accuracy: 0.9663\n",
            "Epoch 5: val_loss did not improve from 0.34702\n",
            "782/782 [==============================] - 41s 53ms/step - loss: 0.0978 - accuracy: 0.9663 - val_loss: 0.4841 - val_accuracy: 0.8479\n",
            "Epoch 6/20\n",
            "781/782 [============================>.] - ETA: 0s - loss: 0.0710 - accuracy: 0.9770\n",
            "Epoch 6: val_loss did not improve from 0.34702\n",
            "782/782 [==============================] - 41s 52ms/step - loss: 0.0710 - accuracy: 0.9770 - val_loss: 0.5464 - val_accuracy: 0.8457\n",
            "Epoch 7/20\n",
            "782/782 [==============================] - ETA: 0s - loss: 0.0492 - accuracy: 0.9838\n",
            "Epoch 7: val_loss did not improve from 0.34702\n",
            "782/782 [==============================] - 41s 52ms/step - loss: 0.0492 - accuracy: 0.9838 - val_loss: 0.5864 - val_accuracy: 0.8414\n",
            "Epoch 8/20\n",
            "782/782 [==============================] - ETA: 0s - loss: 0.0393 - accuracy: 0.9876\n",
            "Epoch 8: val_loss did not improve from 0.34702\n",
            "782/782 [==============================] - 42s 54ms/step - loss: 0.0393 - accuracy: 0.9876 - val_loss: 0.7849 - val_accuracy: 0.8423\n",
            "Epoch 9/20\n",
            "781/782 [============================>.] - ETA: 0s - loss: 0.0301 - accuracy: 0.9902\n",
            "Epoch 9: val_loss did not improve from 0.34702\n",
            "782/782 [==============================] - 42s 53ms/step - loss: 0.0301 - accuracy: 0.9902 - val_loss: 0.7711 - val_accuracy: 0.8383\n",
            "Epoch 10/20\n",
            "781/782 [============================>.] - ETA: 0s - loss: 0.0238 - accuracy: 0.9927\n",
            "Epoch 10: val_loss did not improve from 0.34702\n",
            "782/782 [==============================] - 41s 53ms/step - loss: 0.0238 - accuracy: 0.9927 - val_loss: 0.7655 - val_accuracy: 0.8413\n",
            "Epoch 11/20\n",
            "781/782 [============================>.] - ETA: 0s - loss: 0.0215 - accuracy: 0.9933\n",
            "Epoch 11: val_loss did not improve from 0.34702\n",
            "782/782 [==============================] - 41s 53ms/step - loss: 0.0215 - accuracy: 0.9933 - val_loss: 0.8358 - val_accuracy: 0.8264\n",
            "Epoch 12/20\n",
            "781/782 [============================>.] - ETA: 0s - loss: 0.0171 - accuracy: 0.9943\n",
            "Epoch 12: val_loss did not improve from 0.34702\n",
            "782/782 [==============================] - 41s 53ms/step - loss: 0.0171 - accuracy: 0.9943 - val_loss: 0.8461 - val_accuracy: 0.8419\n",
            "Epoch 13/20\n",
            "781/782 [============================>.] - ETA: 0s - loss: 0.0143 - accuracy: 0.9953\n",
            "Epoch 13: val_loss did not improve from 0.34702\n",
            "Restoring model weights from the end of the best epoch: 3.\n",
            "782/782 [==============================] - 42s 54ms/step - loss: 0.0143 - accuracy: 0.9953 - val_loss: 0.8861 - val_accuracy: 0.8423\n",
            "Epoch 13: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_5.evaluate(test_examples, test_labels)\n",
        "model_5_preds = model_5.predict(test_examples)\n",
        "model_5_results = calculate_results(test_labels, tf.round(model_5_preds))\n",
        "model_5_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_YRh5KWOOg8",
        "outputId": "5f1c8eeb-3bd4-4afc-9562-a4cf209b593c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 15s 19ms/step - loss: 0.3470 - accuracy: 0.8527\n",
            "782/782 [==============================] - 15s 18ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 85.268,\n",
              " 'precision': 0.8543144975626087,\n",
              " 'recall': 0.85268,\n",
              " 'f1_score': 0.8525099023842375}"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## model 6: CNN"
      ],
      "metadata": {
        "id": "AucFTrO8RDfo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()\n",
        "from tensorflow.keras import layers\n",
        "model_6_embedding = layers.Embedding(input_dim=10000, output_dim=128, embeddings_initializer=\"uniform\", input_length=output_seq_length, name=\"embedding_6\")\n",
        "\n",
        "inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
        "x = tv_layer(inputs)\n",
        "x = model_5_embedding(x)\n",
        "x = layers.Conv1D(filters=32, kernel_size=5, activation=\"relu\")(x)\n",
        "x = layers.GlobalMaxPool1D()(x)\n",
        "x = layers.Dense(64, activation='relu')(x)\n",
        "output = layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model_6 = tf.keras.Model(inputs, output, name=\"nlp_model_6\")\n",
        "model_6.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fuICXiDROTaq",
        "outputId": "c6cb8810-e547-41b6-98e5-0ecd4d0a29ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"nlp_model_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 234)              0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding_5 (Embedding)     (None, 234, 128)          1280000   \n",
            "                                                                 \n",
            " conv1d (Conv1D)             (None, 230, 32)           20512     \n",
            "                                                                 \n",
            " global_max_pooling1d (Globa  (None, 32)               0         \n",
            " lMaxPooling1D)                                                  \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                2112      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,302,689\n",
            "Trainable params: 1,302,689\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_6.compile(loss=\"binary_crossentropy\", optimizer=tf.keras.optimizers.Adam(), metrics=[\"accuracy\"])\n",
        "history_6 = model_6.fit(train_examples, train_labels, epochs=20, validation_data=(test_examples, test_labels),callbacks=return_callbacks(model_6.name))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VfBK8OHpRXPj",
        "outputId": "e5f37327-9b30-4eed-bb76-15ae59ddb281"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "782/782 [==============================] - ETA: 0s - loss: 0.3081 - accuracy: 0.8777\n",
            "Epoch 1: val_loss improved from inf to 0.36352, saving model to saved_models/nlp_model_6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r782/782 [==============================] - 15s 13ms/step - loss: 0.3081 - accuracy: 0.8777 - val_loss: 0.3635 - val_accuracy: 0.8405\n",
            "Epoch 2/20\n",
            "780/782 [============================>.] - ETA: 0s - loss: 0.1598 - accuracy: 0.9414\n",
            "Epoch 2: val_loss did not improve from 0.36352\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.1597 - accuracy: 0.9415 - val_loss: 0.3890 - val_accuracy: 0.8484\n",
            "Epoch 3/20\n",
            "782/782 [==============================] - ETA: 0s - loss: 0.0587 - accuracy: 0.9829\n",
            "Epoch 3: val_loss did not improve from 0.36352\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.0587 - accuracy: 0.9829 - val_loss: 0.5268 - val_accuracy: 0.8409\n",
            "Epoch 4/20\n",
            "780/782 [============================>.] - ETA: 0s - loss: 0.0132 - accuracy: 0.9975\n",
            "Epoch 4: val_loss did not improve from 0.36352\n",
            "782/782 [==============================] - 9s 12ms/step - loss: 0.0133 - accuracy: 0.9974 - val_loss: 0.6814 - val_accuracy: 0.8411\n",
            "Epoch 5/20\n",
            "777/782 [============================>.] - ETA: 0s - loss: 0.0026 - accuracy: 0.9999\n",
            "Epoch 5: val_loss did not improve from 0.36352\n",
            "782/782 [==============================] - 9s 12ms/step - loss: 0.0026 - accuracy: 0.9999 - val_loss: 0.7004 - val_accuracy: 0.8487\n",
            "Epoch 6/20\n",
            "779/782 [============================>.] - ETA: 0s - loss: 0.0011 - accuracy: 0.9999\n",
            "Epoch 6: val_loss did not improve from 0.36352\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.0011 - accuracy: 0.9999 - val_loss: 0.7863 - val_accuracy: 0.8478\n",
            "Epoch 7/20\n",
            "780/782 [============================>.] - ETA: 0s - loss: 2.4160e-04 - accuracy: 1.0000\n",
            "Epoch 7: val_loss did not improve from 0.36352\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 2.4129e-04 - accuracy: 1.0000 - val_loss: 0.8264 - val_accuracy: 0.8473\n",
            "Epoch 8/20\n",
            "779/782 [============================>.] - ETA: 0s - loss: 8.6477e-05 - accuracy: 1.0000\n",
            "Epoch 8: val_loss did not improve from 0.36352\n",
            "782/782 [==============================] - 12s 16ms/step - loss: 8.6486e-05 - accuracy: 1.0000 - val_loss: 0.8671 - val_accuracy: 0.8470\n",
            "Epoch 9/20\n",
            "781/782 [============================>.] - ETA: 0s - loss: 5.1353e-05 - accuracy: 1.0000\n",
            "Epoch 9: val_loss did not improve from 0.36352\n",
            "782/782 [==============================] - 11s 14ms/step - loss: 5.1340e-05 - accuracy: 1.0000 - val_loss: 0.9049 - val_accuracy: 0.8468\n",
            "Epoch 10/20\n",
            "782/782 [==============================] - ETA: 0s - loss: 3.2262e-05 - accuracy: 1.0000\n",
            "Epoch 10: val_loss did not improve from 0.36352\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 3.2262e-05 - accuracy: 1.0000 - val_loss: 0.9411 - val_accuracy: 0.8469\n",
            "Epoch 11/20\n",
            "779/782 [============================>.] - ETA: 0s - loss: 2.0853e-05 - accuracy: 1.0000\n",
            "Epoch 11: val_loss did not improve from 0.36352\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "782/782 [==============================] - 10s 12ms/step - loss: 2.0870e-05 - accuracy: 1.0000 - val_loss: 0.9883 - val_accuracy: 0.8467\n",
            "Epoch 11: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_6.evaluate(test_examples, test_labels)\n",
        "model_6_preds = model_6.predict(test_examples)\n",
        "model_6_results = calculate_results(test_labels, tf.round(model_6_preds))\n",
        "model_6_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GNGCKh5TReAY",
        "outputId": "71ae9cb9-1bab-48a2-aaa0-fed9bd54f4da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 4s 5ms/step - loss: 0.3635 - accuracy: 0.8405\n",
            "782/782 [==============================] - 3s 4ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 84.052,\n",
              " 'precision': 0.8459849929470595,\n",
              " 'recall': 0.84052,\n",
              " 'f1_score': 0.8398877381972287}"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame([model_0_results, model_1_results, model_2_results, model_3_results, model_4_results, model_5_results, model_6_results])"
      ],
      "metadata": {
        "id": "LUuYg9gOR5Lg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "K6ytlny6SoSl",
        "outputId": "2ba686e9-6cfb-4af1-fc72-026feb3d1cf0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   accuracy  precision   recall  f1_score\n",
              "0    82.956   0.834304  0.82956  0.828953\n",
              "1    87.100   0.871038  0.87100  0.870997\n",
              "2    84.040   0.840426  0.84040  0.840397\n",
              "3    85.680   0.856804  0.85680  0.856800\n",
              "4    85.852   0.864823  0.85852  0.857906\n",
              "5    85.268   0.854314  0.85268  0.852510\n",
              "6    84.052   0.845985  0.84052  0.839888"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b49b4562-19ae-4456-a7b7-43b96c010272\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accuracy</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>82.956</td>\n",
              "      <td>0.834304</td>\n",
              "      <td>0.82956</td>\n",
              "      <td>0.828953</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>87.100</td>\n",
              "      <td>0.871038</td>\n",
              "      <td>0.87100</td>\n",
              "      <td>0.870997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>84.040</td>\n",
              "      <td>0.840426</td>\n",
              "      <td>0.84040</td>\n",
              "      <td>0.840397</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>85.680</td>\n",
              "      <td>0.856804</td>\n",
              "      <td>0.85680</td>\n",
              "      <td>0.856800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>85.852</td>\n",
              "      <td>0.864823</td>\n",
              "      <td>0.85852</td>\n",
              "      <td>0.857906</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>85.268</td>\n",
              "      <td>0.854314</td>\n",
              "      <td>0.85268</td>\n",
              "      <td>0.852510</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>84.052</td>\n",
              "      <td>0.845985</td>\n",
              "      <td>0.84052</td>\n",
              "      <td>0.839888</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b49b4562-19ae-4456-a7b7-43b96c010272')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b49b4562-19ae-4456-a7b7-43b96c010272 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b49b4562-19ae-4456-a7b7-43b96c010272');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 7: pre-trained Layer"
      ],
      "metadata": {
        "id": "_SA9TiKKS7iW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow_hub as hub\n",
        "sentence_encoder_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
        "                                        input_shape=[], # shape of inputs coming to our model \n",
        "                                        dtype=tf.string, # data type of inputs coming to the USE layer\n",
        "                                        trainable=False, # keep the pretrained weights (we'll create a feature extractor)\n",
        "                                        name=\"USE\")\n",
        "\n",
        "model_7 = tf.keras.Sequential([\n",
        "  sentence_encoder_layer, # take in sentences and then encode them into an embedding\n",
        "  layers.Dense(64, activation=\"relu\"),\n",
        "  layers.Dense(1, activation=\"sigmoid\")\n",
        "], name=\"model_7_USE\")\n",
        "\n",
        "model_7.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_Eo9E5pSsee",
        "outputId": "00a96920-986b-4ffd-8662-1fbbc55846f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_7_USE\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " USE (KerasLayer)            (None, 512)               256797824 \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                32832     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 256,830,721\n",
            "Trainable params: 32,897\n",
            "Non-trainable params: 256,797,824\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_7.compile(loss=\"binary_crossentropy\", optimizer=tf.keras.optimizers.Adam(), metrics=[\"accuracy\"])\n",
        "history_7 = model_7.fit(train_examples, train_labels, epochs=20, validation_data=(test_examples, test_labels),callbacks=return_callbacks(model_7.name))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ylPO297ITTQ3",
        "outputId": "8d8ac73d-c8c3-4eb8-f571-c07b80a297fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "781/782 [============================>.] - ETA: 0s - loss: 0.3734 - accuracy: 0.8406\n",
            "Epoch 1: val_loss improved from inf to 0.32506, saving model to saved_models/model_7_USE\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Function `_wrapped_model` contains input name(s) USE_input with unsupported characters which will be renamed to use_input in the SavedModel.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r782/782 [==============================] - 77s 92ms/step - loss: 0.3733 - accuracy: 0.8407 - val_loss: 0.3251 - val_accuracy: 0.8570\n",
            "Epoch 2/20\n",
            "781/782 [============================>.] - ETA: 0s - loss: 0.3245 - accuracy: 0.8587\n",
            "Epoch 2: val_loss improved from 0.32506 to 0.32488, saving model to saved_models/model_7_USE\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Function `_wrapped_model` contains input name(s) USE_input with unsupported characters which will be renamed to use_input in the SavedModel.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r782/782 [==============================] - 67s 85ms/step - loss: 0.3245 - accuracy: 0.8586 - val_loss: 0.3249 - val_accuracy: 0.8568\n",
            "Epoch 3/20\n",
            "780/782 [============================>.] - ETA: 0s - loss: 0.3201 - accuracy: 0.8627\n",
            "Epoch 3: val_loss improved from 0.32488 to 0.32327, saving model to saved_models/model_7_USE\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Function `_wrapped_model` contains input name(s) USE_input with unsupported characters which will be renamed to use_input in the SavedModel.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r782/782 [==============================] - 62s 80ms/step - loss: 0.3205 - accuracy: 0.8625 - val_loss: 0.3233 - val_accuracy: 0.8564\n",
            "Epoch 4/20\n",
            "782/782 [==============================] - ETA: 0s - loss: 0.3155 - accuracy: 0.8647\n",
            "Epoch 4: val_loss improved from 0.32327 to 0.32241, saving model to saved_models/model_7_USE\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Function `_wrapped_model` contains input name(s) USE_input with unsupported characters which will be renamed to use_input in the SavedModel.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r782/782 [==============================] - 63s 80ms/step - loss: 0.3155 - accuracy: 0.8647 - val_loss: 0.3224 - val_accuracy: 0.8586\n",
            "Epoch 5/20\n",
            "780/782 [============================>.] - ETA: 0s - loss: 0.3110 - accuracy: 0.8674\n",
            "Epoch 5: val_loss did not improve from 0.32241\n",
            "782/782 [==============================] - 55s 70ms/step - loss: 0.3108 - accuracy: 0.8676 - val_loss: 0.3252 - val_accuracy: 0.8554\n",
            "Epoch 6/20\n",
            "781/782 [============================>.] - ETA: 0s - loss: 0.3065 - accuracy: 0.8675\n",
            "Epoch 6: val_loss improved from 0.32241 to 0.32092, saving model to saved_models/model_7_USE\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Function `_wrapped_model` contains input name(s) USE_input with unsupported characters which will be renamed to use_input in the SavedModel.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r782/782 [==============================] - 64s 82ms/step - loss: 0.3064 - accuracy: 0.8676 - val_loss: 0.3209 - val_accuracy: 0.8577\n",
            "Epoch 7/20\n",
            "781/782 [============================>.] - ETA: 0s - loss: 0.3011 - accuracy: 0.8740\n",
            "Epoch 7: val_loss improved from 0.32092 to 0.32076, saving model to saved_models/model_7_USE\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Function `_wrapped_model` contains input name(s) USE_input with unsupported characters which will be renamed to use_input in the SavedModel.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r782/782 [==============================] - 63s 81ms/step - loss: 0.3011 - accuracy: 0.8739 - val_loss: 0.3208 - val_accuracy: 0.8585\n",
            "Epoch 8/20\n",
            "781/782 [============================>.] - ETA: 0s - loss: 0.2969 - accuracy: 0.8749\n",
            "Epoch 8: val_loss improved from 0.32076 to 0.31732, saving model to saved_models/model_7_USE\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Function `_wrapped_model` contains input name(s) USE_input with unsupported characters which will be renamed to use_input in the SavedModel.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r782/782 [==============================] - 65s 84ms/step - loss: 0.2968 - accuracy: 0.8749 - val_loss: 0.3173 - val_accuracy: 0.8600\n",
            "Epoch 9/20\n",
            "781/782 [============================>.] - ETA: 0s - loss: 0.2897 - accuracy: 0.8782\n",
            "Epoch 9: val_loss did not improve from 0.31732\n",
            "782/782 [==============================] - 53s 68ms/step - loss: 0.2900 - accuracy: 0.8782 - val_loss: 0.3237 - val_accuracy: 0.8572\n",
            "Epoch 10/20\n",
            "782/782 [==============================] - ETA: 0s - loss: 0.2841 - accuracy: 0.8836\n",
            "Epoch 10: val_loss did not improve from 0.31732\n",
            "782/782 [==============================] - 54s 68ms/step - loss: 0.2841 - accuracy: 0.8836 - val_loss: 0.3302 - val_accuracy: 0.8552\n",
            "Epoch 11/20\n",
            "782/782 [==============================] - ETA: 0s - loss: 0.2785 - accuracy: 0.8843\n",
            "Epoch 11: val_loss did not improve from 0.31732\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.2785 - accuracy: 0.8843 - val_loss: 0.3202 - val_accuracy: 0.8588\n",
            "Epoch 12/20\n",
            "781/782 [============================>.] - ETA: 0s - loss: 0.2724 - accuracy: 0.8878\n",
            "Epoch 12: val_loss did not improve from 0.31732\n",
            "782/782 [==============================] - 54s 70ms/step - loss: 0.2724 - accuracy: 0.8878 - val_loss: 0.3207 - val_accuracy: 0.8588\n",
            "Epoch 13/20\n",
            "781/782 [============================>.] - ETA: 0s - loss: 0.2663 - accuracy: 0.8905\n",
            "Epoch 13: val_loss did not improve from 0.31732\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.2663 - accuracy: 0.8905 - val_loss: 0.3250 - val_accuracy: 0.8576\n",
            "Epoch 14/20\n",
            "781/782 [============================>.] - ETA: 0s - loss: 0.2603 - accuracy: 0.8954\n",
            "Epoch 14: val_loss did not improve from 0.31732\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.2604 - accuracy: 0.8954 - val_loss: 0.3253 - val_accuracy: 0.8579\n",
            "Epoch 15/20\n",
            "782/782 [==============================] - ETA: 0s - loss: 0.2534 - accuracy: 0.8980\n",
            "Epoch 15: val_loss did not improve from 0.31732\n",
            "782/782 [==============================] - 53s 68ms/step - loss: 0.2534 - accuracy: 0.8980 - val_loss: 0.3246 - val_accuracy: 0.8586\n",
            "Epoch 16/20\n",
            "781/782 [============================>.] - ETA: 0s - loss: 0.2476 - accuracy: 0.8993\n",
            "Epoch 16: val_loss did not improve from 0.31732\n",
            "782/782 [==============================] - 54s 69ms/step - loss: 0.2476 - accuracy: 0.8993 - val_loss: 0.3321 - val_accuracy: 0.8548\n",
            "Epoch 17/20\n",
            "782/782 [==============================] - ETA: 0s - loss: 0.2412 - accuracy: 0.9040\n",
            "Epoch 17: val_loss did not improve from 0.31732\n",
            "782/782 [==============================] - 53s 67ms/step - loss: 0.2412 - accuracy: 0.9040 - val_loss: 0.3271 - val_accuracy: 0.8574\n",
            "Epoch 18/20\n",
            "782/782 [==============================] - ETA: 0s - loss: 0.2359 - accuracy: 0.9059\n",
            "Epoch 18: val_loss did not improve from 0.31732\n",
            "Restoring model weights from the end of the best epoch: 8.\n",
            "782/782 [==============================] - 53s 68ms/step - loss: 0.2359 - accuracy: 0.9059 - val_loss: 0.3372 - val_accuracy: 0.8556\n",
            "Epoch 18: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_7.evaluate(test_examples, test_labels)\n",
        "model_7_preds = model_7.predict(test_examples)\n",
        "model_7_results = calculate_results(test_labels, tf.round(model_7_preds))\n",
        "model_7_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zfZKJ0ZgTdE_",
        "outputId": "a2655bed-065c-420f-8fc8-13df5442cf58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 27s 35ms/step - loss: 0.3173 - accuracy: 0.8600\n",
            "782/782 [==============================] - 27s 34ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 86.004,\n",
              " 'precision': 0.8600400576064092,\n",
              " 'recall': 0.86004,\n",
              " 'f1_score': 0.8600399944015997}"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame([model_0_results, model_1_results, model_2_results, model_3_results, model_4_results, model_5_results, model_6_results, model_7_results])"
      ],
      "metadata": {
        "id": "SqH6tClRTm3t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "YZf08fiyYLyf",
        "outputId": "7cf8e2e5-2032-437f-ec3c-da537ee5e1d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   accuracy  precision   recall  f1_score\n",
              "0    82.956   0.834304  0.82956  0.828953\n",
              "1    87.100   0.871038  0.87100  0.870997\n",
              "2    84.040   0.840426  0.84040  0.840397\n",
              "3    85.680   0.856804  0.85680  0.856800\n",
              "4    85.852   0.864823  0.85852  0.857906\n",
              "5    85.268   0.854314  0.85268  0.852510\n",
              "6    84.052   0.845985  0.84052  0.839888\n",
              "7    86.004   0.860040  0.86004  0.860040"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a3c27fb2-0c3d-4a68-b6ef-795e74406c2f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accuracy</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>82.956</td>\n",
              "      <td>0.834304</td>\n",
              "      <td>0.82956</td>\n",
              "      <td>0.828953</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>87.100</td>\n",
              "      <td>0.871038</td>\n",
              "      <td>0.87100</td>\n",
              "      <td>0.870997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>84.040</td>\n",
              "      <td>0.840426</td>\n",
              "      <td>0.84040</td>\n",
              "      <td>0.840397</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>85.680</td>\n",
              "      <td>0.856804</td>\n",
              "      <td>0.85680</td>\n",
              "      <td>0.856800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>85.852</td>\n",
              "      <td>0.864823</td>\n",
              "      <td>0.85852</td>\n",
              "      <td>0.857906</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>85.268</td>\n",
              "      <td>0.854314</td>\n",
              "      <td>0.85268</td>\n",
              "      <td>0.852510</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>84.052</td>\n",
              "      <td>0.845985</td>\n",
              "      <td>0.84052</td>\n",
              "      <td>0.839888</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>86.004</td>\n",
              "      <td>0.860040</td>\n",
              "      <td>0.86004</td>\n",
              "      <td>0.860040</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a3c27fb2-0c3d-4a68-b6ef-795e74406c2f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a3c27fb2-0c3d-4a68-b6ef-795e74406c2f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a3c27fb2-0c3d-4a68-b6ef-795e74406c2f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NGFdMnrlYNDj"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN/iXQijKMHP3pKfGcm6sRG",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}