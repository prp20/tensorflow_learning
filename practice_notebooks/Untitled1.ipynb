{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed6603bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-25 22:47:50.373565: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-25 22:47:53.059035: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/prp/anaconda3/lib/\n",
      "2023-02-25 22:47:53.059129: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/prp/anaconda3/lib/\n",
      "2023-02-25 22:47:53.059136: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import datetime\n",
    "\n",
    "import IPython\n",
    "import IPython.display\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = (8, 6)\n",
    "mpl.rcParams['axes.grid'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3dff0b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/jena_climate_2009_2016.csv.zip\n",
      "13568290/13568290 [==============================] - 2s 0us/step\n"
     ]
    }
   ],
   "source": [
    "zip_path = tf.keras.utils.get_file(\n",
    "    origin='https://storage.googleapis.com/tensorflow/tf-keras-datasets/jena_climate_2009_2016.csv.zip',\n",
    "    fname='jena_climate_2009_2016.csv.zip',\n",
    "    extract=True)\n",
    "csv_path, _ = os.path.splitext(zip_path) #We load the dataset in a csv_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff3a4935",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed4284d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(data):\n",
    "    \n",
    "    # Getting rid of outliers\n",
    "    data.loc[df['wv (m/s)'] == -9999.0, 'wv (m/s)'] = 0.0\n",
    "    data.loc[df['max. wv (m/s)'] == -9999.0, 'max. wv (m/s)'] = 0.0\n",
    "    \n",
    "    # Taking values every hours\n",
    "    data = data[5::6]# df[start,stop,step]\n",
    "    \n",
    "    wv = data.pop('wv (m/s)')\n",
    "    max_wv = data.pop('max. wv (m/s)')\n",
    "\n",
    "    # Convert to radians.\n",
    "    wd_rad = data.pop('wd (deg)')*np.pi / 180\n",
    "\n",
    "    # Calculate the wind x and y components.\n",
    "    data['Wx'] = wv*np.cos(wd_rad)\n",
    "    data['Wy'] = wv*np.sin(wd_rad)\n",
    "\n",
    "    # Calculate the max wind x and y components.\n",
    "    data['max Wx'] = max_wv*np.cos(wd_rad)\n",
    "    data['max Wy'] = max_wv*np.sin(wd_rad)\n",
    "    \n",
    "    date_time = pd.to_datetime(data.pop('Date Time'), format='%d.%m.%Y %H:%M:%S')\n",
    "    timestamp_s = date_time.map(datetime.datetime.timestamp)\n",
    "    \n",
    "    day = 24*60*60 # Time is second within a single day\n",
    "    year = 365.2425*day # Time in second withon a year\n",
    "\n",
    "    data['Day sin'] = np.sin(timestamp_s * (2*np.pi / day))\n",
    "    data['Day cos'] = np.cos(timestamp_s * (2*np.pi / day))\n",
    "    data['Year sin'] = np.sin(timestamp_s * (2*np.pi / year))\n",
    "    data['Year cos'] = np.cos(timestamp_s * (2*np.pi / year))\n",
    "    \n",
    "    return(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5a43a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(data):\n",
    "    \n",
    "    n = data.shape[0]\n",
    "    \n",
    "    train_df = data.iloc[0: n * 70 //100] # \"iloc\" because we have to select the lines at the indicies 0 to int(n*0.7) compared to \"loc\"\n",
    "    val_df = data.iloc[n * 70 //100 : n * 90 //100]\n",
    "    test_df = data.iloc[n * 90 //100:]\n",
    "    \n",
    "    return(train_df, val_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea1c32be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_92/2152462522.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['Wx'] = wv*np.cos(wd_rad)\n",
      "/tmp/ipykernel_92/2152462522.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['Wy'] = wv*np.sin(wd_rad)\n",
      "/tmp/ipykernel_92/2152462522.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['max Wx'] = max_wv*np.cos(wd_rad)\n",
      "/tmp/ipykernel_92/2152462522.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['max Wy'] = max_wv*np.sin(wd_rad)\n",
      "/tmp/ipykernel_92/2152462522.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['Day sin'] = np.sin(timestamp_s * (2*np.pi / day))\n",
      "/tmp/ipykernel_92/2152462522.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['Day cos'] = np.cos(timestamp_s * (2*np.pi / day))\n",
      "/tmp/ipykernel_92/2152462522.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['Year sin'] = np.sin(timestamp_s * (2*np.pi / year))\n",
      "/tmp/ipykernel_92/2152462522.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['Year cos'] = np.cos(timestamp_s * (2*np.pi / year))\n"
     ]
    }
   ],
   "source": [
    "df_processed = preprocessing(df)\n",
    "\n",
    "train_df, val_df, test_df = split(df_processed)\n",
    "\n",
    "train_mean = train_df.mean() # returns a one column panda dataframe (serie) containing the mean of every columns\n",
    "train_std = train_df.std() # same with standard deviation\n",
    "\n",
    "train_df = (train_df - train_mean)/train_std # As simple as that !\n",
    "val_df = (val_df - train_mean)/train_std\n",
    "test_df = (test_df - train_mean)/train_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57c9b9cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2133bf33",
   "metadata": {},
   "outputs": [],
   "source": [
    "lookback = 48 # Looking at all features for the past 2 days\n",
    "delay = 24 # Trying to predict the temperature for the next day\n",
    "window_length = lookback + delay\n",
    "batch_size = 32 # Features will be batched 32 by 32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8cfe18cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(X, y, delay=24):\n",
    "    # X and y should be pandas dataframes\n",
    "    Xs, ys = [], []\n",
    "    for i in range(lookback, len(X)-delay):\n",
    "        v = X.iloc[i-lookback:i].to_numpy() # every one hour, we take the past 48 hours of features\n",
    "        Xs.append(v)\n",
    "        w = y.iloc[i+delay] # Every timestep, we take the temperature the next delay (here one day)\n",
    "        ys.append(w)\n",
    "    return(np.array(Xs), np.array(ys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28b0e863",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = create_dataset(train_df, train_df['T (degC)'], delay = delay)\n",
    "X_val, y_val = create_dataset(val_df, val_df['T (degC)'], delay = delay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a15e8195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape is (48991, 48, 19): \n",
      "y_train shape is (48991,): \n",
      "\n",
      "X_val shape is (13946, 48, 19): \n",
      "y_val shape is (13946,): \n"
     ]
    }
   ],
   "source": [
    "print(\"X_train shape is {}: \".format(X_train.shape))\n",
    "print(\"y_train shape is {}: \".format(y_train.shape))\n",
    "\n",
    "print(\"\\nX_val shape is {}: \".format(X_val.shape))\n",
    "print(\"y_val shape is {}: \".format(y_val.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d53cb60d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.32\n"
     ]
    }
   ],
   "source": [
    "def naive_eval_arr(X, y, lookback, delay):\n",
    "    batch_maes = []\n",
    "    for i in range(0, len(X)):\n",
    "        preds = X[i, -1, 1] #For all elements in the batch, we are saying the prediction of temperature is equal to the last temperature recorded within the 48 hours\n",
    "        mae = np.mean(np.abs(preds - y[i]))\n",
    "        batch_maes.append(mae)\n",
    "    return(np.mean(batch_maes))\n",
    "\n",
    "naive_loss_arr = naive_eval_arr(X_val, y_val, lookback = lookback, delay = delay)\n",
    "\n",
    "naive_loss_arr = round(naive_eval_arr(X_val, y_val, lookback = lookback, delay = delay),2) # Round the value\n",
    "print(naive_loss_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "19bb8573",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense\n",
    "from keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b9f87af4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-25 23:00:08.018070: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-02-25 23:00:08.130655: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-02-25 23:00:08.130719: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-02-25 23:00:08.133214: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-25 23:00:08.138435: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-02-25 23:00:08.138495: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-02-25 23:00:08.138527: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-02-25 23:00:10.022875: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-02-25 23:00:10.025588: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-02-25 23:00:10.025603: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-02-25 23:00:10.025643: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-02-25 23:00:10.026338: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3929 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "# Let's start with a simple Dense model\n",
    "model = Sequential([\n",
    "    Flatten(input_shape=(lookback, 19)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1) # We try to predict only one value for now\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5f2d3a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-25 23:00:20.485523: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x26f25880 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-02-25 23:00:20.485565: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA GeForce GTX 1660 Ti, Compute Capability 7.5\n",
      "2023-02-25 23:00:20.540407: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-02-25 23:00:21.068097: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-02-25 23:00:21.197181: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1531/1531 [==============================] - 8s 3ms/step - loss: 0.3520 - val_loss: 0.3096\n",
      "Epoch 2/30\n",
      "1531/1531 [==============================] - 5s 3ms/step - loss: 0.2784 - val_loss: 0.2870\n",
      "Epoch 3/30\n",
      "1531/1531 [==============================] - 5s 3ms/step - loss: 0.2702 - val_loss: 0.2985\n",
      "Epoch 4/30\n",
      "1531/1531 [==============================] - 5s 3ms/step - loss: 0.2672 - val_loss: 0.3103\n",
      "Epoch 5/30\n",
      "1531/1531 [==============================] - 5s 3ms/step - loss: 0.2654 - val_loss: 0.2837\n",
      "Epoch 6/30\n",
      "1531/1531 [==============================] - 6s 4ms/step - loss: 0.2640 - val_loss: 0.2802\n",
      "Epoch 7/30\n",
      "1531/1531 [==============================] - 6s 4ms/step - loss: 0.2618 - val_loss: 0.2970\n",
      "Epoch 8/30\n",
      "1531/1531 [==============================] - 6s 4ms/step - loss: 0.2600 - val_loss: 0.3047\n",
      "Epoch 9/30\n",
      "1531/1531 [==============================] - 6s 4ms/step - loss: 0.2580 - val_loss: 0.2859\n",
      "Epoch 10/30\n",
      "1531/1531 [==============================] - 6s 4ms/step - loss: 0.2574 - val_loss: 0.2795\n",
      "Epoch 11/30\n",
      "1531/1531 [==============================] - 7s 4ms/step - loss: 0.2555 - val_loss: 0.2869\n",
      "Epoch 12/30\n",
      "1531/1531 [==============================] - 6s 4ms/step - loss: 0.2542 - val_loss: 0.2862\n",
      "Epoch 13/30\n",
      "1531/1531 [==============================] - 7s 5ms/step - loss: 0.2547 - val_loss: 0.2998\n",
      "Epoch 14/30\n",
      "1531/1531 [==============================] - 6s 4ms/step - loss: 0.2525 - val_loss: 0.2948\n",
      "Epoch 15/30\n",
      "1531/1531 [==============================] - 7s 4ms/step - loss: 0.2509 - val_loss: 0.2928\n",
      "Epoch 16/30\n",
      "1531/1531 [==============================] - 6s 4ms/step - loss: 0.2501 - val_loss: 0.2835\n",
      "Epoch 17/30\n",
      "1531/1531 [==============================] - 6s 4ms/step - loss: 0.2501 - val_loss: 0.3042\n",
      "Epoch 18/30\n",
      "1531/1531 [==============================] - 7s 4ms/step - loss: 0.2500 - val_loss: 0.2796\n",
      "Epoch 19/30\n",
      "1531/1531 [==============================] - 6s 4ms/step - loss: 0.2499 - val_loss: 0.2822\n",
      "Epoch 20/30\n",
      "1531/1531 [==============================] - 6s 4ms/step - loss: 0.2483 - val_loss: 0.2921\n",
      "Epoch 21/30\n",
      "1531/1531 [==============================] - 6s 4ms/step - loss: 0.2475 - val_loss: 0.2838\n",
      "Epoch 22/30\n",
      "1531/1531 [==============================] - 6s 4ms/step - loss: 0.2476 - val_loss: 0.2782\n",
      "Epoch 23/30\n",
      "1531/1531 [==============================] - 6s 4ms/step - loss: 0.2458 - val_loss: 0.2903\n",
      "Epoch 24/30\n",
      "1531/1531 [==============================] - 6s 4ms/step - loss: 0.2461 - val_loss: 0.2919\n",
      "Epoch 25/30\n",
      "1531/1531 [==============================] - 6s 4ms/step - loss: 0.2459 - val_loss: 0.2889\n",
      "Epoch 26/30\n",
      "1531/1531 [==============================] - 7s 4ms/step - loss: 0.2451 - val_loss: 0.3005\n",
      "Epoch 27/30\n",
      "1531/1531 [==============================] - 6s 4ms/step - loss: 0.2446 - val_loss: 0.2836\n",
      "Epoch 28/30\n",
      "1531/1531 [==============================] - 6s 4ms/step - loss: 0.2435 - val_loss: 0.2854\n",
      "Epoch 29/30\n",
      "1531/1531 [==============================] - 6s 4ms/step - loss: 0.2436 - val_loss: 0.2935\n",
      "Epoch 30/30\n",
      "1531/1531 [==============================] - 6s 4ms/step - loss: 0.2442 - val_loss: 0.2941\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(), loss='mae')\n",
    "history = model.fit(X_train, y_train, epochs = 30, validation_data = (X_val, y_val), batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486e3c06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
