{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cc3b56a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-17 23:46:51.905511: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-17 23:46:52.495689: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/prp/anaconda3/lib/\n",
      "2023-02-17 23:46:52.495908: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/prp/anaconda3/lib/\n",
      "2023-02-17 23:46:52.495917: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf490aaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-17 23:46:53.276924: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-02-17 23:46:53.287092: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-02-17 23:46:53.287143: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "190044d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"/mnt/d/Learning/tensorflow_learning/datasets/creditcard.csv\")\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4bf22b00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    284807 non-null  float64\n",
      " 1   V1      284807 non-null  float64\n",
      " 2   V2      284807 non-null  float64\n",
      " 3   V3      284807 non-null  float64\n",
      " 4   V4      284807 non-null  float64\n",
      " 5   V5      284807 non-null  float64\n",
      " 6   V6      284807 non-null  float64\n",
      " 7   V7      284807 non-null  float64\n",
      " 8   V8      284807 non-null  float64\n",
      " 9   V9      284807 non-null  float64\n",
      " 10  V10     284807 non-null  float64\n",
      " 11  V11     284807 non-null  float64\n",
      " 12  V12     284807 non-null  float64\n",
      " 13  V13     284807 non-null  float64\n",
      " 14  V14     284807 non-null  float64\n",
      " 15  V15     284807 non-null  float64\n",
      " 16  V16     284807 non-null  float64\n",
      " 17  V17     284807 non-null  float64\n",
      " 18  V18     284807 non-null  float64\n",
      " 19  V19     284807 non-null  float64\n",
      " 20  V20     284807 non-null  float64\n",
      " 21  V21     284807 non-null  float64\n",
      " 22  V22     284807 non-null  float64\n",
      " 23  V23     284807 non-null  float64\n",
      " 24  V24     284807 non-null  float64\n",
      " 25  V25     284807 non-null  float64\n",
      " 26  V26     284807 non-null  float64\n",
      " 27  V27     284807 non-null  float64\n",
      " 28  V28     284807 non-null  float64\n",
      " 29  Amount  284807 non-null  float64\n",
      " 30  Class   284807 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09009e2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    284315\n",
       "1       492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.Class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56630e75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Time',\n",
       " 'V1',\n",
       " 'V2',\n",
       " 'V3',\n",
       " 'V4',\n",
       " 'V5',\n",
       " 'V6',\n",
       " 'V7',\n",
       " 'V8',\n",
       " 'V9',\n",
       " 'V10',\n",
       " 'V11',\n",
       " 'V12',\n",
       " 'V13',\n",
       " 'V14',\n",
       " 'V15',\n",
       " 'V16',\n",
       " 'V17',\n",
       " 'V18',\n",
       " 'V19',\n",
       " 'V20',\n",
       " 'V21',\n",
       " 'V22',\n",
       " 'V23',\n",
       " 'V24',\n",
       " 'V25',\n",
       " 'V26',\n",
       " 'V27',\n",
       " 'V28',\n",
       " 'Amount']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_names = dataset.columns.values.tolist()\n",
    "column_names = column_names[:-1]\n",
    "column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2967255",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = dataset['Class']\n",
    "data = dataset.drop('Class', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d563e5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807, 30)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9730aeab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55239f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d6149d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         0\n",
       "1         0\n",
       "2         0\n",
       "3         0\n",
       "4         0\n",
       "         ..\n",
       "284802    0\n",
       "284803    0\n",
       "284804    0\n",
       "284805    0\n",
       "284806    0\n",
       "Name: Class, Length: 284807, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95a385fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d2c7f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnscaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d685e594",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "414f1b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data, train_labels, test_labels = train_test_split(data, labels, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aec04338",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import make_column_transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e50e9b1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ColumnTransformer(transformers=[('minmaxscaler', MinMaxScaler(),\n",
       "                                 ['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6',\n",
       "                                  'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13',\n",
       "                                  'V14', 'V15', 'V16', 'V17', 'V18', 'V19',\n",
       "                                  'V20', 'V21', 'V22', 'V23', 'V24', 'V25',\n",
       "                                  'V26', 'V27', 'V28', 'Amount'])])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct = make_column_transformer(\n",
    "    (MinMaxScaler(), column_names) # get all values between 0 and 1\n",
    ")\n",
    "ct.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "55c362fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_normalised = ct.transform(train_data)\n",
    "test_data_normalised = ct.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d094289d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4011      0\n",
       "20020     0\n",
       "33385     0\n",
       "208241    0\n",
       "186510    0\n",
       "         ..\n",
       "110677    0\n",
       "110792    0\n",
       "29261     0\n",
       "162114    0\n",
       "172095    0\n",
       "Name: Class, Length: 227845, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "300d9ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = train_labels.to_numpy()\n",
    "test_labels = test_labels.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b2c265e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((227845,), (56962,))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.shape, test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7843fa18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((227845, 30), (56962, 30))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_normalised.shape, test_data_normalised.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "75823a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_3 (Dense)             (None, 256)               7936      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 256)               65792     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 256)               65792     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 139,777\n",
      "Trainable params: 139,777\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.Dense(\n",
    "            256, activation=\"relu\", input_shape=(train_data_normalised.shape[-1],)\n",
    "        ),\n",
    "        keras.layers.Dense(256, activation=\"relu\"),\n",
    "        keras.layers.Dropout(0.3),\n",
    "        keras.layers.Dense(256, activation=\"relu\"),\n",
    "        keras.layers.Dropout(0.3),\n",
    "        keras.layers.Dense(1, activation=\"sigmoid\"),\n",
    "    ]\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dcbb33f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive samples in training data: 392 (0.17% of total)\n"
     ]
    }
   ],
   "source": [
    "counts = np.bincount(train_labels.reshape(-1, 1)[:, 0])\n",
    "print(\n",
    "    \"Number of positive samples in training data: {} ({:.2f}% of total)\".format(\n",
    "        counts[1], 100 * float(counts[1]) / len(train_labels)\n",
    "    )\n",
    ")\n",
    "\n",
    "weight_for_0 = 1.0 / counts[0]\n",
    "weight_for_1 = 1.0 / counts[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2134d2c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "112/112 - 2s - loss: 4.4243e-06 - fn: 121.0000 - fp: 36778.0000 - tn: 190675.0000 - tp: 271.0000 - precision: 0.0073 - recall: 0.6913 - val_loss: 0.0663 - val_fn: 21.0000 - val_fp: 27.0000 - val_tn: 56835.0000 - val_tp: 79.0000 - val_precision: 0.7453 - val_recall: 0.7900 - 2s/epoch - 22ms/step\n",
      "Epoch 2/30\n",
      "112/112 - 1s - loss: 2.4053e-06 - fn: 56.0000 - fp: 14329.0000 - tn: 213124.0000 - tp: 336.0000 - precision: 0.0229 - recall: 0.8571 - val_loss: 0.0165 - val_fn: 44.0000 - val_fp: 12.0000 - val_tn: 56850.0000 - val_tp: 56.0000 - val_precision: 0.8235 - val_recall: 0.5600 - 839ms/epoch - 7ms/step\n",
      "Epoch 3/30\n",
      "112/112 - 1s - loss: 2.1936e-06 - fn: 58.0000 - fp: 7541.0000 - tn: 219912.0000 - tp: 334.0000 - precision: 0.0424 - recall: 0.8520 - val_loss: 0.1305 - val_fn: 15.0000 - val_fp: 128.0000 - val_tn: 56734.0000 - val_tp: 85.0000 - val_precision: 0.3991 - val_recall: 0.8500 - 865ms/epoch - 8ms/step\n",
      "Epoch 4/30\n",
      "112/112 - 1s - loss: 2.0566e-06 - fn: 53.0000 - fp: 8432.0000 - tn: 219021.0000 - tp: 339.0000 - precision: 0.0387 - recall: 0.8648 - val_loss: 0.0949 - val_fn: 12.0000 - val_fp: 486.0000 - val_tn: 56376.0000 - val_tp: 88.0000 - val_precision: 0.1533 - val_recall: 0.8800 - 849ms/epoch - 8ms/step\n",
      "Epoch 5/30\n",
      "112/112 - 1s - loss: 1.9322e-06 - fn: 52.0000 - fp: 7503.0000 - tn: 219950.0000 - tp: 340.0000 - precision: 0.0434 - recall: 0.8673 - val_loss: 0.0742 - val_fn: 18.0000 - val_fp: 104.0000 - val_tn: 56758.0000 - val_tp: 82.0000 - val_precision: 0.4409 - val_recall: 0.8200 - 898ms/epoch - 8ms/step\n",
      "Epoch 6/30\n",
      "112/112 - 1s - loss: 1.9186e-06 - fn: 52.0000 - fp: 6110.0000 - tn: 221343.0000 - tp: 340.0000 - precision: 0.0527 - recall: 0.8673 - val_loss: 0.1497 - val_fn: 10.0000 - val_fp: 1524.0000 - val_tn: 55338.0000 - val_tp: 90.0000 - val_precision: 0.0558 - val_recall: 0.9000 - 920ms/epoch - 8ms/step\n",
      "Epoch 7/30\n",
      "112/112 - 1s - loss: 1.8017e-06 - fn: 45.0000 - fp: 6288.0000 - tn: 221165.0000 - tp: 347.0000 - precision: 0.0523 - recall: 0.8852 - val_loss: 0.1333 - val_fn: 12.0000 - val_fp: 627.0000 - val_tn: 56235.0000 - val_tp: 88.0000 - val_precision: 0.1231 - val_recall: 0.8800 - 923ms/epoch - 8ms/step\n",
      "Epoch 8/30\n",
      "112/112 - 1s - loss: 1.7596e-06 - fn: 50.0000 - fp: 7446.0000 - tn: 220007.0000 - tp: 342.0000 - precision: 0.0439 - recall: 0.8724 - val_loss: 0.0097 - val_fn: 26.0000 - val_fp: 29.0000 - val_tn: 56833.0000 - val_tp: 74.0000 - val_precision: 0.7184 - val_recall: 0.7400 - 910ms/epoch - 8ms/step\n",
      "Epoch 9/30\n",
      "112/112 - 1s - loss: 2.1572e-06 - fn: 58.0000 - fp: 6765.0000 - tn: 220688.0000 - tp: 334.0000 - precision: 0.0470 - recall: 0.8520 - val_loss: 0.0648 - val_fn: 19.0000 - val_fp: 95.0000 - val_tn: 56767.0000 - val_tp: 81.0000 - val_precision: 0.4602 - val_recall: 0.8100 - 916ms/epoch - 8ms/step\n",
      "Epoch 10/30\n",
      "112/112 - 1s - loss: 1.8404e-06 - fn: 50.0000 - fp: 6241.0000 - tn: 221212.0000 - tp: 342.0000 - precision: 0.0520 - recall: 0.8724 - val_loss: 0.0654 - val_fn: 12.0000 - val_fp: 540.0000 - val_tn: 56322.0000 - val_tp: 88.0000 - val_precision: 0.1401 - val_recall: 0.8800 - 893ms/epoch - 8ms/step\n",
      "Epoch 11/30\n",
      "112/112 - 1s - loss: 1.9512e-06 - fn: 50.0000 - fp: 7792.0000 - tn: 219661.0000 - tp: 342.0000 - precision: 0.0420 - recall: 0.8724 - val_loss: 0.2226 - val_fn: 12.0000 - val_fp: 589.0000 - val_tn: 56273.0000 - val_tp: 88.0000 - val_precision: 0.1300 - val_recall: 0.8800 - 906ms/epoch - 8ms/step\n",
      "Epoch 12/30\n",
      "112/112 - 1s - loss: 1.9319e-06 - fn: 46.0000 - fp: 6560.0000 - tn: 220893.0000 - tp: 346.0000 - precision: 0.0501 - recall: 0.8827 - val_loss: 0.1252 - val_fn: 12.0000 - val_fp: 501.0000 - val_tn: 56361.0000 - val_tp: 88.0000 - val_precision: 0.1494 - val_recall: 0.8800 - 904ms/epoch - 8ms/step\n",
      "Epoch 13/30\n",
      "112/112 - 1s - loss: 1.8641e-06 - fn: 50.0000 - fp: 6876.0000 - tn: 220577.0000 - tp: 342.0000 - precision: 0.0474 - recall: 0.8724 - val_loss: 0.1473 - val_fn: 12.0000 - val_fp: 749.0000 - val_tn: 56113.0000 - val_tp: 88.0000 - val_precision: 0.1051 - val_recall: 0.8800 - 884ms/epoch - 8ms/step\n",
      "Epoch 14/30\n",
      "112/112 - 1s - loss: 1.8414e-06 - fn: 47.0000 - fp: 4658.0000 - tn: 222795.0000 - tp: 345.0000 - precision: 0.0690 - recall: 0.8801 - val_loss: 0.1470 - val_fn: 11.0000 - val_fp: 1145.0000 - val_tn: 55717.0000 - val_tp: 89.0000 - val_precision: 0.0721 - val_recall: 0.8900 - 917ms/epoch - 8ms/step\n",
      "Epoch 15/30\n",
      "112/112 - 1s - loss: 1.9606e-06 - fn: 51.0000 - fp: 5656.0000 - tn: 221797.0000 - tp: 341.0000 - precision: 0.0569 - recall: 0.8699 - val_loss: 0.2284 - val_fn: 11.0000 - val_fp: 1640.0000 - val_tn: 55222.0000 - val_tp: 89.0000 - val_precision: 0.0515 - val_recall: 0.8900 - 935ms/epoch - 8ms/step\n",
      "Epoch 16/30\n",
      "112/112 - 1s - loss: 1.7243e-06 - fn: 42.0000 - fp: 5455.0000 - tn: 221998.0000 - tp: 350.0000 - precision: 0.0603 - recall: 0.8929 - val_loss: 0.2783 - val_fn: 10.0000 - val_fp: 2407.0000 - val_tn: 54455.0000 - val_tp: 90.0000 - val_precision: 0.0360 - val_recall: 0.9000 - 931ms/epoch - 8ms/step\n",
      "Epoch 17/30\n",
      "112/112 - 1s - loss: 1.6661e-06 - fn: 45.0000 - fp: 5341.0000 - tn: 222112.0000 - tp: 347.0000 - precision: 0.0610 - recall: 0.8852 - val_loss: 0.0690 - val_fn: 12.0000 - val_fp: 407.0000 - val_tn: 56455.0000 - val_tp: 88.0000 - val_precision: 0.1778 - val_recall: 0.8800 - 937ms/epoch - 8ms/step\n",
      "Epoch 18/30\n",
      "112/112 - 1s - loss: 1.6754e-06 - fn: 45.0000 - fp: 5041.0000 - tn: 222412.0000 - tp: 347.0000 - precision: 0.0644 - recall: 0.8852 - val_loss: 0.0962 - val_fn: 12.0000 - val_fp: 823.0000 - val_tn: 56039.0000 - val_tp: 88.0000 - val_precision: 0.0966 - val_recall: 0.8800 - 927ms/epoch - 8ms/step\n",
      "Epoch 19/30\n",
      "112/112 - 1s - loss: 1.8714e-06 - fn: 50.0000 - fp: 8210.0000 - tn: 219243.0000 - tp: 342.0000 - precision: 0.0400 - recall: 0.8724 - val_loss: 0.0466 - val_fn: 19.0000 - val_fp: 138.0000 - val_tn: 56724.0000 - val_tp: 81.0000 - val_precision: 0.3699 - val_recall: 0.8100 - 898ms/epoch - 8ms/step\n",
      "Epoch 20/30\n",
      "112/112 - 1s - loss: 1.8347e-06 - fn: 48.0000 - fp: 5186.0000 - tn: 222267.0000 - tp: 344.0000 - precision: 0.0622 - recall: 0.8776 - val_loss: 0.0530 - val_fn: 12.0000 - val_fp: 433.0000 - val_tn: 56429.0000 - val_tp: 88.0000 - val_precision: 0.1689 - val_recall: 0.8800 - 913ms/epoch - 8ms/step\n",
      "Epoch 21/30\n",
      "112/112 - 1s - loss: 1.9958e-06 - fn: 54.0000 - fp: 6135.0000 - tn: 221318.0000 - tp: 338.0000 - precision: 0.0522 - recall: 0.8622 - val_loss: 0.0786 - val_fn: 12.0000 - val_fp: 523.0000 - val_tn: 56339.0000 - val_tp: 88.0000 - val_precision: 0.1440 - val_recall: 0.8800 - 934ms/epoch - 8ms/step\n",
      "Epoch 22/30\n",
      "112/112 - 1s - loss: 1.8563e-06 - fn: 46.0000 - fp: 7537.0000 - tn: 219916.0000 - tp: 346.0000 - precision: 0.0439 - recall: 0.8827 - val_loss: 0.2685 - val_fn: 8.0000 - val_fp: 3914.0000 - val_tn: 52948.0000 - val_tp: 92.0000 - val_precision: 0.0230 - val_recall: 0.9200 - 934ms/epoch - 8ms/step\n",
      "Epoch 23/30\n",
      "112/112 - 1s - loss: 1.6998e-06 - fn: 42.0000 - fp: 5383.0000 - tn: 222070.0000 - tp: 350.0000 - precision: 0.0611 - recall: 0.8929 - val_loss: 0.1029 - val_fn: 13.0000 - val_fp: 251.0000 - val_tn: 56611.0000 - val_tp: 87.0000 - val_precision: 0.2574 - val_recall: 0.8700 - 943ms/epoch - 8ms/step\n",
      "Epoch 24/30\n",
      "112/112 - 1s - loss: 1.5664e-06 - fn: 44.0000 - fp: 4730.0000 - tn: 222723.0000 - tp: 348.0000 - precision: 0.0685 - recall: 0.8878 - val_loss: 0.1624 - val_fn: 10.0000 - val_fp: 1815.0000 - val_tn: 55047.0000 - val_tp: 90.0000 - val_precision: 0.0472 - val_recall: 0.9000 - 933ms/epoch - 8ms/step\n",
      "Epoch 25/30\n",
      "112/112 - 1s - loss: 1.6911e-06 - fn: 45.0000 - fp: 6242.0000 - tn: 221211.0000 - tp: 347.0000 - precision: 0.0527 - recall: 0.8852 - val_loss: 0.1891 - val_fn: 10.0000 - val_fp: 1992.0000 - val_tn: 54870.0000 - val_tp: 90.0000 - val_precision: 0.0432 - val_recall: 0.9000 - 922ms/epoch - 8ms/step\n",
      "Epoch 26/30\n",
      "112/112 - 1s - loss: 1.8926e-06 - fn: 49.0000 - fp: 6657.0000 - tn: 220796.0000 - tp: 343.0000 - precision: 0.0490 - recall: 0.8750 - val_loss: 0.0814 - val_fn: 14.0000 - val_fp: 250.0000 - val_tn: 56612.0000 - val_tp: 86.0000 - val_precision: 0.2560 - val_recall: 0.8600 - 922ms/epoch - 8ms/step\n",
      "Epoch 27/30\n",
      "112/112 - 1s - loss: 2.0524e-06 - fn: 58.0000 - fp: 8249.0000 - tn: 219204.0000 - tp: 334.0000 - precision: 0.0389 - recall: 0.8520 - val_loss: 0.2903 - val_fn: 11.0000 - val_fp: 1621.0000 - val_tn: 55241.0000 - val_tp: 89.0000 - val_precision: 0.0520 - val_recall: 0.8900 - 895ms/epoch - 8ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/30\n",
      "112/112 - 1s - loss: 1.9511e-06 - fn: 53.0000 - fp: 8544.0000 - tn: 218909.0000 - tp: 339.0000 - precision: 0.0382 - recall: 0.8648 - val_loss: 0.0654 - val_fn: 13.0000 - val_fp: 394.0000 - val_tn: 56468.0000 - val_tp: 87.0000 - val_precision: 0.1809 - val_recall: 0.8700 - 918ms/epoch - 8ms/step\n",
      "Epoch 29/30\n",
      "112/112 - 1s - loss: 1.7255e-06 - fn: 48.0000 - fp: 5983.0000 - tn: 221470.0000 - tp: 344.0000 - precision: 0.0544 - recall: 0.8776 - val_loss: 0.1563 - val_fn: 11.0000 - val_fp: 1484.0000 - val_tn: 55378.0000 - val_tp: 89.0000 - val_precision: 0.0566 - val_recall: 0.8900 - 913ms/epoch - 8ms/step\n",
      "Epoch 30/30\n",
      "112/112 - 1s - loss: 1.6373e-06 - fn: 41.0000 - fp: 5655.0000 - tn: 221798.0000 - tp: 351.0000 - precision: 0.0584 - recall: 0.8954 - val_loss: 0.1684 - val_fn: 11.0000 - val_fp: 1187.0000 - val_tn: 55675.0000 - val_tp: 89.0000 - val_precision: 0.0697 - val_recall: 0.8900 - 899ms/epoch - 8ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe0d426c9a0>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = [\n",
    "    keras.metrics.FalseNegatives(name=\"fn\"),\n",
    "    keras.metrics.FalsePositives(name=\"fp\"),\n",
    "    keras.metrics.TrueNegatives(name=\"tn\"),\n",
    "    keras.metrics.TruePositives(name=\"tp\"),\n",
    "    keras.metrics.Precision(name=\"precision\"),\n",
    "    keras.metrics.Recall(name=\"recall\"),\n",
    "]\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(1e-2), loss=\"binary_crossentropy\", metrics=metrics\n",
    ")\n",
    "\n",
    "callbacks = [keras.callbacks.ModelCheckpoint(\"fraud_model_at_epoch_{epoch}.h5\")]\n",
    "class_weight = {0: weight_for_0, 1: weight_for_1}\n",
    "\n",
    "model.fit(\n",
    "    train_data_normalised,\n",
    "    train_labels,\n",
    "    batch_size=2048,\n",
    "    epochs=30,\n",
    "    verbose=2,\n",
    "    callbacks=callbacks,\n",
    "    validation_data=(test_data_normalised, test_labels),\n",
    "    class_weight=class_weight,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ca93f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
